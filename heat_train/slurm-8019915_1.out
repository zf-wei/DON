/people/weiz828/.conda/envs/test/lib/python3.12/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/people/weiz828/.conda/envs/test/lib/python3.12/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
The dimension of y_tensor is torch.Size([5000, 2]).
The dimension of y_expanded is torch.Size([500, 5000, 2]) after expanding.
The dimensions of the initial conditions are: (500, 50)
The dimensions of the solutions are: (500, 100, 50)
The dimension of u_tensor is torch.Size([500, 50]).
The dimension of u_expanded is torch.Size([500, 5000, 50]) after expanding.
The loaded solution dataset has dimension (500, 100, 50),
	 while the arranged linearized dataset has dimension (500, 5000).
The dimension of s_tensor is torch.Size([500, 5000]).
The dimension of s_expanded is torch.Size([500, 5000, 1]) after expanding.
Epoch 1
A best model at epoch 1 has been saved with training error 0.023911092.
A best model at epoch 1 has been saved with training error 0.019749112.
A best model at epoch 1 has been saved with training error 0.018401034.
A best model at epoch 1 has been saved with training error 0.016090980.
A best model at epoch 1 has been saved with training error 0.010045837.
A best model at epoch 1 has been saved with training error 0.007458847.
Epoch 1, Loss: 0.015134926, Improvement: 0.015134926, Best Loss: 0.007458847 in Epoch 1
Epoch 2
A best model at epoch 2 has been saved with training error 0.005231919.
Epoch 2, Loss: 0.010710399, Improvement: -0.004424528, Best Loss: 0.005231919 in Epoch 2
Epoch 3
Epoch 3, Loss: 0.010238475, Improvement: -0.000471924, Best Loss: 0.005231919 in Epoch 2
Epoch 4
Epoch 4, Loss: 0.009691835, Improvement: -0.000546640, Best Loss: 0.005231919 in Epoch 2
Epoch 5
Epoch 5, Loss: 0.008409297, Improvement: -0.001282538, Best Loss: 0.005231919 in Epoch 2
Epoch 6
A best model at epoch 6 has been saved with training error 0.004041876.
Epoch 6, Loss: 0.006622918, Improvement: -0.001786379, Best Loss: 0.004041876 in Epoch 6
Epoch 7
A best model at epoch 7 has been saved with training error 0.003824838.
Epoch 7, Loss: 0.006840734, Improvement: 0.000217816, Best Loss: 0.003824838 in Epoch 7
Epoch 8
Epoch 8, Loss: 0.006154144, Improvement: -0.000686590, Best Loss: 0.003824838 in Epoch 7
Epoch 9
A best model at epoch 9 has been saved with training error 0.003325420.
Epoch 9, Loss: 0.005615696, Improvement: -0.000538448, Best Loss: 0.003325420 in Epoch 9
Epoch 10
A best model at epoch 10 has been saved with training error 0.003016144.
Epoch 10, Loss: 0.005416984, Improvement: -0.000198712, Best Loss: 0.003016144 in Epoch 10
Epoch 11
Epoch 11, Loss: 0.005168552, Improvement: -0.000248432, Best Loss: 0.003016144 in Epoch 10
Epoch 12
Epoch 12, Loss: 0.004939353, Improvement: -0.000229198, Best Loss: 0.003016144 in Epoch 10
Epoch 13
Epoch 13, Loss: 0.004812118, Improvement: -0.000127235, Best Loss: 0.003016144 in Epoch 10
Epoch 14
Epoch 14, Loss: 0.004781969, Improvement: -0.000030149, Best Loss: 0.003016144 in Epoch 10
Epoch 15
Epoch 15, Loss: 0.005194835, Improvement: 0.000412866, Best Loss: 0.003016144 in Epoch 10
Epoch 16
Epoch 16, Loss: 0.004704473, Improvement: -0.000490362, Best Loss: 0.003016144 in Epoch 10
Epoch 17
A best model at epoch 17 has been saved with training error 0.002962437.
A best model at epoch 17 has been saved with training error 0.002809409.
Epoch 17, Loss: 0.004258768, Improvement: -0.000445705, Best Loss: 0.002809409 in Epoch 17
Epoch 18
A best model at epoch 18 has been saved with training error 0.001755195.
Epoch 18, Loss: 0.004022358, Improvement: -0.000236410, Best Loss: 0.001755195 in Epoch 18
Epoch 19
Epoch 19, Loss: 0.004006008, Improvement: -0.000016350, Best Loss: 0.001755195 in Epoch 18
Epoch 20
Epoch 20, Loss: 0.003901655, Improvement: -0.000104353, Best Loss: 0.001755195 in Epoch 18
Epoch 21
Epoch 21, Loss: 0.003412428, Improvement: -0.000489227, Best Loss: 0.001755195 in Epoch 18
Epoch 22
Epoch 22, Loss: 0.004113534, Improvement: 0.000701106, Best Loss: 0.001755195 in Epoch 18
Epoch 23
Epoch 23, Loss: 0.003475836, Improvement: -0.000637697, Best Loss: 0.001755195 in Epoch 18
Epoch 24
Epoch 24, Loss: 0.003082149, Improvement: -0.000393687, Best Loss: 0.001755195 in Epoch 18
Epoch 25
Epoch 25, Loss: 0.002818446, Improvement: -0.000263703, Best Loss: 0.001755195 in Epoch 18
Epoch 26
Epoch 26, Loss: 0.002969443, Improvement: 0.000150997, Best Loss: 0.001755195 in Epoch 18
Epoch 27
Epoch 27, Loss: 0.003143689, Improvement: 0.000174246, Best Loss: 0.001755195 in Epoch 18
Epoch 28
Epoch 28, Loss: 0.002767589, Improvement: -0.000376100, Best Loss: 0.001755195 in Epoch 18
Epoch 29
A best model at epoch 29 has been saved with training error 0.001699170.
Epoch 29, Loss: 0.002736560, Improvement: -0.000031029, Best Loss: 0.001699170 in Epoch 29
Epoch 30
A best model at epoch 30 has been saved with training error 0.001496534.
Epoch 30, Loss: 0.002804820, Improvement: 0.000068260, Best Loss: 0.001496534 in Epoch 30
Epoch 31
Epoch 31, Loss: 0.002842427, Improvement: 0.000037607, Best Loss: 0.001496534 in Epoch 30
Epoch 32
Epoch 32, Loss: 0.002572800, Improvement: -0.000269627, Best Loss: 0.001496534 in Epoch 30
Epoch 33
A best model at epoch 33 has been saved with training error 0.001473244.
Epoch 33, Loss: 0.002388861, Improvement: -0.000183939, Best Loss: 0.001473244 in Epoch 33
Epoch 34
A best model at epoch 34 has been saved with training error 0.001318358.
Epoch 34, Loss: 0.002409883, Improvement: 0.000021022, Best Loss: 0.001318358 in Epoch 34
Epoch 35
Epoch 35, Loss: 0.002241669, Improvement: -0.000168214, Best Loss: 0.001318358 in Epoch 34
Epoch 36
Epoch 36, Loss: 0.002289512, Improvement: 0.000047843, Best Loss: 0.001318358 in Epoch 34
Epoch 37
Epoch 37, Loss: 0.003052945, Improvement: 0.000763433, Best Loss: 0.001318358 in Epoch 34
Epoch 38
Epoch 38, Loss: 0.002973292, Improvement: -0.000079653, Best Loss: 0.001318358 in Epoch 34
Epoch 39
Epoch 39, Loss: 0.002298529, Improvement: -0.000674763, Best Loss: 0.001318358 in Epoch 34
Epoch 40
Epoch 40, Loss: 0.002130876, Improvement: -0.000167653, Best Loss: 0.001318358 in Epoch 34
Epoch 41
A best model at epoch 41 has been saved with training error 0.001253028.
Epoch 41, Loss: 0.002054334, Improvement: -0.000076542, Best Loss: 0.001253028 in Epoch 41
Epoch 42
Epoch 42, Loss: 0.002040313, Improvement: -0.000014020, Best Loss: 0.001253028 in Epoch 41
Epoch 43
Epoch 43, Loss: 0.002760627, Improvement: 0.000720313, Best Loss: 0.001253028 in Epoch 41
Epoch 44
Epoch 44, Loss: 0.002336922, Improvement: -0.000423705, Best Loss: 0.001253028 in Epoch 41
Epoch 45
Epoch 45, Loss: 0.002021753, Improvement: -0.000315170, Best Loss: 0.001253028 in Epoch 41
Epoch 46
A best model at epoch 46 has been saved with training error 0.001155306.
Epoch 46, Loss: 0.001891752, Improvement: -0.000130000, Best Loss: 0.001155306 in Epoch 46
Epoch 47
Epoch 47, Loss: 0.003249694, Improvement: 0.001357942, Best Loss: 0.001155306 in Epoch 46
Epoch 48
Epoch 48, Loss: 0.002162547, Improvement: -0.001087147, Best Loss: 0.001155306 in Epoch 46
Epoch 49
A best model at epoch 49 has been saved with training error 0.000975941.
Epoch 49, Loss: 0.001816705, Improvement: -0.000345842, Best Loss: 0.000975941 in Epoch 49
Epoch 50
Model saving checkpoint: the model trained after epoch 50 has been saved with the training errors.
Epoch 50, Loss: 0.001731184, Improvement: -0.000085521, Best Loss: 0.000975941 in Epoch 49
Epoch 51
A best model at epoch 51 has been saved with training error 0.000960540.
Epoch 51, Loss: 0.001641145, Improvement: -0.000090039, Best Loss: 0.000960540 in Epoch 51
Epoch 52
A best model at epoch 52 has been saved with training error 0.000880404.
Epoch 52, Loss: 0.001566400, Improvement: -0.000074745, Best Loss: 0.000880404 in Epoch 52
Epoch 53
Epoch 53, Loss: 0.001714009, Improvement: 0.000147609, Best Loss: 0.000880404 in Epoch 52
Epoch 54
Epoch 54, Loss: 0.002635845, Improvement: 0.000921836, Best Loss: 0.000880404 in Epoch 52
Epoch 55
Epoch 55, Loss: 0.002494504, Improvement: -0.000141341, Best Loss: 0.000880404 in Epoch 52
Epoch 56
Epoch 56, Loss: 0.001891732, Improvement: -0.000602772, Best Loss: 0.000880404 in Epoch 52
Epoch 57
Epoch 57, Loss: 0.001704036, Improvement: -0.000187696, Best Loss: 0.000880404 in Epoch 52
Epoch 58
A best model at epoch 58 has been saved with training error 0.000775417.
Epoch 58, Loss: 0.001684363, Improvement: -0.000019673, Best Loss: 0.000775417 in Epoch 58
Epoch 59
A best model at epoch 59 has been saved with training error 0.000750950.
Epoch 59, Loss: 0.001540116, Improvement: -0.000144247, Best Loss: 0.000750950 in Epoch 59
Epoch 60
Epoch 60, Loss: 0.001510090, Improvement: -0.000030027, Best Loss: 0.000750950 in Epoch 59
Epoch 61
Epoch 61, Loss: 0.001749278, Improvement: 0.000239189, Best Loss: 0.000750950 in Epoch 59
Epoch 62
Epoch 62, Loss: 0.001894122, Improvement: 0.000144843, Best Loss: 0.000750950 in Epoch 59
Epoch 63
Epoch 63, Loss: 0.001476617, Improvement: -0.000417504, Best Loss: 0.000750950 in Epoch 59
Epoch 64
A best model at epoch 64 has been saved with training error 0.000665152.
Epoch 64, Loss: 0.001324675, Improvement: -0.000151942, Best Loss: 0.000665152 in Epoch 64
Epoch 65
Epoch 65, Loss: 0.001247109, Improvement: -0.000077566, Best Loss: 0.000665152 in Epoch 64
Epoch 66
A best model at epoch 66 has been saved with training error 0.000455276.
Epoch 66, Loss: 0.001231737, Improvement: -0.000015372, Best Loss: 0.000455276 in Epoch 66
Epoch 67
Epoch 67, Loss: 0.001924978, Improvement: 0.000693240, Best Loss: 0.000455276 in Epoch 66
Epoch 68
Epoch 68, Loss: 0.001821205, Improvement: -0.000103773, Best Loss: 0.000455276 in Epoch 66
Epoch 69
Epoch 69, Loss: 0.001353294, Improvement: -0.000467911, Best Loss: 0.000455276 in Epoch 66
Epoch 70
Epoch 70, Loss: 0.001215815, Improvement: -0.000137479, Best Loss: 0.000455276 in Epoch 66
Epoch 71
Epoch 71, Loss: 0.001197652, Improvement: -0.000018163, Best Loss: 0.000455276 in Epoch 66
Epoch 72
Epoch 72, Loss: 0.001142407, Improvement: -0.000055245, Best Loss: 0.000455276 in Epoch 66
Epoch 73
Epoch 73, Loss: 0.001059816, Improvement: -0.000082591, Best Loss: 0.000455276 in Epoch 66
Epoch 74
Epoch 74, Loss: 0.001346364, Improvement: 0.000286548, Best Loss: 0.000455276 in Epoch 66
Epoch 75
Epoch 75, Loss: 0.001682284, Improvement: 0.000335920, Best Loss: 0.000455276 in Epoch 66
Epoch 76
Epoch 76, Loss: 0.001480252, Improvement: -0.000202032, Best Loss: 0.000455276 in Epoch 66
Epoch 77
Epoch 77, Loss: 0.001323746, Improvement: -0.000156506, Best Loss: 0.000455276 in Epoch 66
Epoch 78
Epoch 78, Loss: 0.001184100, Improvement: -0.000139646, Best Loss: 0.000455276 in Epoch 66
Epoch 79
Epoch 79, Loss: 0.001018011, Improvement: -0.000166089, Best Loss: 0.000455276 in Epoch 66
Epoch 80
Epoch 80, Loss: 0.000937558, Improvement: -0.000080453, Best Loss: 0.000455276 in Epoch 66
Epoch 81
Epoch 81, Loss: 0.001092373, Improvement: 0.000154815, Best Loss: 0.000455276 in Epoch 66
Epoch 82
Epoch 82, Loss: 0.001066251, Improvement: -0.000026122, Best Loss: 0.000455276 in Epoch 66
Epoch 83
Epoch 83, Loss: 0.001070591, Improvement: 0.000004340, Best Loss: 0.000455276 in Epoch 66
Epoch 84
Epoch 84, Loss: 0.001484172, Improvement: 0.000413581, Best Loss: 0.000455276 in Epoch 66
Epoch 85
Epoch 85, Loss: 0.001783435, Improvement: 0.000299263, Best Loss: 0.000455276 in Epoch 66
Epoch 86
Epoch 86, Loss: 0.001203383, Improvement: -0.000580052, Best Loss: 0.000455276 in Epoch 66
Epoch 87
Epoch 87, Loss: 0.001026696, Improvement: -0.000176687, Best Loss: 0.000455276 in Epoch 66
Epoch 88
Epoch 88, Loss: 0.000974742, Improvement: -0.000051953, Best Loss: 0.000455276 in Epoch 66
Epoch 89
Epoch 89, Loss: 0.000967852, Improvement: -0.000006891, Best Loss: 0.000455276 in Epoch 66
Epoch 90
Epoch 90, Loss: 0.000840012, Improvement: -0.000127840, Best Loss: 0.000455276 in Epoch 66
Epoch 91
Epoch 91, Loss: 0.000817510, Improvement: -0.000022502, Best Loss: 0.000455276 in Epoch 66
Epoch 92
Epoch 92, Loss: 0.000805185, Improvement: -0.000012325, Best Loss: 0.000455276 in Epoch 66
Epoch 93
Epoch 93, Loss: 0.001374367, Improvement: 0.000569182, Best Loss: 0.000455276 in Epoch 66
Epoch 94
Epoch 94, Loss: 0.001191206, Improvement: -0.000183161, Best Loss: 0.000455276 in Epoch 66
Epoch 95
Epoch 95, Loss: 0.000998175, Improvement: -0.000193032, Best Loss: 0.000455276 in Epoch 66
Epoch 96
Epoch 96, Loss: 0.000851310, Improvement: -0.000146864, Best Loss: 0.000455276 in Epoch 66
Epoch 97
Epoch 97, Loss: 0.000789378, Improvement: -0.000061932, Best Loss: 0.000455276 in Epoch 66
Epoch 98
Epoch 98, Loss: 0.000710857, Improvement: -0.000078521, Best Loss: 0.000455276 in Epoch 66
Epoch 99
Epoch 99, Loss: 0.001003637, Improvement: 0.000292781, Best Loss: 0.000455276 in Epoch 66
Epoch 100
Model saving checkpoint: the model trained after epoch 100 has been saved with the training errors.
Epoch 100, Loss: 0.001801051, Improvement: 0.000797414, Best Loss: 0.000455276 in Epoch 66
Epoch 101
Epoch 101, Loss: 0.001735729, Improvement: -0.000065323, Best Loss: 0.000455276 in Epoch 66
Epoch 102
Epoch 102, Loss: 0.001355707, Improvement: -0.000380022, Best Loss: 0.000455276 in Epoch 66
Epoch 103
Epoch 103, Loss: 0.001019490, Improvement: -0.000336216, Best Loss: 0.000455276 in Epoch 66
Epoch 104
A best model at epoch 104 has been saved with training error 0.000444172.
Epoch 104, Loss: 0.000889871, Improvement: -0.000129620, Best Loss: 0.000444172 in Epoch 104
Epoch 105
Epoch 105, Loss: 0.000776445, Improvement: -0.000113426, Best Loss: 0.000444172 in Epoch 104
Epoch 106
Epoch 106, Loss: 0.000703704, Improvement: -0.000072741, Best Loss: 0.000444172 in Epoch 104
Epoch 107
A best model at epoch 107 has been saved with training error 0.000369609.
Epoch 107, Loss: 0.000671136, Improvement: -0.000032568, Best Loss: 0.000369609 in Epoch 107
Epoch 108
Epoch 108, Loss: 0.000612163, Improvement: -0.000058973, Best Loss: 0.000369609 in Epoch 107
Epoch 109
Epoch 109, Loss: 0.000578846, Improvement: -0.000033317, Best Loss: 0.000369609 in Epoch 107
Epoch 110
Epoch 110, Loss: 0.000676272, Improvement: 0.000097426, Best Loss: 0.000369609 in Epoch 107
Epoch 111
A best model at epoch 111 has been saved with training error 0.000365519.
Epoch 111, Loss: 0.001034643, Improvement: 0.000358371, Best Loss: 0.000365519 in Epoch 111
Epoch 112
Epoch 112, Loss: 0.001179635, Improvement: 0.000144992, Best Loss: 0.000365519 in Epoch 111
Epoch 113
Epoch 113, Loss: 0.000771949, Improvement: -0.000407686, Best Loss: 0.000365519 in Epoch 111
Epoch 114
A best model at epoch 114 has been saved with training error 0.000300670.
Epoch 114, Loss: 0.000683398, Improvement: -0.000088550, Best Loss: 0.000300670 in Epoch 114
Epoch 115
Epoch 115, Loss: 0.000653570, Improvement: -0.000029828, Best Loss: 0.000300670 in Epoch 114
Epoch 116
Epoch 116, Loss: 0.000630845, Improvement: -0.000022726, Best Loss: 0.000300670 in Epoch 114
Epoch 117
Epoch 117, Loss: 0.000576046, Improvement: -0.000054799, Best Loss: 0.000300670 in Epoch 114
Epoch 118
Epoch 118, Loss: 0.000543607, Improvement: -0.000032438, Best Loss: 0.000300670 in Epoch 114
Epoch 119
Epoch 119, Loss: 0.000649969, Improvement: 0.000106362, Best Loss: 0.000300670 in Epoch 114
Epoch 120
Epoch 120, Loss: 0.001134550, Improvement: 0.000484580, Best Loss: 0.000300670 in Epoch 114
Epoch 121
Epoch 121, Loss: 0.001126847, Improvement: -0.000007703, Best Loss: 0.000300670 in Epoch 114
Epoch 122
Epoch 122, Loss: 0.000726641, Improvement: -0.000400206, Best Loss: 0.000300670 in Epoch 114
Epoch 123
Epoch 123, Loss: 0.000613363, Improvement: -0.000113278, Best Loss: 0.000300670 in Epoch 114
Epoch 124
Epoch 124, Loss: 0.000655277, Improvement: 0.000041915, Best Loss: 0.000300670 in Epoch 114
Epoch 125
Epoch 125, Loss: 0.001440057, Improvement: 0.000784779, Best Loss: 0.000300670 in Epoch 114
Epoch 126
Epoch 126, Loss: 0.000858607, Improvement: -0.000581449, Best Loss: 0.000300670 in Epoch 114
Epoch 127
Epoch 127, Loss: 0.000701962, Improvement: -0.000156645, Best Loss: 0.000300670 in Epoch 114
Epoch 128
Epoch 128, Loss: 0.000633219, Improvement: -0.000068744, Best Loss: 0.000300670 in Epoch 114
Epoch 129
Epoch 129, Loss: 0.000610341, Improvement: -0.000022877, Best Loss: 0.000300670 in Epoch 114
Epoch 130
Epoch 130, Loss: 0.000657507, Improvement: 0.000047166, Best Loss: 0.000300670 in Epoch 114
Epoch 131
Epoch 131, Loss: 0.000605191, Improvement: -0.000052316, Best Loss: 0.000300670 in Epoch 114
Epoch 132
Epoch 132, Loss: 0.000569357, Improvement: -0.000035834, Best Loss: 0.000300670 in Epoch 114
Epoch 133
Epoch 133, Loss: 0.000813868, Improvement: 0.000244511, Best Loss: 0.000300670 in Epoch 114
Epoch 134
Epoch 134, Loss: 0.000680495, Improvement: -0.000133373, Best Loss: 0.000300670 in Epoch 114
Epoch 135
Epoch 135, Loss: 0.000603009, Improvement: -0.000077486, Best Loss: 0.000300670 in Epoch 114
Epoch 136
Epoch 136, Loss: 0.000682338, Improvement: 0.000079329, Best Loss: 0.000300670 in Epoch 114
Epoch 137
Epoch 137, Loss: 0.000699713, Improvement: 0.000017375, Best Loss: 0.000300670 in Epoch 114
Epoch 138
Epoch 138, Loss: 0.001095404, Improvement: 0.000395691, Best Loss: 0.000300670 in Epoch 114
Epoch 139
Epoch 139, Loss: 0.000752400, Improvement: -0.000343004, Best Loss: 0.000300670 in Epoch 114
Epoch 140
Epoch 140, Loss: 0.000649259, Improvement: -0.000103141, Best Loss: 0.000300670 in Epoch 114
Epoch 141
Epoch 141, Loss: 0.000612936, Improvement: -0.000036323, Best Loss: 0.000300670 in Epoch 114
Epoch 142
Epoch 142, Loss: 0.000616374, Improvement: 0.000003438, Best Loss: 0.000300670 in Epoch 114
Epoch 143
Epoch 143, Loss: 0.000538440, Improvement: -0.000077934, Best Loss: 0.000300670 in Epoch 114
Epoch 144
A best model at epoch 144 has been saved with training error 0.000285371.
Epoch 144, Loss: 0.000486173, Improvement: -0.000052267, Best Loss: 0.000285371 in Epoch 144
Epoch 145
Epoch 145, Loss: 0.000565769, Improvement: 0.000079596, Best Loss: 0.000285371 in Epoch 144
Epoch 146
A best model at epoch 146 has been saved with training error 0.000277202.
Epoch 146, Loss: 0.000431400, Improvement: -0.000134369, Best Loss: 0.000277202 in Epoch 146
Epoch 147
Epoch 147, Loss: 0.000395760, Improvement: -0.000035640, Best Loss: 0.000277202 in Epoch 146
Epoch 148
Epoch 148, Loss: 0.000392373, Improvement: -0.000003387, Best Loss: 0.000277202 in Epoch 146
Epoch 149
Epoch 149, Loss: 0.000578981, Improvement: 0.000186609, Best Loss: 0.000277202 in Epoch 146
Epoch 150
Model saving checkpoint: the model trained after epoch 150 has been saved with the training errors.
Epoch 150, Loss: 0.000459112, Improvement: -0.000119869, Best Loss: 0.000277202 in Epoch 146
Epoch 151
Epoch 151, Loss: 0.000461591, Improvement: 0.000002479, Best Loss: 0.000277202 in Epoch 146
Epoch 152
Epoch 152, Loss: 0.000536313, Improvement: 0.000074722, Best Loss: 0.000277202 in Epoch 146
Epoch 153
Epoch 153, Loss: 0.000632896, Improvement: 0.000096583, Best Loss: 0.000277202 in Epoch 146
Epoch 154
Epoch 154, Loss: 0.000638963, Improvement: 0.000006067, Best Loss: 0.000277202 in Epoch 146
Epoch 155
Epoch 155, Loss: 0.000472138, Improvement: -0.000166825, Best Loss: 0.000277202 in Epoch 146
Epoch 156
A best model at epoch 156 has been saved with training error 0.000276802.
Epoch 156, Loss: 0.000396056, Improvement: -0.000076083, Best Loss: 0.000276802 in Epoch 156
Epoch 157
A best model at epoch 157 has been saved with training error 0.000209755.
Epoch 157, Loss: 0.000571425, Improvement: 0.000175369, Best Loss: 0.000209755 in Epoch 157
Epoch 158
Epoch 158, Loss: 0.000518023, Improvement: -0.000053401, Best Loss: 0.000209755 in Epoch 157
Epoch 159
Epoch 159, Loss: 0.000399585, Improvement: -0.000118438, Best Loss: 0.000209755 in Epoch 157
Epoch 160
Epoch 160, Loss: 0.000378953, Improvement: -0.000020632, Best Loss: 0.000209755 in Epoch 157
Epoch 161
Epoch 161, Loss: 0.001197144, Improvement: 0.000818191, Best Loss: 0.000209755 in Epoch 157
Epoch 162
Epoch 162, Loss: 0.001037332, Improvement: -0.000159813, Best Loss: 0.000209755 in Epoch 157
Epoch 163
Epoch 163, Loss: 0.000616539, Improvement: -0.000420792, Best Loss: 0.000209755 in Epoch 157
Epoch 164
Epoch 164, Loss: 0.000478428, Improvement: -0.000138111, Best Loss: 0.000209755 in Epoch 157
Epoch 165
Epoch 165, Loss: 0.000424915, Improvement: -0.000053513, Best Loss: 0.000209755 in Epoch 157
Epoch 166
Epoch 166, Loss: 0.000368091, Improvement: -0.000056824, Best Loss: 0.000209755 in Epoch 157
Epoch 167
Epoch 167, Loss: 0.000346497, Improvement: -0.000021594, Best Loss: 0.000209755 in Epoch 157
Epoch 168
Epoch 168, Loss: 0.000332541, Improvement: -0.000013957, Best Loss: 0.000209755 in Epoch 157
Epoch 169
A best model at epoch 169 has been saved with training error 0.000188242.
Epoch 169, Loss: 0.000313549, Improvement: -0.000018992, Best Loss: 0.000188242 in Epoch 169
Epoch 170
A best model at epoch 170 has been saved with training error 0.000162979.
Epoch 170, Loss: 0.000309095, Improvement: -0.000004453, Best Loss: 0.000162979 in Epoch 170
Epoch 171
Epoch 171, Loss: 0.000325838, Improvement: 0.000016742, Best Loss: 0.000162979 in Epoch 170
Epoch 172
Epoch 172, Loss: 0.000386698, Improvement: 0.000060860, Best Loss: 0.000162979 in Epoch 170
Epoch 173
Epoch 173, Loss: 0.000970940, Improvement: 0.000584242, Best Loss: 0.000162979 in Epoch 170
Epoch 174
Epoch 174, Loss: 0.001437243, Improvement: 0.000466303, Best Loss: 0.000162979 in Epoch 170
Epoch 175
Epoch 175, Loss: 0.000763010, Improvement: -0.000674233, Best Loss: 0.000162979 in Epoch 170
Epoch 176
Epoch 176, Loss: 0.000570636, Improvement: -0.000192373, Best Loss: 0.000162979 in Epoch 170
Epoch 177
Epoch 177, Loss: 0.000413401, Improvement: -0.000157235, Best Loss: 0.000162979 in Epoch 170
Epoch 178
Epoch 178, Loss: 0.000370847, Improvement: -0.000042554, Best Loss: 0.000162979 in Epoch 170
Epoch 179
Epoch 179, Loss: 0.000341863, Improvement: -0.000028984, Best Loss: 0.000162979 in Epoch 170
Epoch 180
Epoch 180, Loss: 0.000325287, Improvement: -0.000016576, Best Loss: 0.000162979 in Epoch 170
Epoch 181
Epoch 181, Loss: 0.000310479, Improvement: -0.000014808, Best Loss: 0.000162979 in Epoch 170
Epoch 182
Epoch 182, Loss: 0.000310018, Improvement: -0.000000461, Best Loss: 0.000162979 in Epoch 170
Epoch 183
Epoch 183, Loss: 0.000296481, Improvement: -0.000013537, Best Loss: 0.000162979 in Epoch 170
Epoch 184
Epoch 184, Loss: 0.000285967, Improvement: -0.000010515, Best Loss: 0.000162979 in Epoch 170
Epoch 185
Epoch 185, Loss: 0.000266727, Improvement: -0.000019240, Best Loss: 0.000162979 in Epoch 170
Epoch 186
A best model at epoch 186 has been saved with training error 0.000162646.
Epoch 186, Loss: 0.000263944, Improvement: -0.000002783, Best Loss: 0.000162646 in Epoch 186
Epoch 187
Epoch 187, Loss: 0.000258475, Improvement: -0.000005469, Best Loss: 0.000162646 in Epoch 186
Epoch 188
Epoch 188, Loss: 0.000249578, Improvement: -0.000008897, Best Loss: 0.000162646 in Epoch 186
Epoch 189
Epoch 189, Loss: 0.000326340, Improvement: 0.000076762, Best Loss: 0.000162646 in Epoch 186
Epoch 190
Epoch 190, Loss: 0.000603699, Improvement: 0.000277359, Best Loss: 0.000162646 in Epoch 186
Epoch 191
Epoch 191, Loss: 0.000546889, Improvement: -0.000056811, Best Loss: 0.000162646 in Epoch 186
Epoch 192
Epoch 192, Loss: 0.000627780, Improvement: 0.000080891, Best Loss: 0.000162646 in Epoch 186
Epoch 193
Epoch 193, Loss: 0.000468122, Improvement: -0.000159658, Best Loss: 0.000162646 in Epoch 186
Epoch 194
Epoch 194, Loss: 0.000322197, Improvement: -0.000145925, Best Loss: 0.000162646 in Epoch 186
Epoch 195
Epoch 195, Loss: 0.000307197, Improvement: -0.000015000, Best Loss: 0.000162646 in Epoch 186
Epoch 196
Epoch 196, Loss: 0.000360683, Improvement: 0.000053486, Best Loss: 0.000162646 in Epoch 186
Epoch 197
Epoch 197, Loss: 0.000279676, Improvement: -0.000081007, Best Loss: 0.000162646 in Epoch 186
Epoch 198
Epoch 198, Loss: 0.000260280, Improvement: -0.000019396, Best Loss: 0.000162646 in Epoch 186
Epoch 199
Epoch 199, Loss: 0.000244669, Improvement: -0.000015611, Best Loss: 0.000162646 in Epoch 186
Epoch 200
Model saving checkpoint: the model trained after epoch 200 has been saved with the training errors.
Epoch 200, Loss: 0.000242088, Improvement: -0.000002581, Best Loss: 0.000162646 in Epoch 186
Epoch 201
Epoch 201, Loss: 0.000254416, Improvement: 0.000012328, Best Loss: 0.000162646 in Epoch 186
Epoch 202
Epoch 202, Loss: 0.000271368, Improvement: 0.000016952, Best Loss: 0.000162646 in Epoch 186
Epoch 203
A best model at epoch 203 has been saved with training error 0.000154874.
A best model at epoch 203 has been saved with training error 0.000115616.
Epoch 203, Loss: 0.000250269, Improvement: -0.000021099, Best Loss: 0.000115616 in Epoch 203
Epoch 204
Epoch 204, Loss: 0.000230776, Improvement: -0.000019493, Best Loss: 0.000115616 in Epoch 203
Epoch 205
Epoch 205, Loss: 0.000259175, Improvement: 0.000028399, Best Loss: 0.000115616 in Epoch 203
Epoch 206
Epoch 206, Loss: 0.000605968, Improvement: 0.000346793, Best Loss: 0.000115616 in Epoch 203
Epoch 207
Epoch 207, Loss: 0.000483960, Improvement: -0.000122008, Best Loss: 0.000115616 in Epoch 203
Epoch 208
Epoch 208, Loss: 0.000288095, Improvement: -0.000195865, Best Loss: 0.000115616 in Epoch 203
Epoch 209
Epoch 209, Loss: 0.000256721, Improvement: -0.000031373, Best Loss: 0.000115616 in Epoch 203
Epoch 210
Epoch 210, Loss: 0.000229524, Improvement: -0.000027198, Best Loss: 0.000115616 in Epoch 203
Epoch 211
A best model at epoch 211 has been saved with training error 0.000114012.
Epoch 211, Loss: 0.000210283, Improvement: -0.000019241, Best Loss: 0.000114012 in Epoch 211
Epoch 212
A best model at epoch 212 has been saved with training error 0.000109157.
Epoch 212, Loss: 0.000212116, Improvement: 0.000001833, Best Loss: 0.000109157 in Epoch 212
Epoch 213
Epoch 213, Loss: 0.000282721, Improvement: 0.000070604, Best Loss: 0.000109157 in Epoch 212
Epoch 214
Epoch 214, Loss: 0.000575732, Improvement: 0.000293011, Best Loss: 0.000109157 in Epoch 212
Epoch 215
Epoch 215, Loss: 0.000542243, Improvement: -0.000033489, Best Loss: 0.000109157 in Epoch 212
Epoch 216
Epoch 216, Loss: 0.000403510, Improvement: -0.000138734, Best Loss: 0.000109157 in Epoch 212
Epoch 217
Epoch 217, Loss: 0.000382617, Improvement: -0.000020893, Best Loss: 0.000109157 in Epoch 212
Epoch 218
Epoch 218, Loss: 0.000298601, Improvement: -0.000084016, Best Loss: 0.000109157 in Epoch 212
Epoch 219
Epoch 219, Loss: 0.000246032, Improvement: -0.000052569, Best Loss: 0.000109157 in Epoch 212
Epoch 220
Epoch 220, Loss: 0.000212874, Improvement: -0.000033158, Best Loss: 0.000109157 in Epoch 212
Epoch 221
Epoch 221, Loss: 0.000200438, Improvement: -0.000012436, Best Loss: 0.000109157 in Epoch 212
Epoch 222
Epoch 222, Loss: 0.000185096, Improvement: -0.000015342, Best Loss: 0.000109157 in Epoch 212
Epoch 223
A best model at epoch 223 has been saved with training error 0.000103898.
Epoch 223, Loss: 0.000186640, Improvement: 0.000001545, Best Loss: 0.000103898 in Epoch 223
Epoch 224
Epoch 224, Loss: 0.000173417, Improvement: -0.000013224, Best Loss: 0.000103898 in Epoch 223
Epoch 225
Epoch 225, Loss: 0.000181761, Improvement: 0.000008344, Best Loss: 0.000103898 in Epoch 223
Epoch 226
Epoch 226, Loss: 0.000203615, Improvement: 0.000021854, Best Loss: 0.000103898 in Epoch 223
Epoch 227
Epoch 227, Loss: 0.000767739, Improvement: 0.000564124, Best Loss: 0.000103898 in Epoch 223
Epoch 228
Epoch 228, Loss: 0.000649981, Improvement: -0.000117758, Best Loss: 0.000103898 in Epoch 223
Epoch 229
Epoch 229, Loss: 0.000325704, Improvement: -0.000324277, Best Loss: 0.000103898 in Epoch 223
Epoch 230
Epoch 230, Loss: 0.000330688, Improvement: 0.000004984, Best Loss: 0.000103898 in Epoch 223
Epoch 231
Epoch 231, Loss: 0.000321663, Improvement: -0.000009025, Best Loss: 0.000103898 in Epoch 223
Epoch 232
Epoch 232, Loss: 0.000223117, Improvement: -0.000098546, Best Loss: 0.000103898 in Epoch 223
Epoch 233
Epoch 233, Loss: 0.000220375, Improvement: -0.000002742, Best Loss: 0.000103898 in Epoch 223
Epoch 234
Epoch 234, Loss: 0.000247263, Improvement: 0.000026887, Best Loss: 0.000103898 in Epoch 223
Epoch 235
Epoch 235, Loss: 0.000202791, Improvement: -0.000044472, Best Loss: 0.000103898 in Epoch 223
Epoch 236
Epoch 236, Loss: 0.000213032, Improvement: 0.000010242, Best Loss: 0.000103898 in Epoch 223
Epoch 237
Epoch 237, Loss: 0.000247683, Improvement: 0.000034651, Best Loss: 0.000103898 in Epoch 223
Epoch 238
Epoch 238, Loss: 0.000190747, Improvement: -0.000056937, Best Loss: 0.000103898 in Epoch 223
Epoch 239
Epoch 239, Loss: 0.000307805, Improvement: 0.000117058, Best Loss: 0.000103898 in Epoch 223
Epoch 240
Epoch 240, Loss: 0.000243405, Improvement: -0.000064400, Best Loss: 0.000103898 in Epoch 223
Epoch 241
Epoch 241, Loss: 0.000301431, Improvement: 0.000058026, Best Loss: 0.000103898 in Epoch 223
Epoch 242
Epoch 242, Loss: 0.000280582, Improvement: -0.000020849, Best Loss: 0.000103898 in Epoch 223
Epoch 243
Epoch 243, Loss: 0.000191203, Improvement: -0.000089379, Best Loss: 0.000103898 in Epoch 223
Epoch 244
Epoch 244, Loss: 0.000185750, Improvement: -0.000005453, Best Loss: 0.000103898 in Epoch 223
Epoch 245
Epoch 245, Loss: 0.000469871, Improvement: 0.000284121, Best Loss: 0.000103898 in Epoch 223
Epoch 246
Epoch 246, Loss: 0.000415508, Improvement: -0.000054363, Best Loss: 0.000103898 in Epoch 223
Epoch 247
Epoch 247, Loss: 0.000241568, Improvement: -0.000173940, Best Loss: 0.000103898 in Epoch 223
Epoch 248
Epoch 248, Loss: 0.000185825, Improvement: -0.000055743, Best Loss: 0.000103898 in Epoch 223
Epoch 249
A best model at epoch 249 has been saved with training error 0.000094979.
Epoch 249, Loss: 0.000155291, Improvement: -0.000030534, Best Loss: 0.000094979 in Epoch 249
Epoch 250
A best model at epoch 250 has been saved with training error 0.000090501.
Model saving checkpoint: the model trained after epoch 250 has been saved with the training errors.
Epoch 250, Loss: 0.000159989, Improvement: 0.000004699, Best Loss: 0.000090501 in Epoch 250
Epoch 251
Epoch 251, Loss: 0.000173278, Improvement: 0.000013288, Best Loss: 0.000090501 in Epoch 250
Epoch 252
Epoch 252, Loss: 0.000204343, Improvement: 0.000031066, Best Loss: 0.000090501 in Epoch 250
Epoch 253
Epoch 253, Loss: 0.000160507, Improvement: -0.000043836, Best Loss: 0.000090501 in Epoch 250
Epoch 254
Epoch 254, Loss: 0.000133252, Improvement: -0.000027255, Best Loss: 0.000090501 in Epoch 250
Epoch 255
Epoch 255, Loss: 0.000187089, Improvement: 0.000053837, Best Loss: 0.000090501 in Epoch 250
Epoch 256
A best model at epoch 256 has been saved with training error 0.000086118.
Epoch 256, Loss: 0.000179720, Improvement: -0.000007370, Best Loss: 0.000086118 in Epoch 256
Epoch 257
Epoch 257, Loss: 0.000374872, Improvement: 0.000195152, Best Loss: 0.000086118 in Epoch 256
Epoch 258
Epoch 258, Loss: 0.000313810, Improvement: -0.000061062, Best Loss: 0.000086118 in Epoch 256
Epoch 259
Epoch 259, Loss: 0.000233296, Improvement: -0.000080514, Best Loss: 0.000086118 in Epoch 256
Epoch 260
Epoch 260, Loss: 0.000243235, Improvement: 0.000009939, Best Loss: 0.000086118 in Epoch 256
Epoch 261
Epoch 261, Loss: 0.000236173, Improvement: -0.000007062, Best Loss: 0.000086118 in Epoch 256
Epoch 262
Epoch 262, Loss: 0.000169839, Improvement: -0.000066334, Best Loss: 0.000086118 in Epoch 256
Epoch 263
Epoch 263, Loss: 0.000143577, Improvement: -0.000026262, Best Loss: 0.000086118 in Epoch 256
Epoch 264
Epoch 264, Loss: 0.000144575, Improvement: 0.000000998, Best Loss: 0.000086118 in Epoch 256
Epoch 265
A best model at epoch 265 has been saved with training error 0.000083100.
Epoch 265, Loss: 0.000128464, Improvement: -0.000016111, Best Loss: 0.000083100 in Epoch 265
Epoch 266
Epoch 266, Loss: 0.000174796, Improvement: 0.000046332, Best Loss: 0.000083100 in Epoch 265
Epoch 267
Epoch 267, Loss: 0.000661221, Improvement: 0.000486426, Best Loss: 0.000083100 in Epoch 265
Epoch 268
Epoch 268, Loss: 0.000375921, Improvement: -0.000285300, Best Loss: 0.000083100 in Epoch 265
Epoch 269
Epoch 269, Loss: 0.000204734, Improvement: -0.000171187, Best Loss: 0.000083100 in Epoch 265
Epoch 270
A best model at epoch 270 has been saved with training error 0.000077969.
Epoch 270, Loss: 0.000132208, Improvement: -0.000072526, Best Loss: 0.000077969 in Epoch 270
Epoch 271
A best model at epoch 271 has been saved with training error 0.000071131.
Epoch 271, Loss: 0.000125767, Improvement: -0.000006442, Best Loss: 0.000071131 in Epoch 271
Epoch 272
Epoch 272, Loss: 0.000128561, Improvement: 0.000002795, Best Loss: 0.000071131 in Epoch 271
Epoch 273
A best model at epoch 273 has been saved with training error 0.000064778.
Epoch 273, Loss: 0.000116075, Improvement: -0.000012487, Best Loss: 0.000064778 in Epoch 273
Epoch 274
Epoch 274, Loss: 0.000121688, Improvement: 0.000005614, Best Loss: 0.000064778 in Epoch 273
Epoch 275
Epoch 275, Loss: 0.000135859, Improvement: 0.000014171, Best Loss: 0.000064778 in Epoch 273
Epoch 276
Epoch 276, Loss: 0.000137251, Improvement: 0.000001392, Best Loss: 0.000064778 in Epoch 273
Epoch 277
Epoch 277, Loss: 0.000142315, Improvement: 0.000005064, Best Loss: 0.000064778 in Epoch 273
Epoch 278
Epoch 278, Loss: 0.000175618, Improvement: 0.000033303, Best Loss: 0.000064778 in Epoch 273
Epoch 279
Epoch 279, Loss: 0.000179847, Improvement: 0.000004229, Best Loss: 0.000064778 in Epoch 273
Epoch 280
Epoch 280, Loss: 0.000130747, Improvement: -0.000049100, Best Loss: 0.000064778 in Epoch 273
Epoch 281
Epoch 281, Loss: 0.000127661, Improvement: -0.000003086, Best Loss: 0.000064778 in Epoch 273
Epoch 282
Epoch 282, Loss: 0.000212105, Improvement: 0.000084444, Best Loss: 0.000064778 in Epoch 273
Epoch 283
Epoch 283, Loss: 0.000345458, Improvement: 0.000133352, Best Loss: 0.000064778 in Epoch 273
Epoch 284
Epoch 284, Loss: 0.000238064, Improvement: -0.000107394, Best Loss: 0.000064778 in Epoch 273
Epoch 285
Epoch 285, Loss: 0.000157464, Improvement: -0.000080600, Best Loss: 0.000064778 in Epoch 273
Epoch 286
Epoch 286, Loss: 0.000119016, Improvement: -0.000038448, Best Loss: 0.000064778 in Epoch 273
Epoch 287
A best model at epoch 287 has been saved with training error 0.000058996.
Epoch 287, Loss: 0.000094087, Improvement: -0.000024929, Best Loss: 0.000058996 in Epoch 287
Epoch 288
Epoch 288, Loss: 0.000170040, Improvement: 0.000075953, Best Loss: 0.000058996 in Epoch 287
Epoch 289
Epoch 289, Loss: 0.000247277, Improvement: 0.000077237, Best Loss: 0.000058996 in Epoch 287
Epoch 290
Epoch 290, Loss: 0.000219704, Improvement: -0.000027573, Best Loss: 0.000058996 in Epoch 287
Epoch 291
Epoch 291, Loss: 0.000183194, Improvement: -0.000036510, Best Loss: 0.000058996 in Epoch 287
Epoch 292
Epoch 292, Loss: 0.000143806, Improvement: -0.000039388, Best Loss: 0.000058996 in Epoch 287
Epoch 293
Epoch 293, Loss: 0.000106591, Improvement: -0.000037215, Best Loss: 0.000058996 in Epoch 287
Epoch 294
Epoch 294, Loss: 0.000107014, Improvement: 0.000000423, Best Loss: 0.000058996 in Epoch 287
Epoch 295
A best model at epoch 295 has been saved with training error 0.000056349.
Epoch 295, Loss: 0.000091218, Improvement: -0.000015796, Best Loss: 0.000056349 in Epoch 295
Epoch 296
Epoch 296, Loss: 0.000104033, Improvement: 0.000012815, Best Loss: 0.000056349 in Epoch 295
Epoch 297
Epoch 297, Loss: 0.000123939, Improvement: 0.000019906, Best Loss: 0.000056349 in Epoch 295
Epoch 298
Epoch 298, Loss: 0.000154419, Improvement: 0.000030480, Best Loss: 0.000056349 in Epoch 295
Epoch 299
Epoch 299, Loss: 0.000153985, Improvement: -0.000000434, Best Loss: 0.000056349 in Epoch 295
Epoch 300
Model saving checkpoint: the model trained after epoch 300 has been saved with the training errors.
Epoch 300, Loss: 0.000141456, Improvement: -0.000012530, Best Loss: 0.000056349 in Epoch 295
Epoch 301
Epoch 301, Loss: 0.000165375, Improvement: 0.000023919, Best Loss: 0.000056349 in Epoch 295
Epoch 302
Epoch 302, Loss: 0.000205791, Improvement: 0.000040416, Best Loss: 0.000056349 in Epoch 295
Epoch 303
Epoch 303, Loss: 0.000213067, Improvement: 0.000007276, Best Loss: 0.000056349 in Epoch 295
Epoch 304
Epoch 304, Loss: 0.000142613, Improvement: -0.000070454, Best Loss: 0.000056349 in Epoch 295
Epoch 305
Epoch 305, Loss: 0.000151509, Improvement: 0.000008896, Best Loss: 0.000056349 in Epoch 295
Epoch 306
Epoch 306, Loss: 0.000172338, Improvement: 0.000020829, Best Loss: 0.000056349 in Epoch 295
Epoch 307
Epoch 307, Loss: 0.000194971, Improvement: 0.000022634, Best Loss: 0.000056349 in Epoch 295
Epoch 308
Epoch 308, Loss: 0.000336908, Improvement: 0.000141937, Best Loss: 0.000056349 in Epoch 295
Epoch 309
Epoch 309, Loss: 0.000397421, Improvement: 0.000060513, Best Loss: 0.000056349 in Epoch 295
Epoch 310
Epoch 310, Loss: 0.000224733, Improvement: -0.000172687, Best Loss: 0.000056349 in Epoch 295
Epoch 311
Epoch 311, Loss: 0.000158152, Improvement: -0.000066582, Best Loss: 0.000056349 in Epoch 295
Epoch 312
Epoch 312, Loss: 0.000214577, Improvement: 0.000056425, Best Loss: 0.000056349 in Epoch 295
Epoch 313
Epoch 313, Loss: 0.000141709, Improvement: -0.000072867, Best Loss: 0.000056349 in Epoch 295
Epoch 314
Epoch 314, Loss: 0.000101818, Improvement: -0.000039891, Best Loss: 0.000056349 in Epoch 295
Epoch 315
Epoch 315, Loss: 0.000082567, Improvement: -0.000019252, Best Loss: 0.000056349 in Epoch 295
Epoch 316
Epoch 316, Loss: 0.000092391, Improvement: 0.000009824, Best Loss: 0.000056349 in Epoch 295
Epoch 317
Epoch 317, Loss: 0.000113133, Improvement: 0.000020742, Best Loss: 0.000056349 in Epoch 295
Epoch 318
Epoch 318, Loss: 0.000091215, Improvement: -0.000021918, Best Loss: 0.000056349 in Epoch 295
Epoch 319
A best model at epoch 319 has been saved with training error 0.000055185.
Epoch 319, Loss: 0.000082834, Improvement: -0.000008381, Best Loss: 0.000055185 in Epoch 319
Epoch 320
Epoch 320, Loss: 0.000125614, Improvement: 0.000042780, Best Loss: 0.000055185 in Epoch 319
Epoch 321
Epoch 321, Loss: 0.000311827, Improvement: 0.000186213, Best Loss: 0.000055185 in Epoch 319
Epoch 322
Epoch 322, Loss: 0.000369672, Improvement: 0.000057845, Best Loss: 0.000055185 in Epoch 319
Epoch 323
Epoch 323, Loss: 0.000158691, Improvement: -0.000210981, Best Loss: 0.000055185 in Epoch 319
Epoch 324
Epoch 324, Loss: 0.000124893, Improvement: -0.000033798, Best Loss: 0.000055185 in Epoch 319
Epoch 325
Epoch 325, Loss: 0.000091203, Improvement: -0.000033690, Best Loss: 0.000055185 in Epoch 319
Epoch 326
Epoch 326, Loss: 0.000084469, Improvement: -0.000006734, Best Loss: 0.000055185 in Epoch 319
Epoch 327
A best model at epoch 327 has been saved with training error 0.000048937.
Epoch 327, Loss: 0.000079815, Improvement: -0.000004653, Best Loss: 0.000048937 in Epoch 327
Epoch 328
Epoch 328, Loss: 0.000080082, Improvement: 0.000000267, Best Loss: 0.000048937 in Epoch 327
Epoch 329
Epoch 329, Loss: 0.000078894, Improvement: -0.000001188, Best Loss: 0.000048937 in Epoch 327
Epoch 330
A best model at epoch 330 has been saved with training error 0.000045049.
Epoch 330, Loss: 0.000070664, Improvement: -0.000008231, Best Loss: 0.000045049 in Epoch 330
Epoch 331
Epoch 331, Loss: 0.000134353, Improvement: 0.000063689, Best Loss: 0.000045049 in Epoch 330
Epoch 332
Epoch 332, Loss: 0.000158344, Improvement: 0.000023991, Best Loss: 0.000045049 in Epoch 330
Epoch 333
Epoch 333, Loss: 0.000122093, Improvement: -0.000036251, Best Loss: 0.000045049 in Epoch 330
Epoch 334
Epoch 334, Loss: 0.000146721, Improvement: 0.000024628, Best Loss: 0.000045049 in Epoch 330
Epoch 335
Epoch 335, Loss: 0.000174190, Improvement: 0.000027469, Best Loss: 0.000045049 in Epoch 330
Epoch 336
Epoch 336, Loss: 0.000172949, Improvement: -0.000001241, Best Loss: 0.000045049 in Epoch 330
Epoch 337
Epoch 337, Loss: 0.000141705, Improvement: -0.000031244, Best Loss: 0.000045049 in Epoch 330
Epoch 338
Epoch 338, Loss: 0.000104817, Improvement: -0.000036888, Best Loss: 0.000045049 in Epoch 330
Epoch 339
A best model at epoch 339 has been saved with training error 0.000044625.
Epoch 339, Loss: 0.000083159, Improvement: -0.000021658, Best Loss: 0.000044625 in Epoch 339
Epoch 340
Epoch 340, Loss: 0.000087035, Improvement: 0.000003877, Best Loss: 0.000044625 in Epoch 339
Epoch 341
Epoch 341, Loss: 0.000154697, Improvement: 0.000067662, Best Loss: 0.000044625 in Epoch 339
Epoch 342
Epoch 342, Loss: 0.000170100, Improvement: 0.000015403, Best Loss: 0.000044625 in Epoch 339
Epoch 343
Epoch 343, Loss: 0.000083173, Improvement: -0.000086927, Best Loss: 0.000044625 in Epoch 339
Epoch 344
Epoch 344, Loss: 0.000065511, Improvement: -0.000017662, Best Loss: 0.000044625 in Epoch 339
Epoch 345
A best model at epoch 345 has been saved with training error 0.000042197.
Epoch 345, Loss: 0.000053649, Improvement: -0.000011861, Best Loss: 0.000042197 in Epoch 345
Epoch 346
A best model at epoch 346 has been saved with training error 0.000032140.
Epoch 346, Loss: 0.000050246, Improvement: -0.000003403, Best Loss: 0.000032140 in Epoch 346
Epoch 347
Epoch 347, Loss: 0.000068387, Improvement: 0.000018141, Best Loss: 0.000032140 in Epoch 346
Epoch 348
Epoch 348, Loss: 0.000081446, Improvement: 0.000013059, Best Loss: 0.000032140 in Epoch 346
Epoch 349
Epoch 349, Loss: 0.000208316, Improvement: 0.000126870, Best Loss: 0.000032140 in Epoch 346
Epoch 350
Model saving checkpoint: the model trained after epoch 350 has been saved with the training errors.
Epoch 350, Loss: 0.000175662, Improvement: -0.000032654, Best Loss: 0.000032140 in Epoch 346
Epoch 351
Epoch 351, Loss: 0.000175892, Improvement: 0.000000231, Best Loss: 0.000032140 in Epoch 346
Epoch 352
Epoch 352, Loss: 0.000129053, Improvement: -0.000046839, Best Loss: 0.000032140 in Epoch 346
Epoch 353
Epoch 353, Loss: 0.000082179, Improvement: -0.000046875, Best Loss: 0.000032140 in Epoch 346
Epoch 354
Epoch 354, Loss: 0.000108495, Improvement: 0.000026316, Best Loss: 0.000032140 in Epoch 346
Epoch 355
Epoch 355, Loss: 0.000090903, Improvement: -0.000017593, Best Loss: 0.000032140 in Epoch 346
Epoch 356
Epoch 356, Loss: 0.000070823, Improvement: -0.000020080, Best Loss: 0.000032140 in Epoch 346
Epoch 357
Epoch 357, Loss: 0.000081651, Improvement: 0.000010829, Best Loss: 0.000032140 in Epoch 346
Epoch 358
Epoch 358, Loss: 0.000141061, Improvement: 0.000059410, Best Loss: 0.000032140 in Epoch 346
Epoch 359
Epoch 359, Loss: 0.000110653, Improvement: -0.000030408, Best Loss: 0.000032140 in Epoch 346
Epoch 360
Epoch 360, Loss: 0.000105944, Improvement: -0.000004709, Best Loss: 0.000032140 in Epoch 346
Epoch 361
Epoch 361, Loss: 0.000103738, Improvement: -0.000002206, Best Loss: 0.000032140 in Epoch 346
Epoch 362
Epoch 362, Loss: 0.000061904, Improvement: -0.000041833, Best Loss: 0.000032140 in Epoch 346
Epoch 363
Epoch 363, Loss: 0.000194150, Improvement: 0.000132245, Best Loss: 0.000032140 in Epoch 346
Epoch 364
Epoch 364, Loss: 0.000367794, Improvement: 0.000173644, Best Loss: 0.000032140 in Epoch 346
Epoch 365
Epoch 365, Loss: 0.000172203, Improvement: -0.000195591, Best Loss: 0.000032140 in Epoch 346
Epoch 366
Epoch 366, Loss: 0.000102949, Improvement: -0.000069254, Best Loss: 0.000032140 in Epoch 346
Epoch 367
Epoch 367, Loss: 0.000053899, Improvement: -0.000049050, Best Loss: 0.000032140 in Epoch 346
Epoch 368
Epoch 368, Loss: 0.000047094, Improvement: -0.000006805, Best Loss: 0.000032140 in Epoch 346
Epoch 369
A best model at epoch 369 has been saved with training error 0.000031427.
Epoch 369, Loss: 0.000043452, Improvement: -0.000003642, Best Loss: 0.000031427 in Epoch 369
Epoch 370
A best model at epoch 370 has been saved with training error 0.000028062.
Epoch 370, Loss: 0.000041719, Improvement: -0.000001733, Best Loss: 0.000028062 in Epoch 370
Epoch 371
Epoch 371, Loss: 0.000036277, Improvement: -0.000005442, Best Loss: 0.000028062 in Epoch 370
Epoch 372
A best model at epoch 372 has been saved with training error 0.000025827.
A best model at epoch 372 has been saved with training error 0.000023992.
Epoch 372, Loss: 0.000035454, Improvement: -0.000000823, Best Loss: 0.000023992 in Epoch 372
Epoch 373
Epoch 373, Loss: 0.000034050, Improvement: -0.000001404, Best Loss: 0.000023992 in Epoch 372
Epoch 374
Epoch 374, Loss: 0.000032824, Improvement: -0.000001226, Best Loss: 0.000023992 in Epoch 372
Epoch 375
Epoch 375, Loss: 0.000039794, Improvement: 0.000006969, Best Loss: 0.000023992 in Epoch 372
Epoch 376
Epoch 376, Loss: 0.000058196, Improvement: 0.000018402, Best Loss: 0.000023992 in Epoch 372
Epoch 377
Epoch 377, Loss: 0.000051375, Improvement: -0.000006821, Best Loss: 0.000023992 in Epoch 372
Epoch 378
Epoch 378, Loss: 0.000070253, Improvement: 0.000018878, Best Loss: 0.000023992 in Epoch 372
Epoch 379
Epoch 379, Loss: 0.000060190, Improvement: -0.000010063, Best Loss: 0.000023992 in Epoch 372
Epoch 380
Epoch 380, Loss: 0.000046201, Improvement: -0.000013989, Best Loss: 0.000023992 in Epoch 372
Epoch 381
Epoch 381, Loss: 0.000040172, Improvement: -0.000006029, Best Loss: 0.000023992 in Epoch 372
Epoch 382
Epoch 382, Loss: 0.000045338, Improvement: 0.000005166, Best Loss: 0.000023992 in Epoch 372
Epoch 383
Epoch 383, Loss: 0.000056976, Improvement: 0.000011638, Best Loss: 0.000023992 in Epoch 372
Epoch 384
Epoch 384, Loss: 0.000057747, Improvement: 0.000000771, Best Loss: 0.000023992 in Epoch 372
Epoch 385
Epoch 385, Loss: 0.000070058, Improvement: 0.000012312, Best Loss: 0.000023992 in Epoch 372
Epoch 386
Epoch 386, Loss: 0.000171185, Improvement: 0.000101127, Best Loss: 0.000023992 in Epoch 372
Epoch 387
Epoch 387, Loss: 0.000129399, Improvement: -0.000041787, Best Loss: 0.000023992 in Epoch 372
Epoch 388
Epoch 388, Loss: 0.000097637, Improvement: -0.000031762, Best Loss: 0.000023992 in Epoch 372
Epoch 389
Epoch 389, Loss: 0.000084075, Improvement: -0.000013562, Best Loss: 0.000023992 in Epoch 372
Epoch 390
Epoch 390, Loss: 0.000055550, Improvement: -0.000028525, Best Loss: 0.000023992 in Epoch 372
Epoch 391
Epoch 391, Loss: 0.000064480, Improvement: 0.000008930, Best Loss: 0.000023992 in Epoch 372
Epoch 392
Epoch 392, Loss: 0.000118777, Improvement: 0.000054297, Best Loss: 0.000023992 in Epoch 372
Epoch 393
Epoch 393, Loss: 0.000161593, Improvement: 0.000042815, Best Loss: 0.000023992 in Epoch 372
Epoch 394
Epoch 394, Loss: 0.000099179, Improvement: -0.000062414, Best Loss: 0.000023992 in Epoch 372
Epoch 395
Epoch 395, Loss: 0.000087837, Improvement: -0.000011342, Best Loss: 0.000023992 in Epoch 372
Epoch 396
Epoch 396, Loss: 0.000053627, Improvement: -0.000034209, Best Loss: 0.000023992 in Epoch 372
Epoch 397
Epoch 397, Loss: 0.000034529, Improvement: -0.000019098, Best Loss: 0.000023992 in Epoch 372
Epoch 398
Epoch 398, Loss: 0.000035662, Improvement: 0.000001133, Best Loss: 0.000023992 in Epoch 372
Epoch 399
Epoch 399, Loss: 0.000077893, Improvement: 0.000042231, Best Loss: 0.000023992 in Epoch 372
Epoch 400
Model saving checkpoint: the model trained after epoch 400 has been saved with the training errors.
Epoch 400, Loss: 0.000137679, Improvement: 0.000059786, Best Loss: 0.000023992 in Epoch 372
Epoch 401
Epoch 401, Loss: 0.000111677, Improvement: -0.000026002, Best Loss: 0.000023992 in Epoch 372
Epoch 402
Epoch 402, Loss: 0.000062533, Improvement: -0.000049144, Best Loss: 0.000023992 in Epoch 372
Epoch 403
Epoch 403, Loss: 0.000104621, Improvement: 0.000042088, Best Loss: 0.000023992 in Epoch 372
Epoch 404
Epoch 404, Loss: 0.000101131, Improvement: -0.000003490, Best Loss: 0.000023992 in Epoch 372
Epoch 405
Epoch 405, Loss: 0.000057723, Improvement: -0.000043408, Best Loss: 0.000023992 in Epoch 372
Epoch 406
Epoch 406, Loss: 0.000043872, Improvement: -0.000013850, Best Loss: 0.000023992 in Epoch 372
Epoch 407
Epoch 407, Loss: 0.000039535, Improvement: -0.000004338, Best Loss: 0.000023992 in Epoch 372
Epoch 408
Epoch 408, Loss: 0.000044844, Improvement: 0.000005310, Best Loss: 0.000023992 in Epoch 372
Epoch 409
Epoch 409, Loss: 0.000046395, Improvement: 0.000001550, Best Loss: 0.000023992 in Epoch 372
Epoch 410
Epoch 410, Loss: 0.000056072, Improvement: 0.000009678, Best Loss: 0.000023992 in Epoch 372
Epoch 411
Epoch 411, Loss: 0.000058168, Improvement: 0.000002096, Best Loss: 0.000023992 in Epoch 372
Epoch 412
Epoch 412, Loss: 0.000046519, Improvement: -0.000011650, Best Loss: 0.000023992 in Epoch 372
Epoch 413
Epoch 413, Loss: 0.000043864, Improvement: -0.000002655, Best Loss: 0.000023992 in Epoch 372
Epoch 414
Epoch 414, Loss: 0.000050724, Improvement: 0.000006861, Best Loss: 0.000023992 in Epoch 372
Epoch 415
Epoch 415, Loss: 0.000062220, Improvement: 0.000011496, Best Loss: 0.000023992 in Epoch 372
Epoch 416
Epoch 416, Loss: 0.000056488, Improvement: -0.000005733, Best Loss: 0.000023992 in Epoch 372
Epoch 417
A best model at epoch 417 has been saved with training error 0.000023496.
Epoch 417, Loss: 0.000072233, Improvement: 0.000015745, Best Loss: 0.000023496 in Epoch 417
Epoch 418
Epoch 418, Loss: 0.000130242, Improvement: 0.000058009, Best Loss: 0.000023496 in Epoch 417
Epoch 419
Epoch 419, Loss: 0.000122591, Improvement: -0.000007650, Best Loss: 0.000023496 in Epoch 417
Epoch 420
Epoch 420, Loss: 0.000115520, Improvement: -0.000007071, Best Loss: 0.000023496 in Epoch 417
Epoch 421
Epoch 421, Loss: 0.000069810, Improvement: -0.000045710, Best Loss: 0.000023496 in Epoch 417
Epoch 422
Epoch 422, Loss: 0.000124409, Improvement: 0.000054599, Best Loss: 0.000023496 in Epoch 417
Epoch 423
Epoch 423, Loss: 0.000070511, Improvement: -0.000053898, Best Loss: 0.000023496 in Epoch 417
Epoch 424
A best model at epoch 424 has been saved with training error 0.000022556.
Epoch 424, Loss: 0.000038152, Improvement: -0.000032359, Best Loss: 0.000022556 in Epoch 424
Epoch 425
A best model at epoch 425 has been saved with training error 0.000021847.
A best model at epoch 425 has been saved with training error 0.000019592.
Epoch 425, Loss: 0.000030419, Improvement: -0.000007733, Best Loss: 0.000019592 in Epoch 425
Epoch 426
Epoch 426, Loss: 0.000030222, Improvement: -0.000000197, Best Loss: 0.000019592 in Epoch 425
Epoch 427
Epoch 427, Loss: 0.000028743, Improvement: -0.000001479, Best Loss: 0.000019592 in Epoch 425
Epoch 428
Epoch 428, Loss: 0.000048607, Improvement: 0.000019864, Best Loss: 0.000019592 in Epoch 425
Epoch 429
Epoch 429, Loss: 0.000070021, Improvement: 0.000021414, Best Loss: 0.000019592 in Epoch 425
Epoch 430
Epoch 430, Loss: 0.000062598, Improvement: -0.000007423, Best Loss: 0.000019592 in Epoch 425
Epoch 431
Epoch 431, Loss: 0.000111546, Improvement: 0.000048948, Best Loss: 0.000019592 in Epoch 425
Epoch 432
Epoch 432, Loss: 0.000148597, Improvement: 0.000037051, Best Loss: 0.000019592 in Epoch 425
Epoch 433
Epoch 433, Loss: 0.000114305, Improvement: -0.000034291, Best Loss: 0.000019592 in Epoch 425
Epoch 434
Epoch 434, Loss: 0.000096119, Improvement: -0.000018187, Best Loss: 0.000019592 in Epoch 425
Epoch 435
Epoch 435, Loss: 0.000053016, Improvement: -0.000043102, Best Loss: 0.000019592 in Epoch 425
Epoch 436
Epoch 436, Loss: 0.000086512, Improvement: 0.000033496, Best Loss: 0.000019592 in Epoch 425
Epoch 437
Epoch 437, Loss: 0.000077582, Improvement: -0.000008930, Best Loss: 0.000019592 in Epoch 425
Epoch 438
Epoch 438, Loss: 0.000060960, Improvement: -0.000016621, Best Loss: 0.000019592 in Epoch 425
Epoch 439
Epoch 439, Loss: 0.000069892, Improvement: 0.000008932, Best Loss: 0.000019592 in Epoch 425
Epoch 440
Epoch 440, Loss: 0.000057354, Improvement: -0.000012538, Best Loss: 0.000019592 in Epoch 425
Epoch 441
A best model at epoch 441 has been saved with training error 0.000016571.
Epoch 441, Loss: 0.000033435, Improvement: -0.000023919, Best Loss: 0.000016571 in Epoch 441
Epoch 442
Epoch 442, Loss: 0.000025905, Improvement: -0.000007530, Best Loss: 0.000016571 in Epoch 441
Epoch 443
Epoch 443, Loss: 0.000028081, Improvement: 0.000002176, Best Loss: 0.000016571 in Epoch 441
Epoch 444
Epoch 444, Loss: 0.000035883, Improvement: 0.000007802, Best Loss: 0.000016571 in Epoch 441
Epoch 445
Epoch 445, Loss: 0.000043570, Improvement: 0.000007687, Best Loss: 0.000016571 in Epoch 441
Epoch 446
A best model at epoch 446 has been saved with training error 0.000012523.
Epoch 446, Loss: 0.000026327, Improvement: -0.000017243, Best Loss: 0.000012523 in Epoch 446
Epoch 447
Epoch 447, Loss: 0.000024299, Improvement: -0.000002028, Best Loss: 0.000012523 in Epoch 446
Epoch 448
Epoch 448, Loss: 0.000026982, Improvement: 0.000002683, Best Loss: 0.000012523 in Epoch 446
Epoch 449
Epoch 449, Loss: 0.000063011, Improvement: 0.000036029, Best Loss: 0.000012523 in Epoch 446
Epoch 450
Model saving checkpoint: the model trained after epoch 450 has been saved with the training errors.
Epoch 450, Loss: 0.000166706, Improvement: 0.000103695, Best Loss: 0.000012523 in Epoch 446
Epoch 451
Epoch 451, Loss: 0.000107828, Improvement: -0.000058878, Best Loss: 0.000012523 in Epoch 446
Epoch 452
Epoch 452, Loss: 0.000037827, Improvement: -0.000070001, Best Loss: 0.000012523 in Epoch 446
Epoch 453
Epoch 453, Loss: 0.000023362, Improvement: -0.000014465, Best Loss: 0.000012523 in Epoch 446
Epoch 454
Epoch 454, Loss: 0.000019917, Improvement: -0.000003445, Best Loss: 0.000012523 in Epoch 446
Epoch 455
A best model at epoch 455 has been saved with training error 0.000012481.
Epoch 455, Loss: 0.000017483, Improvement: -0.000002434, Best Loss: 0.000012481 in Epoch 455
Epoch 456
A best model at epoch 456 has been saved with training error 0.000011978.
Epoch 456, Loss: 0.000017164, Improvement: -0.000000319, Best Loss: 0.000011978 in Epoch 456
Epoch 457
Epoch 457, Loss: 0.000021849, Improvement: 0.000004685, Best Loss: 0.000011978 in Epoch 456
Epoch 458
A best model at epoch 458 has been saved with training error 0.000011737.
A best model at epoch 458 has been saved with training error 0.000011334.
Epoch 458, Loss: 0.000019054, Improvement: -0.000002795, Best Loss: 0.000011334 in Epoch 458
Epoch 459
Epoch 459, Loss: 0.000018511, Improvement: -0.000000542, Best Loss: 0.000011334 in Epoch 458
Epoch 460
Epoch 460, Loss: 0.000018593, Improvement: 0.000000082, Best Loss: 0.000011334 in Epoch 458
Epoch 461
A best model at epoch 461 has been saved with training error 0.000010830.
A best model at epoch 461 has been saved with training error 0.000010465.
Epoch 461, Loss: 0.000016236, Improvement: -0.000002357, Best Loss: 0.000010465 in Epoch 461
Epoch 462
Epoch 462, Loss: 0.000017219, Improvement: 0.000000983, Best Loss: 0.000010465 in Epoch 461
Epoch 463
Epoch 463, Loss: 0.000017265, Improvement: 0.000000046, Best Loss: 0.000010465 in Epoch 461
Epoch 464
Epoch 464, Loss: 0.000025522, Improvement: 0.000008257, Best Loss: 0.000010465 in Epoch 461
Epoch 465
Epoch 465, Loss: 0.000024002, Improvement: -0.000001520, Best Loss: 0.000010465 in Epoch 461
Epoch 466
Epoch 466, Loss: 0.000089664, Improvement: 0.000065662, Best Loss: 0.000010465 in Epoch 461
Epoch 467
Epoch 467, Loss: 0.000091056, Improvement: 0.000001392, Best Loss: 0.000010465 in Epoch 461
Epoch 468
Epoch 468, Loss: 0.000061539, Improvement: -0.000029518, Best Loss: 0.000010465 in Epoch 461
Epoch 469
Epoch 469, Loss: 0.000048835, Improvement: -0.000012704, Best Loss: 0.000010465 in Epoch 461
Epoch 470
Epoch 470, Loss: 0.000048706, Improvement: -0.000000129, Best Loss: 0.000010465 in Epoch 461
Epoch 471
Epoch 471, Loss: 0.000050835, Improvement: 0.000002128, Best Loss: 0.000010465 in Epoch 461
Epoch 472
Epoch 472, Loss: 0.000033023, Improvement: -0.000017811, Best Loss: 0.000010465 in Epoch 461
Epoch 473
Epoch 473, Loss: 0.000050133, Improvement: 0.000017110, Best Loss: 0.000010465 in Epoch 461
Epoch 474
Epoch 474, Loss: 0.000112211, Improvement: 0.000062077, Best Loss: 0.000010465 in Epoch 461
Epoch 475
Epoch 475, Loss: 0.000151316, Improvement: 0.000039106, Best Loss: 0.000010465 in Epoch 461
Epoch 476
Epoch 476, Loss: 0.000156235, Improvement: 0.000004919, Best Loss: 0.000010465 in Epoch 461
Epoch 477
Epoch 477, Loss: 0.000082076, Improvement: -0.000074160, Best Loss: 0.000010465 in Epoch 461
Epoch 478
Epoch 478, Loss: 0.000063704, Improvement: -0.000018372, Best Loss: 0.000010465 in Epoch 461
Epoch 479
Epoch 479, Loss: 0.000085851, Improvement: 0.000022147, Best Loss: 0.000010465 in Epoch 461
Epoch 480
Epoch 480, Loss: 0.000076405, Improvement: -0.000009446, Best Loss: 0.000010465 in Epoch 461
Epoch 481
Epoch 481, Loss: 0.000045778, Improvement: -0.000030627, Best Loss: 0.000010465 in Epoch 461
Epoch 482
Epoch 482, Loss: 0.000026080, Improvement: -0.000019699, Best Loss: 0.000010465 in Epoch 461
Epoch 483
Epoch 483, Loss: 0.000029248, Improvement: 0.000003169, Best Loss: 0.000010465 in Epoch 461
Epoch 484
Epoch 484, Loss: 0.000024752, Improvement: -0.000004497, Best Loss: 0.000010465 in Epoch 461
Epoch 485
Epoch 485, Loss: 0.000027100, Improvement: 0.000002348, Best Loss: 0.000010465 in Epoch 461
Epoch 486
Epoch 486, Loss: 0.000023120, Improvement: -0.000003980, Best Loss: 0.000010465 in Epoch 461
Epoch 487
A best model at epoch 487 has been saved with training error 0.000008975.
Epoch 487, Loss: 0.000016933, Improvement: -0.000006187, Best Loss: 0.000008975 in Epoch 487
Epoch 488
Epoch 488, Loss: 0.000018915, Improvement: 0.000001981, Best Loss: 0.000008975 in Epoch 487
Epoch 489
Epoch 489, Loss: 0.000019394, Improvement: 0.000000480, Best Loss: 0.000008975 in Epoch 487
Epoch 490
Epoch 490, Loss: 0.000016757, Improvement: -0.000002638, Best Loss: 0.000008975 in Epoch 487
Epoch 491
Epoch 491, Loss: 0.000013480, Improvement: -0.000003277, Best Loss: 0.000008975 in Epoch 487
Epoch 492
A best model at epoch 492 has been saved with training error 0.000008537.
Epoch 492, Loss: 0.000014311, Improvement: 0.000000831, Best Loss: 0.000008537 in Epoch 492
Epoch 493
Epoch 493, Loss: 0.000014329, Improvement: 0.000000018, Best Loss: 0.000008537 in Epoch 492
Epoch 494
Epoch 494, Loss: 0.000019191, Improvement: 0.000004863, Best Loss: 0.000008537 in Epoch 492
Epoch 495
Epoch 495, Loss: 0.000018133, Improvement: -0.000001058, Best Loss: 0.000008537 in Epoch 492
Epoch 496
Epoch 496, Loss: 0.000019144, Improvement: 0.000001011, Best Loss: 0.000008537 in Epoch 492
Epoch 497
Epoch 497, Loss: 0.000042217, Improvement: 0.000023073, Best Loss: 0.000008537 in Epoch 492
Epoch 498
Epoch 498, Loss: 0.000031589, Improvement: -0.000010627, Best Loss: 0.000008537 in Epoch 492
Epoch 499
Epoch 499, Loss: 0.000045253, Improvement: 0.000013664, Best Loss: 0.000008537 in Epoch 492
Epoch 500
Model saving checkpoint: the model trained after epoch 500 has been saved with the training errors.
Epoch 500, Loss: 0.000064206, Improvement: 0.000018952, Best Loss: 0.000008537 in Epoch 492
Epoch 501
Epoch 501, Loss: 0.000086051, Improvement: 0.000021845, Best Loss: 0.000008537 in Epoch 492
Epoch 502
Epoch 502, Loss: 0.000113971, Improvement: 0.000027919, Best Loss: 0.000008537 in Epoch 492
Epoch 503
Epoch 503, Loss: 0.000110938, Improvement: -0.000003033, Best Loss: 0.000008537 in Epoch 492
Epoch 504
Epoch 504, Loss: 0.000075139, Improvement: -0.000035799, Best Loss: 0.000008537 in Epoch 492
Epoch 505
Epoch 505, Loss: 0.000046115, Improvement: -0.000029024, Best Loss: 0.000008537 in Epoch 492
Epoch 506
Epoch 506, Loss: 0.000032365, Improvement: -0.000013750, Best Loss: 0.000008537 in Epoch 492
Epoch 507
Epoch 507, Loss: 0.000026179, Improvement: -0.000006186, Best Loss: 0.000008537 in Epoch 492
Epoch 508
Epoch 508, Loss: 0.000034688, Improvement: 0.000008509, Best Loss: 0.000008537 in Epoch 492
Epoch 509
Epoch 509, Loss: 0.000057371, Improvement: 0.000022683, Best Loss: 0.000008537 in Epoch 492
Epoch 510
Epoch 510, Loss: 0.000211466, Improvement: 0.000154096, Best Loss: 0.000008537 in Epoch 492
Epoch 511
Epoch 511, Loss: 0.000172652, Improvement: -0.000038815, Best Loss: 0.000008537 in Epoch 492
Epoch 512
Epoch 512, Loss: 0.000057846, Improvement: -0.000114805, Best Loss: 0.000008537 in Epoch 492
Epoch 513
Epoch 513, Loss: 0.000023645, Improvement: -0.000034202, Best Loss: 0.000008537 in Epoch 492
Epoch 514
Epoch 514, Loss: 0.000015703, Improvement: -0.000007941, Best Loss: 0.000008537 in Epoch 492
Epoch 515
Epoch 515, Loss: 0.000013665, Improvement: -0.000002038, Best Loss: 0.000008537 in Epoch 492
Epoch 516
Epoch 516, Loss: 0.000012903, Improvement: -0.000000762, Best Loss: 0.000008537 in Epoch 492
Epoch 517
A best model at epoch 517 has been saved with training error 0.000008165.
Epoch 517, Loss: 0.000011757, Improvement: -0.000001146, Best Loss: 0.000008165 in Epoch 517
Epoch 518
A best model at epoch 518 has been saved with training error 0.000008021.
A best model at epoch 518 has been saved with training error 0.000006606.
Epoch 518, Loss: 0.000011169, Improvement: -0.000000588, Best Loss: 0.000006606 in Epoch 518
Epoch 519
Epoch 519, Loss: 0.000010972, Improvement: -0.000000197, Best Loss: 0.000006606 in Epoch 518
Epoch 520
Epoch 520, Loss: 0.000011175, Improvement: 0.000000203, Best Loss: 0.000006606 in Epoch 518
Epoch 521
Epoch 521, Loss: 0.000013365, Improvement: 0.000002191, Best Loss: 0.000006606 in Epoch 518
Epoch 522
Epoch 522, Loss: 0.000015507, Improvement: 0.000002141, Best Loss: 0.000006606 in Epoch 518
Epoch 523
Epoch 523, Loss: 0.000011475, Improvement: -0.000004031, Best Loss: 0.000006606 in Epoch 518
Epoch 524
Epoch 524, Loss: 0.000010340, Improvement: -0.000001135, Best Loss: 0.000006606 in Epoch 518
Epoch 525
Epoch 525, Loss: 0.000009972, Improvement: -0.000000368, Best Loss: 0.000006606 in Epoch 518
Epoch 526
Epoch 526, Loss: 0.000010361, Improvement: 0.000000390, Best Loss: 0.000006606 in Epoch 518
Epoch 527
Epoch 527, Loss: 0.000011656, Improvement: 0.000001295, Best Loss: 0.000006606 in Epoch 518
Epoch 528
Epoch 528, Loss: 0.000013539, Improvement: 0.000001883, Best Loss: 0.000006606 in Epoch 518
Epoch 529
Epoch 529, Loss: 0.000018121, Improvement: 0.000004582, Best Loss: 0.000006606 in Epoch 518
Epoch 530
Epoch 530, Loss: 0.000013585, Improvement: -0.000004537, Best Loss: 0.000006606 in Epoch 518
Epoch 531
Epoch 531, Loss: 0.000014025, Improvement: 0.000000441, Best Loss: 0.000006606 in Epoch 518
Epoch 532
Epoch 532, Loss: 0.000037746, Improvement: 0.000023721, Best Loss: 0.000006606 in Epoch 518
Epoch 533
Epoch 533, Loss: 0.000060260, Improvement: 0.000022514, Best Loss: 0.000006606 in Epoch 518
Epoch 534
Epoch 534, Loss: 0.000062056, Improvement: 0.000001795, Best Loss: 0.000006606 in Epoch 518
Epoch 535
Epoch 535, Loss: 0.000030187, Improvement: -0.000031869, Best Loss: 0.000006606 in Epoch 518
Epoch 536
Epoch 536, Loss: 0.000029759, Improvement: -0.000000428, Best Loss: 0.000006606 in Epoch 518
Epoch 537
Epoch 537, Loss: 0.000018515, Improvement: -0.000011244, Best Loss: 0.000006606 in Epoch 518
Epoch 538
Epoch 538, Loss: 0.000013967, Improvement: -0.000004547, Best Loss: 0.000006606 in Epoch 518
Epoch 539
Epoch 539, Loss: 0.000014304, Improvement: 0.000000337, Best Loss: 0.000006606 in Epoch 518
Epoch 540
Epoch 540, Loss: 0.000020788, Improvement: 0.000006484, Best Loss: 0.000006606 in Epoch 518
Epoch 541
Epoch 541, Loss: 0.000056107, Improvement: 0.000035318, Best Loss: 0.000006606 in Epoch 518
Epoch 542
Epoch 542, Loss: 0.000066546, Improvement: 0.000010439, Best Loss: 0.000006606 in Epoch 518
Epoch 543
Epoch 543, Loss: 0.000056546, Improvement: -0.000010000, Best Loss: 0.000006606 in Epoch 518
Epoch 544
Epoch 544, Loss: 0.000036394, Improvement: -0.000020152, Best Loss: 0.000006606 in Epoch 518
Epoch 545
Epoch 545, Loss: 0.000026535, Improvement: -0.000009859, Best Loss: 0.000006606 in Epoch 518
Epoch 546
Epoch 546, Loss: 0.000031912, Improvement: 0.000005377, Best Loss: 0.000006606 in Epoch 518
Epoch 547
Epoch 547, Loss: 0.000019669, Improvement: -0.000012243, Best Loss: 0.000006606 in Epoch 518
Epoch 548
Epoch 548, Loss: 0.000034425, Improvement: 0.000014756, Best Loss: 0.000006606 in Epoch 518
Epoch 549
Epoch 549, Loss: 0.000048431, Improvement: 0.000014006, Best Loss: 0.000006606 in Epoch 518
Epoch 550
Model saving checkpoint: the model trained after epoch 550 has been saved with the training errors.
Epoch 550, Loss: 0.000058785, Improvement: 0.000010354, Best Loss: 0.000006606 in Epoch 518
Epoch 551
Epoch 551, Loss: 0.000063520, Improvement: 0.000004736, Best Loss: 0.000006606 in Epoch 518
Epoch 552
Epoch 552, Loss: 0.000116364, Improvement: 0.000052844, Best Loss: 0.000006606 in Epoch 518
Epoch 553
Epoch 553, Loss: 0.000092697, Improvement: -0.000023667, Best Loss: 0.000006606 in Epoch 518
Epoch 554
Epoch 554, Loss: 0.000035771, Improvement: -0.000056926, Best Loss: 0.000006606 in Epoch 518
Epoch 555
Epoch 555, Loss: 0.000025310, Improvement: -0.000010462, Best Loss: 0.000006606 in Epoch 518
Epoch 556
Epoch 556, Loss: 0.000014224, Improvement: -0.000011086, Best Loss: 0.000006606 in Epoch 518
Epoch 557
Epoch 557, Loss: 0.000011419, Improvement: -0.000002805, Best Loss: 0.000006606 in Epoch 518
Epoch 558
Epoch 558, Loss: 0.000012648, Improvement: 0.000001229, Best Loss: 0.000006606 in Epoch 518
Epoch 559
Epoch 559, Loss: 0.000015479, Improvement: 0.000002831, Best Loss: 0.000006606 in Epoch 518
Epoch 560
Epoch 560, Loss: 0.000016460, Improvement: 0.000000981, Best Loss: 0.000006606 in Epoch 518
Epoch 561
Epoch 561, Loss: 0.000016453, Improvement: -0.000000007, Best Loss: 0.000006606 in Epoch 518
Epoch 562
Epoch 562, Loss: 0.000017519, Improvement: 0.000001066, Best Loss: 0.000006606 in Epoch 518
Epoch 563
Epoch 563, Loss: 0.000015821, Improvement: -0.000001698, Best Loss: 0.000006606 in Epoch 518
Epoch 564
Epoch 564, Loss: 0.000015516, Improvement: -0.000000306, Best Loss: 0.000006606 in Epoch 518
Epoch 565
Epoch 565, Loss: 0.000015366, Improvement: -0.000000149, Best Loss: 0.000006606 in Epoch 518
Epoch 566
Epoch 566, Loss: 0.000029747, Improvement: 0.000014381, Best Loss: 0.000006606 in Epoch 518
Epoch 567
Epoch 567, Loss: 0.000026965, Improvement: -0.000002782, Best Loss: 0.000006606 in Epoch 518
Epoch 568
Epoch 568, Loss: 0.000028541, Improvement: 0.000001576, Best Loss: 0.000006606 in Epoch 518
Epoch 569
Epoch 569, Loss: 0.000033360, Improvement: 0.000004819, Best Loss: 0.000006606 in Epoch 518
Epoch 570
Epoch 570, Loss: 0.000054458, Improvement: 0.000021098, Best Loss: 0.000006606 in Epoch 518
Epoch 571
Epoch 571, Loss: 0.000046524, Improvement: -0.000007934, Best Loss: 0.000006606 in Epoch 518
Epoch 572
Epoch 572, Loss: 0.000035566, Improvement: -0.000010958, Best Loss: 0.000006606 in Epoch 518
Epoch 573
Epoch 573, Loss: 0.000031584, Improvement: -0.000003982, Best Loss: 0.000006606 in Epoch 518
Epoch 574
Epoch 574, Loss: 0.000025041, Improvement: -0.000006543, Best Loss: 0.000006606 in Epoch 518
Epoch 575
Epoch 575, Loss: 0.000023794, Improvement: -0.000001247, Best Loss: 0.000006606 in Epoch 518
Epoch 576
Epoch 576, Loss: 0.000028398, Improvement: 0.000004604, Best Loss: 0.000006606 in Epoch 518
Epoch 577
Epoch 577, Loss: 0.000016200, Improvement: -0.000012198, Best Loss: 0.000006606 in Epoch 518
Epoch 578
Epoch 578, Loss: 0.000041843, Improvement: 0.000025643, Best Loss: 0.000006606 in Epoch 518
Epoch 579
Epoch 579, Loss: 0.000074224, Improvement: 0.000032382, Best Loss: 0.000006606 in Epoch 518
Epoch 580
Epoch 580, Loss: 0.000065885, Improvement: -0.000008340, Best Loss: 0.000006606 in Epoch 518
Epoch 581
Epoch 581, Loss: 0.000037192, Improvement: -0.000028693, Best Loss: 0.000006606 in Epoch 518
Epoch 582
Epoch 582, Loss: 0.000061984, Improvement: 0.000024793, Best Loss: 0.000006606 in Epoch 518
Epoch 583
Epoch 583, Loss: 0.000048198, Improvement: -0.000013786, Best Loss: 0.000006606 in Epoch 518
Epoch 584
Epoch 584, Loss: 0.000029003, Improvement: -0.000019196, Best Loss: 0.000006606 in Epoch 518
Epoch 585
Epoch 585, Loss: 0.000020138, Improvement: -0.000008865, Best Loss: 0.000006606 in Epoch 518
Epoch 586
Epoch 586, Loss: 0.000014182, Improvement: -0.000005956, Best Loss: 0.000006606 in Epoch 518
Epoch 587
Epoch 587, Loss: 0.000015380, Improvement: 0.000001198, Best Loss: 0.000006606 in Epoch 518
Epoch 588
Epoch 588, Loss: 0.000018524, Improvement: 0.000003145, Best Loss: 0.000006606 in Epoch 518
Epoch 589
Epoch 589, Loss: 0.000037969, Improvement: 0.000019445, Best Loss: 0.000006606 in Epoch 518
Epoch 590
Epoch 590, Loss: 0.000043123, Improvement: 0.000005154, Best Loss: 0.000006606 in Epoch 518
Epoch 591
Epoch 591, Loss: 0.000050324, Improvement: 0.000007201, Best Loss: 0.000006606 in Epoch 518
Epoch 592
Epoch 592, Loss: 0.000085672, Improvement: 0.000035348, Best Loss: 0.000006606 in Epoch 518
Epoch 593
Epoch 593, Loss: 0.000132609, Improvement: 0.000046937, Best Loss: 0.000006606 in Epoch 518
Epoch 594
Epoch 594, Loss: 0.000048930, Improvement: -0.000083679, Best Loss: 0.000006606 in Epoch 518
Epoch 595
Epoch 595, Loss: 0.000020834, Improvement: -0.000028096, Best Loss: 0.000006606 in Epoch 518
Epoch 596
Epoch 596, Loss: 0.000013047, Improvement: -0.000007786, Best Loss: 0.000006606 in Epoch 518
Epoch 597
Epoch 597, Loss: 0.000010747, Improvement: -0.000002301, Best Loss: 0.000006606 in Epoch 518
Epoch 598
A best model at epoch 598 has been saved with training error 0.000005465.
Epoch 598, Loss: 0.000008576, Improvement: -0.000002171, Best Loss: 0.000005465 in Epoch 598
Epoch 599
A best model at epoch 599 has been saved with training error 0.000005296.
Epoch 599, Loss: 0.000008447, Improvement: -0.000000129, Best Loss: 0.000005296 in Epoch 599
Epoch 600
Model saving checkpoint: the model trained after epoch 600 has been saved with the training errors.
Epoch 600, Loss: 0.000008973, Improvement: 0.000000526, Best Loss: 0.000005296 in Epoch 599
Epoch 601
Epoch 601, Loss: 0.000008089, Improvement: -0.000000884, Best Loss: 0.000005296 in Epoch 599
Epoch 602
A best model at epoch 602 has been saved with training error 0.000004951.
Epoch 602, Loss: 0.000007810, Improvement: -0.000000279, Best Loss: 0.000004951 in Epoch 602
Epoch 603
Epoch 603, Loss: 0.000012757, Improvement: 0.000004947, Best Loss: 0.000004951 in Epoch 602
Epoch 604
Epoch 604, Loss: 0.000031536, Improvement: 0.000018779, Best Loss: 0.000004951 in Epoch 602
Epoch 605
Epoch 605, Loss: 0.000020660, Improvement: -0.000010875, Best Loss: 0.000004951 in Epoch 602
Epoch 606
Epoch 606, Loss: 0.000016237, Improvement: -0.000004423, Best Loss: 0.000004951 in Epoch 602
Epoch 607
Epoch 607, Loss: 0.000021654, Improvement: 0.000005417, Best Loss: 0.000004951 in Epoch 602
Epoch 608
Epoch 608, Loss: 0.000031028, Improvement: 0.000009375, Best Loss: 0.000004951 in Epoch 602
Epoch 609
Epoch 609, Loss: 0.000025507, Improvement: -0.000005522, Best Loss: 0.000004951 in Epoch 602
Epoch 610
Epoch 610, Loss: 0.000018400, Improvement: -0.000007106, Best Loss: 0.000004951 in Epoch 602
Epoch 611
Epoch 611, Loss: 0.000021201, Improvement: 0.000002801, Best Loss: 0.000004951 in Epoch 602
Epoch 612
Epoch 612, Loss: 0.000020826, Improvement: -0.000000375, Best Loss: 0.000004951 in Epoch 602
Epoch 613
Epoch 613, Loss: 0.000032807, Improvement: 0.000011981, Best Loss: 0.000004951 in Epoch 602
Epoch 614
Epoch 614, Loss: 0.000045092, Improvement: 0.000012285, Best Loss: 0.000004951 in Epoch 602
Epoch 615
Epoch 615, Loss: 0.000027678, Improvement: -0.000017414, Best Loss: 0.000004951 in Epoch 602
Epoch 616
Epoch 616, Loss: 0.000020995, Improvement: -0.000006683, Best Loss: 0.000004951 in Epoch 602
Epoch 617
Epoch 617, Loss: 0.000020442, Improvement: -0.000000553, Best Loss: 0.000004951 in Epoch 602
Epoch 618
Epoch 618, Loss: 0.000018110, Improvement: -0.000002332, Best Loss: 0.000004951 in Epoch 602
Epoch 619
Epoch 619, Loss: 0.000033483, Improvement: 0.000015373, Best Loss: 0.000004951 in Epoch 602
Epoch 620
Epoch 620, Loss: 0.000043389, Improvement: 0.000009906, Best Loss: 0.000004951 in Epoch 602
Epoch 621
Epoch 621, Loss: 0.000034826, Improvement: -0.000008562, Best Loss: 0.000004951 in Epoch 602
Epoch 622
Epoch 622, Loss: 0.000026282, Improvement: -0.000008545, Best Loss: 0.000004951 in Epoch 602
Epoch 623
Epoch 623, Loss: 0.000021800, Improvement: -0.000004481, Best Loss: 0.000004951 in Epoch 602
Epoch 624
Epoch 624, Loss: 0.000019852, Improvement: -0.000001948, Best Loss: 0.000004951 in Epoch 602
Epoch 625
