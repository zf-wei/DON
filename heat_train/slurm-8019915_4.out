/people/weiz828/.conda/envs/test/lib/python3.12/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/people/weiz828/.conda/envs/test/lib/python3.12/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
The dimension of y_tensor is torch.Size([5000, 2]).
The dimension of y_expanded is torch.Size([500, 5000, 2]) after expanding.
The dimensions of the initial conditions are: (500, 50)
The dimensions of the solutions are: (500, 100, 50)
The dimension of u_tensor is torch.Size([500, 50]).
The dimension of u_expanded is torch.Size([500, 5000, 50]) after expanding.
The loaded solution dataset has dimension (500, 100, 50),
	 while the arranged linearized dataset has dimension (500, 5000).
The dimension of s_tensor is torch.Size([500, 5000]).
The dimension of s_expanded is torch.Size([500, 5000, 1]) after expanding.
Epoch 1
A best model at epoch 1 has been saved with training error 0.029445089.
A best model at epoch 1 has been saved with training error 0.021829957.
A best model at epoch 1 has been saved with training error 0.017810775.
A best model at epoch 1 has been saved with training error 0.015356377.
A best model at epoch 1 has been saved with training error 0.010464921.
A best model at epoch 1 has been saved with training error 0.009345377.
Epoch 1, Loss: 0.020040369, Improvement: 0.020040369, Best Loss: 0.009345377 in Epoch 1
Epoch 2
A best model at epoch 2 has been saved with training error 0.008249776.
Epoch 2, Loss: 0.015270716, Improvement: -0.004769653, Best Loss: 0.008249776 in Epoch 2
Epoch 3
Epoch 3, Loss: 0.012362738, Improvement: -0.002907978, Best Loss: 0.008249776 in Epoch 2
Epoch 4
A best model at epoch 4 has been saved with training error 0.007741801.
A best model at epoch 4 has been saved with training error 0.006998621.
Epoch 4, Loss: 0.011631919, Improvement: -0.000730819, Best Loss: 0.006998621 in Epoch 4
Epoch 5
A best model at epoch 5 has been saved with training error 0.006587351.
Epoch 5, Loss: 0.011720920, Improvement: 0.000089001, Best Loss: 0.006587351 in Epoch 5
Epoch 6
Epoch 6, Loss: 0.011100063, Improvement: -0.000620857, Best Loss: 0.006587351 in Epoch 5
Epoch 7
A best model at epoch 7 has been saved with training error 0.006311654.
Epoch 7, Loss: 0.011071843, Improvement: -0.000028221, Best Loss: 0.006311654 in Epoch 7
Epoch 8
Epoch 8, Loss: 0.010970019, Improvement: -0.000101824, Best Loss: 0.006311654 in Epoch 7
Epoch 9
Epoch 9, Loss: 0.010865443, Improvement: -0.000104575, Best Loss: 0.006311654 in Epoch 7
Epoch 10
A best model at epoch 10 has been saved with training error 0.005046294.
Epoch 10, Loss: 0.010781208, Improvement: -0.000084235, Best Loss: 0.005046294 in Epoch 10
Epoch 11
Epoch 11, Loss: 0.010784113, Improvement: 0.000002904, Best Loss: 0.005046294 in Epoch 10
Epoch 12
Epoch 12, Loss: 0.010744053, Improvement: -0.000040059, Best Loss: 0.005046294 in Epoch 10
Epoch 13
Epoch 13, Loss: 0.010716390, Improvement: -0.000027663, Best Loss: 0.005046294 in Epoch 10
Epoch 14
A best model at epoch 14 has been saved with training error 0.004349868.
Epoch 14, Loss: 0.010693843, Improvement: -0.000022547, Best Loss: 0.004349868 in Epoch 14
Epoch 15
Epoch 15, Loss: 0.010688851, Improvement: -0.000004992, Best Loss: 0.004349868 in Epoch 14
Epoch 16
Epoch 16, Loss: 0.010664611, Improvement: -0.000024240, Best Loss: 0.004349868 in Epoch 14
Epoch 17
Epoch 17, Loss: 0.010643706, Improvement: -0.000020905, Best Loss: 0.004349868 in Epoch 14
Epoch 18
Epoch 18, Loss: 0.010638307, Improvement: -0.000005399, Best Loss: 0.004349868 in Epoch 14
Epoch 19
Epoch 19, Loss: 0.010629868, Improvement: -0.000008439, Best Loss: 0.004349868 in Epoch 14
Epoch 20
Epoch 20, Loss: 0.010725936, Improvement: 0.000096068, Best Loss: 0.004349868 in Epoch 14
Epoch 21
Epoch 21, Loss: 0.010785746, Improvement: 0.000059809, Best Loss: 0.004349868 in Epoch 14
Epoch 22
Epoch 22, Loss: 0.010874112, Improvement: 0.000088366, Best Loss: 0.004349868 in Epoch 14
Epoch 23
Epoch 23, Loss: 0.010586831, Improvement: -0.000287281, Best Loss: 0.004349868 in Epoch 14
Epoch 24
Epoch 24, Loss: 0.010514574, Improvement: -0.000072256, Best Loss: 0.004349868 in Epoch 14
Epoch 25
Epoch 25, Loss: 0.010479322, Improvement: -0.000035252, Best Loss: 0.004349868 in Epoch 14
Epoch 26
Epoch 26, Loss: 0.010394324, Improvement: -0.000084999, Best Loss: 0.004349868 in Epoch 14
Epoch 27
A best model at epoch 27 has been saved with training error 0.004017888.
Epoch 27, Loss: 0.010350405, Improvement: -0.000043918, Best Loss: 0.004017888 in Epoch 27
Epoch 28
Epoch 28, Loss: 0.010257173, Improvement: -0.000093233, Best Loss: 0.004017888 in Epoch 27
Epoch 29
Epoch 29, Loss: 0.010135277, Improvement: -0.000121896, Best Loss: 0.004017888 in Epoch 27
Epoch 30
A best model at epoch 30 has been saved with training error 0.003603998.
Epoch 30, Loss: 0.009912248, Improvement: -0.000223028, Best Loss: 0.003603998 in Epoch 30
Epoch 31
Epoch 31, Loss: 0.009498445, Improvement: -0.000413803, Best Loss: 0.003603998 in Epoch 30
Epoch 32
Epoch 32, Loss: 0.008995526, Improvement: -0.000502920, Best Loss: 0.003603998 in Epoch 30
Epoch 33
Epoch 33, Loss: 0.007608368, Improvement: -0.001387158, Best Loss: 0.003603998 in Epoch 30
Epoch 34
Epoch 34, Loss: 0.007419724, Improvement: -0.000188644, Best Loss: 0.003603998 in Epoch 30
Epoch 35
Epoch 35, Loss: 0.006971823, Improvement: -0.000447900, Best Loss: 0.003603998 in Epoch 30
Epoch 36
Epoch 36, Loss: 0.007099955, Improvement: 0.000128132, Best Loss: 0.003603998 in Epoch 30
Epoch 37
Epoch 37, Loss: 0.006608159, Improvement: -0.000491796, Best Loss: 0.003603998 in Epoch 30
Epoch 38
Epoch 38, Loss: 0.006451342, Improvement: -0.000156817, Best Loss: 0.003603998 in Epoch 30
Epoch 39
Epoch 39, Loss: 0.006221738, Improvement: -0.000229604, Best Loss: 0.003603998 in Epoch 30
Epoch 40
A best model at epoch 40 has been saved with training error 0.003449820.
Epoch 40, Loss: 0.006172113, Improvement: -0.000049625, Best Loss: 0.003449820 in Epoch 40
Epoch 41
Epoch 41, Loss: 0.006134666, Improvement: -0.000037447, Best Loss: 0.003449820 in Epoch 40
Epoch 42
Epoch 42, Loss: 0.006048608, Improvement: -0.000086058, Best Loss: 0.003449820 in Epoch 40
Epoch 43
Epoch 43, Loss: 0.006094765, Improvement: 0.000046157, Best Loss: 0.003449820 in Epoch 40
Epoch 44
Epoch 44, Loss: 0.006122991, Improvement: 0.000028226, Best Loss: 0.003449820 in Epoch 40
Epoch 45
Epoch 45, Loss: 0.005972353, Improvement: -0.000150639, Best Loss: 0.003449820 in Epoch 40
Epoch 46
A best model at epoch 46 has been saved with training error 0.002701266.
Epoch 46, Loss: 0.006208087, Improvement: 0.000235735, Best Loss: 0.002701266 in Epoch 46
Epoch 47
Epoch 47, Loss: 0.006035019, Improvement: -0.000173069, Best Loss: 0.002701266 in Epoch 46
Epoch 48
Epoch 48, Loss: 0.006297093, Improvement: 0.000262075, Best Loss: 0.002701266 in Epoch 46
Epoch 49
Epoch 49, Loss: 0.006504707, Improvement: 0.000207614, Best Loss: 0.002701266 in Epoch 46
Epoch 50
Model saving checkpoint: the model trained after epoch 50 has been saved with the training errors.
Epoch 50, Loss: 0.006906954, Improvement: 0.000402246, Best Loss: 0.002701266 in Epoch 46
Epoch 51
Epoch 51, Loss: 0.006212616, Improvement: -0.000694338, Best Loss: 0.002701266 in Epoch 46
Epoch 52
Epoch 52, Loss: 0.005788100, Improvement: -0.000424516, Best Loss: 0.002701266 in Epoch 46
Epoch 53
Epoch 53, Loss: 0.005645836, Improvement: -0.000142265, Best Loss: 0.002701266 in Epoch 46
Epoch 54
Epoch 54, Loss: 0.005539589, Improvement: -0.000106246, Best Loss: 0.002701266 in Epoch 46
Epoch 55
Epoch 55, Loss: 0.005485620, Improvement: -0.000053969, Best Loss: 0.002701266 in Epoch 46
Epoch 56
Epoch 56, Loss: 0.005428890, Improvement: -0.000056730, Best Loss: 0.002701266 in Epoch 46
Epoch 57
Epoch 57, Loss: 0.005411714, Improvement: -0.000017177, Best Loss: 0.002701266 in Epoch 46
Epoch 58
Epoch 58, Loss: 0.005390109, Improvement: -0.000021605, Best Loss: 0.002701266 in Epoch 46
Epoch 59
Epoch 59, Loss: 0.005360933, Improvement: -0.000029175, Best Loss: 0.002701266 in Epoch 46
Epoch 60
Epoch 60, Loss: 0.005264843, Improvement: -0.000096091, Best Loss: 0.002701266 in Epoch 46
Epoch 61
Epoch 61, Loss: 0.005316661, Improvement: 0.000051818, Best Loss: 0.002701266 in Epoch 46
Epoch 62
Epoch 62, Loss: 0.005144456, Improvement: -0.000172205, Best Loss: 0.002701266 in Epoch 46
Epoch 63
Epoch 63, Loss: 0.005160644, Improvement: 0.000016189, Best Loss: 0.002701266 in Epoch 46
Epoch 64
Epoch 64, Loss: 0.005476416, Improvement: 0.000315772, Best Loss: 0.002701266 in Epoch 46
Epoch 65
Epoch 65, Loss: 0.005372609, Improvement: -0.000103807, Best Loss: 0.002701266 in Epoch 46
Epoch 66
Epoch 66, Loss: 0.005343895, Improvement: -0.000028714, Best Loss: 0.002701266 in Epoch 46
Epoch 67
Epoch 67, Loss: 0.005186989, Improvement: -0.000156905, Best Loss: 0.002701266 in Epoch 46
Epoch 68
A best model at epoch 68 has been saved with training error 0.002554261.
Epoch 68, Loss: 0.005086826, Improvement: -0.000100163, Best Loss: 0.002554261 in Epoch 68
Epoch 69
Epoch 69, Loss: 0.005069714, Improvement: -0.000017112, Best Loss: 0.002554261 in Epoch 68
Epoch 70
Epoch 70, Loss: 0.005387298, Improvement: 0.000317585, Best Loss: 0.002554261 in Epoch 68
Epoch 71
Epoch 71, Loss: 0.006524969, Improvement: 0.001137670, Best Loss: 0.002554261 in Epoch 68
Epoch 72
Epoch 72, Loss: 0.005719360, Improvement: -0.000805608, Best Loss: 0.002554261 in Epoch 68
Epoch 73
A best model at epoch 73 has been saved with training error 0.002152342.
Epoch 73, Loss: 0.005096617, Improvement: -0.000622743, Best Loss: 0.002152342 in Epoch 73
Epoch 74
Epoch 74, Loss: 0.004929674, Improvement: -0.000166943, Best Loss: 0.002152342 in Epoch 73
Epoch 75
Epoch 75, Loss: 0.004796086, Improvement: -0.000133587, Best Loss: 0.002152342 in Epoch 73
Epoch 76
Epoch 76, Loss: 0.004755245, Improvement: -0.000040841, Best Loss: 0.002152342 in Epoch 73
Epoch 77
Epoch 77, Loss: 0.004807002, Improvement: 0.000051757, Best Loss: 0.002152342 in Epoch 73
Epoch 78
Epoch 78, Loss: 0.004687971, Improvement: -0.000119031, Best Loss: 0.002152342 in Epoch 73
Epoch 79
Epoch 79, Loss: 0.004671648, Improvement: -0.000016323, Best Loss: 0.002152342 in Epoch 73
Epoch 80
Epoch 80, Loss: 0.004647828, Improvement: -0.000023821, Best Loss: 0.002152342 in Epoch 73
Epoch 81
Epoch 81, Loss: 0.004573713, Improvement: -0.000074114, Best Loss: 0.002152342 in Epoch 73
Epoch 82
A best model at epoch 82 has been saved with training error 0.001962957.
Epoch 82, Loss: 0.004568050, Improvement: -0.000005663, Best Loss: 0.001962957 in Epoch 82
Epoch 83
Epoch 83, Loss: 0.004853576, Improvement: 0.000285526, Best Loss: 0.001962957 in Epoch 82
Epoch 84
Epoch 84, Loss: 0.004720819, Improvement: -0.000132757, Best Loss: 0.001962957 in Epoch 82
Epoch 85
Epoch 85, Loss: 0.004862851, Improvement: 0.000142032, Best Loss: 0.001962957 in Epoch 82
Epoch 86
Epoch 86, Loss: 0.005154821, Improvement: 0.000291969, Best Loss: 0.001962957 in Epoch 82
Epoch 87
Epoch 87, Loss: 0.005691809, Improvement: 0.000536988, Best Loss: 0.001962957 in Epoch 82
Epoch 88
Epoch 88, Loss: 0.004707299, Improvement: -0.000984510, Best Loss: 0.001962957 in Epoch 82
Epoch 89
Epoch 89, Loss: 0.004609961, Improvement: -0.000097338, Best Loss: 0.001962957 in Epoch 82
Epoch 90
Epoch 90, Loss: 0.004931493, Improvement: 0.000321533, Best Loss: 0.001962957 in Epoch 82
Epoch 91
Epoch 91, Loss: 0.004701724, Improvement: -0.000229770, Best Loss: 0.001962957 in Epoch 82
Epoch 92
Epoch 92, Loss: 0.004270219, Improvement: -0.000431505, Best Loss: 0.001962957 in Epoch 82
Epoch 93
Epoch 93, Loss: 0.004018864, Improvement: -0.000251355, Best Loss: 0.001962957 in Epoch 82
Epoch 94
Epoch 94, Loss: 0.003833281, Improvement: -0.000185583, Best Loss: 0.001962957 in Epoch 82
Epoch 95
Epoch 95, Loss: 0.003711554, Improvement: -0.000121727, Best Loss: 0.001962957 in Epoch 82
Epoch 96
Epoch 96, Loss: 0.003499175, Improvement: -0.000212379, Best Loss: 0.001962957 in Epoch 82
Epoch 97
A best model at epoch 97 has been saved with training error 0.001577615.
Epoch 97, Loss: 0.003256501, Improvement: -0.000242675, Best Loss: 0.001577615 in Epoch 97
Epoch 98
Epoch 98, Loss: 0.003153289, Improvement: -0.000103211, Best Loss: 0.001577615 in Epoch 97
Epoch 99
Epoch 99, Loss: 0.003076725, Improvement: -0.000076565, Best Loss: 0.001577615 in Epoch 97
Epoch 100
Model saving checkpoint: the model trained after epoch 100 has been saved with the training errors.
Epoch 100, Loss: 0.002818199, Improvement: -0.000258525, Best Loss: 0.001577615 in Epoch 97
Epoch 101
Epoch 101, Loss: 0.002711349, Improvement: -0.000106851, Best Loss: 0.001577615 in Epoch 97
Epoch 102
A best model at epoch 102 has been saved with training error 0.001392980.
Epoch 102, Loss: 0.002514811, Improvement: -0.000196537, Best Loss: 0.001392980 in Epoch 102
Epoch 103
Epoch 103, Loss: 0.002325589, Improvement: -0.000189223, Best Loss: 0.001392980 in Epoch 102
Epoch 104
Epoch 104, Loss: 0.002628013, Improvement: 0.000302425, Best Loss: 0.001392980 in Epoch 102
Epoch 105
A best model at epoch 105 has been saved with training error 0.001259573.
Epoch 105, Loss: 0.002410549, Improvement: -0.000217464, Best Loss: 0.001259573 in Epoch 105
Epoch 106
Epoch 106, Loss: 0.002387182, Improvement: -0.000023367, Best Loss: 0.001259573 in Epoch 105
Epoch 107
A best model at epoch 107 has been saved with training error 0.001022295.
Epoch 107, Loss: 0.002213940, Improvement: -0.000173242, Best Loss: 0.001022295 in Epoch 107
Epoch 108
Epoch 108, Loss: 0.001954890, Improvement: -0.000259050, Best Loss: 0.001022295 in Epoch 107
Epoch 109
Epoch 109, Loss: 0.003080524, Improvement: 0.001125634, Best Loss: 0.001022295 in Epoch 107
Epoch 110
Epoch 110, Loss: 0.002374320, Improvement: -0.000706204, Best Loss: 0.001022295 in Epoch 107
Epoch 111
Epoch 111, Loss: 0.001863670, Improvement: -0.000510650, Best Loss: 0.001022295 in Epoch 107
Epoch 112
Epoch 112, Loss: 0.001833963, Improvement: -0.000029707, Best Loss: 0.001022295 in Epoch 107
Epoch 113
A best model at epoch 113 has been saved with training error 0.000937139.
Epoch 113, Loss: 0.002035118, Improvement: 0.000201156, Best Loss: 0.000937139 in Epoch 113
Epoch 114
Epoch 114, Loss: 0.002429333, Improvement: 0.000394215, Best Loss: 0.000937139 in Epoch 113
Epoch 115
Epoch 115, Loss: 0.001839862, Improvement: -0.000589471, Best Loss: 0.000937139 in Epoch 113
Epoch 116
Epoch 116, Loss: 0.001977650, Improvement: 0.000137788, Best Loss: 0.000937139 in Epoch 113
Epoch 117
Epoch 117, Loss: 0.001758993, Improvement: -0.000218656, Best Loss: 0.000937139 in Epoch 113
Epoch 118
A best model at epoch 118 has been saved with training error 0.000802417.
Epoch 118, Loss: 0.001589167, Improvement: -0.000169827, Best Loss: 0.000802417 in Epoch 118
Epoch 119
Epoch 119, Loss: 0.001557243, Improvement: -0.000031923, Best Loss: 0.000802417 in Epoch 118
Epoch 120
Epoch 120, Loss: 0.001446081, Improvement: -0.000111162, Best Loss: 0.000802417 in Epoch 118
Epoch 121
Epoch 121, Loss: 0.001544377, Improvement: 0.000098296, Best Loss: 0.000802417 in Epoch 118
Epoch 122
Epoch 122, Loss: 0.002042660, Improvement: 0.000498283, Best Loss: 0.000802417 in Epoch 118
Epoch 123
Epoch 123, Loss: 0.002270208, Improvement: 0.000227548, Best Loss: 0.000802417 in Epoch 118
Epoch 124
Epoch 124, Loss: 0.004244736, Improvement: 0.001974528, Best Loss: 0.000802417 in Epoch 118
Epoch 125
Epoch 125, Loss: 0.003251189, Improvement: -0.000993547, Best Loss: 0.000802417 in Epoch 118
Epoch 126
Epoch 126, Loss: 0.002078111, Improvement: -0.001173078, Best Loss: 0.000802417 in Epoch 118
Epoch 127
Epoch 127, Loss: 0.001428564, Improvement: -0.000649547, Best Loss: 0.000802417 in Epoch 118
Epoch 128
Epoch 128, Loss: 0.001258855, Improvement: -0.000169710, Best Loss: 0.000802417 in Epoch 118
Epoch 129
Epoch 129, Loss: 0.001191768, Improvement: -0.000067087, Best Loss: 0.000802417 in Epoch 118
Epoch 130
A best model at epoch 130 has been saved with training error 0.000691340.
Epoch 130, Loss: 0.001154007, Improvement: -0.000037761, Best Loss: 0.000691340 in Epoch 130
Epoch 131
Epoch 131, Loss: 0.001120318, Improvement: -0.000033690, Best Loss: 0.000691340 in Epoch 130
Epoch 132
Epoch 132, Loss: 0.001095614, Improvement: -0.000024704, Best Loss: 0.000691340 in Epoch 130
Epoch 133
A best model at epoch 133 has been saved with training error 0.000648873.
Epoch 133, Loss: 0.001077423, Improvement: -0.000018191, Best Loss: 0.000648873 in Epoch 133
Epoch 134
Epoch 134, Loss: 0.001065088, Improvement: -0.000012335, Best Loss: 0.000648873 in Epoch 133
Epoch 135
Epoch 135, Loss: 0.001078508, Improvement: 0.000013420, Best Loss: 0.000648873 in Epoch 133
Epoch 136
Epoch 136, Loss: 0.001061313, Improvement: -0.000017195, Best Loss: 0.000648873 in Epoch 133
Epoch 137
A best model at epoch 137 has been saved with training error 0.000624057.
A best model at epoch 137 has been saved with training error 0.000613704.
Epoch 137, Loss: 0.001045884, Improvement: -0.000015429, Best Loss: 0.000613704 in Epoch 137
Epoch 138
Epoch 138, Loss: 0.001008179, Improvement: -0.000037705, Best Loss: 0.000613704 in Epoch 137
Epoch 139
Epoch 139, Loss: 0.000981950, Improvement: -0.000026229, Best Loss: 0.000613704 in Epoch 137
Epoch 140
A best model at epoch 140 has been saved with training error 0.000487224.
Epoch 140, Loss: 0.000961482, Improvement: -0.000020468, Best Loss: 0.000487224 in Epoch 140
Epoch 141
Epoch 141, Loss: 0.000936060, Improvement: -0.000025422, Best Loss: 0.000487224 in Epoch 140
Epoch 142
A best model at epoch 142 has been saved with training error 0.000414305.
Epoch 142, Loss: 0.000920128, Improvement: -0.000015932, Best Loss: 0.000414305 in Epoch 142
Epoch 143
Epoch 143, Loss: 0.000911428, Improvement: -0.000008700, Best Loss: 0.000414305 in Epoch 142
Epoch 144
Epoch 144, Loss: 0.000918333, Improvement: 0.000006905, Best Loss: 0.000414305 in Epoch 142
Epoch 145
Epoch 145, Loss: 0.000938171, Improvement: 0.000019838, Best Loss: 0.000414305 in Epoch 142
Epoch 146
Epoch 146, Loss: 0.000919484, Improvement: -0.000018687, Best Loss: 0.000414305 in Epoch 142
Epoch 147
Epoch 147, Loss: 0.000954261, Improvement: 0.000034777, Best Loss: 0.000414305 in Epoch 142
Epoch 148
Epoch 148, Loss: 0.000938773, Improvement: -0.000015488, Best Loss: 0.000414305 in Epoch 142
Epoch 149
Epoch 149, Loss: 0.000857654, Improvement: -0.000081119, Best Loss: 0.000414305 in Epoch 142
Epoch 150
Model saving checkpoint: the model trained after epoch 150 has been saved with the training errors.
Epoch 150, Loss: 0.000881586, Improvement: 0.000023931, Best Loss: 0.000414305 in Epoch 142
Epoch 151
Epoch 151, Loss: 0.000884897, Improvement: 0.000003311, Best Loss: 0.000414305 in Epoch 142
Epoch 152
Epoch 152, Loss: 0.000864297, Improvement: -0.000020600, Best Loss: 0.000414305 in Epoch 142
Epoch 153
Epoch 153, Loss: 0.000895398, Improvement: 0.000031101, Best Loss: 0.000414305 in Epoch 142
Epoch 154
Epoch 154, Loss: 0.000893883, Improvement: -0.000001516, Best Loss: 0.000414305 in Epoch 142
Epoch 155
Epoch 155, Loss: 0.000791284, Improvement: -0.000102598, Best Loss: 0.000414305 in Epoch 142
Epoch 156
Epoch 156, Loss: 0.000818248, Improvement: 0.000026963, Best Loss: 0.000414305 in Epoch 142
Epoch 157
Epoch 157, Loss: 0.000819928, Improvement: 0.000001680, Best Loss: 0.000414305 in Epoch 142
Epoch 158
Epoch 158, Loss: 0.000793957, Improvement: -0.000025971, Best Loss: 0.000414305 in Epoch 142
Epoch 159
Epoch 159, Loss: 0.000714311, Improvement: -0.000079646, Best Loss: 0.000414305 in Epoch 142
Epoch 160
Epoch 160, Loss: 0.000739606, Improvement: 0.000025295, Best Loss: 0.000414305 in Epoch 142
Epoch 161
Epoch 161, Loss: 0.000762117, Improvement: 0.000022511, Best Loss: 0.000414305 in Epoch 142
Epoch 162
Epoch 162, Loss: 0.000921100, Improvement: 0.000158983, Best Loss: 0.000414305 in Epoch 142
Epoch 163
Epoch 163, Loss: 0.001041877, Improvement: 0.000120777, Best Loss: 0.000414305 in Epoch 142
Epoch 164
Epoch 164, Loss: 0.000978121, Improvement: -0.000063756, Best Loss: 0.000414305 in Epoch 142
Epoch 165
Epoch 165, Loss: 0.001050154, Improvement: 0.000072033, Best Loss: 0.000414305 in Epoch 142
Epoch 166
Epoch 166, Loss: 0.000833206, Improvement: -0.000216948, Best Loss: 0.000414305 in Epoch 142
Epoch 167
A best model at epoch 167 has been saved with training error 0.000408722.
Epoch 167, Loss: 0.000722898, Improvement: -0.000110308, Best Loss: 0.000408722 in Epoch 167
Epoch 168
Epoch 168, Loss: 0.000822950, Improvement: 0.000100052, Best Loss: 0.000408722 in Epoch 167
Epoch 169
Epoch 169, Loss: 0.000984923, Improvement: 0.000161973, Best Loss: 0.000408722 in Epoch 167
Epoch 170
Epoch 170, Loss: 0.002262304, Improvement: 0.001277380, Best Loss: 0.000408722 in Epoch 167
Epoch 171
Epoch 171, Loss: 0.001455228, Improvement: -0.000807075, Best Loss: 0.000408722 in Epoch 167
Epoch 172
Epoch 172, Loss: 0.001088010, Improvement: -0.000367218, Best Loss: 0.000408722 in Epoch 167
Epoch 173
Epoch 173, Loss: 0.000702208, Improvement: -0.000385802, Best Loss: 0.000408722 in Epoch 167
Epoch 174
Epoch 174, Loss: 0.000717433, Improvement: 0.000015225, Best Loss: 0.000408722 in Epoch 167
Epoch 175
Epoch 175, Loss: 0.000683903, Improvement: -0.000033530, Best Loss: 0.000408722 in Epoch 167
Epoch 176
A best model at epoch 176 has been saved with training error 0.000398179.
Epoch 176, Loss: 0.000633778, Improvement: -0.000050125, Best Loss: 0.000398179 in Epoch 176
Epoch 177
Epoch 177, Loss: 0.000646541, Improvement: 0.000012763, Best Loss: 0.000398179 in Epoch 176
Epoch 178
Epoch 178, Loss: 0.000655028, Improvement: 0.000008487, Best Loss: 0.000398179 in Epoch 176
Epoch 179
A best model at epoch 179 has been saved with training error 0.000390532.
Epoch 179, Loss: 0.000557021, Improvement: -0.000098007, Best Loss: 0.000390532 in Epoch 179
Epoch 180
A best model at epoch 180 has been saved with training error 0.000379073.
A best model at epoch 180 has been saved with training error 0.000350991.
Epoch 180, Loss: 0.000516997, Improvement: -0.000040024, Best Loss: 0.000350991 in Epoch 180
Epoch 181
Epoch 181, Loss: 0.000512140, Improvement: -0.000004857, Best Loss: 0.000350991 in Epoch 180
Epoch 182
Epoch 182, Loss: 0.000531412, Improvement: 0.000019273, Best Loss: 0.000350991 in Epoch 180
Epoch 183
A best model at epoch 183 has been saved with training error 0.000324614.
Epoch 183, Loss: 0.000531104, Improvement: -0.000000308, Best Loss: 0.000324614 in Epoch 183
Epoch 184
Epoch 184, Loss: 0.000559889, Improvement: 0.000028785, Best Loss: 0.000324614 in Epoch 183
Epoch 185
Epoch 185, Loss: 0.000633177, Improvement: 0.000073288, Best Loss: 0.000324614 in Epoch 183
Epoch 186
Epoch 186, Loss: 0.000661888, Improvement: 0.000028711, Best Loss: 0.000324614 in Epoch 183
Epoch 187
Epoch 187, Loss: 0.000533763, Improvement: -0.000128125, Best Loss: 0.000324614 in Epoch 183
Epoch 188
Epoch 188, Loss: 0.000515927, Improvement: -0.000017836, Best Loss: 0.000324614 in Epoch 183
Epoch 189
Epoch 189, Loss: 0.000603670, Improvement: 0.000087743, Best Loss: 0.000324614 in Epoch 183
Epoch 190
Epoch 190, Loss: 0.000677173, Improvement: 0.000073503, Best Loss: 0.000324614 in Epoch 183
Epoch 191
Epoch 191, Loss: 0.000709824, Improvement: 0.000032652, Best Loss: 0.000324614 in Epoch 183
Epoch 192
Epoch 192, Loss: 0.000637834, Improvement: -0.000071990, Best Loss: 0.000324614 in Epoch 183
Epoch 193
Epoch 193, Loss: 0.000718605, Improvement: 0.000080770, Best Loss: 0.000324614 in Epoch 183
Epoch 194
Epoch 194, Loss: 0.000560522, Improvement: -0.000158083, Best Loss: 0.000324614 in Epoch 183
Epoch 195
Epoch 195, Loss: 0.000465482, Improvement: -0.000095040, Best Loss: 0.000324614 in Epoch 183
Epoch 196
A best model at epoch 196 has been saved with training error 0.000320607.
A best model at epoch 196 has been saved with training error 0.000317772.
Epoch 196, Loss: 0.000467776, Improvement: 0.000002294, Best Loss: 0.000317772 in Epoch 196
Epoch 197
A best model at epoch 197 has been saved with training error 0.000310768.
A best model at epoch 197 has been saved with training error 0.000283560.
Epoch 197, Loss: 0.000391669, Improvement: -0.000076108, Best Loss: 0.000283560 in Epoch 197
Epoch 198
Epoch 198, Loss: 0.000527234, Improvement: 0.000135566, Best Loss: 0.000283560 in Epoch 197
Epoch 199
Epoch 199, Loss: 0.000582704, Improvement: 0.000055470, Best Loss: 0.000283560 in Epoch 197
Epoch 200
Model saving checkpoint: the model trained after epoch 200 has been saved with the training errors.
Epoch 200, Loss: 0.000527168, Improvement: -0.000055535, Best Loss: 0.000283560 in Epoch 197
Epoch 201
Epoch 201, Loss: 0.000794355, Improvement: 0.000267186, Best Loss: 0.000283560 in Epoch 197
Epoch 202
Epoch 202, Loss: 0.000778684, Improvement: -0.000015671, Best Loss: 0.000283560 in Epoch 197
Epoch 203
Epoch 203, Loss: 0.000720677, Improvement: -0.000058006, Best Loss: 0.000283560 in Epoch 197
Epoch 204
Epoch 204, Loss: 0.000526488, Improvement: -0.000194190, Best Loss: 0.000283560 in Epoch 197
Epoch 205
Epoch 205, Loss: 0.000488561, Improvement: -0.000037927, Best Loss: 0.000283560 in Epoch 197
Epoch 206
Epoch 206, Loss: 0.000460452, Improvement: -0.000028109, Best Loss: 0.000283560 in Epoch 197
Epoch 207
Epoch 207, Loss: 0.000437069, Improvement: -0.000023383, Best Loss: 0.000283560 in Epoch 197
Epoch 208
Epoch 208, Loss: 0.000485198, Improvement: 0.000048129, Best Loss: 0.000283560 in Epoch 197
Epoch 209
A best model at epoch 209 has been saved with training error 0.000252523.
Epoch 209, Loss: 0.000515007, Improvement: 0.000029809, Best Loss: 0.000252523 in Epoch 209
Epoch 210
Epoch 210, Loss: 0.000710282, Improvement: 0.000195275, Best Loss: 0.000252523 in Epoch 209
Epoch 211
Epoch 211, Loss: 0.000636648, Improvement: -0.000073635, Best Loss: 0.000252523 in Epoch 209
Epoch 212
Epoch 212, Loss: 0.001025545, Improvement: 0.000388897, Best Loss: 0.000252523 in Epoch 209
Epoch 213
Epoch 213, Loss: 0.001176046, Improvement: 0.000150501, Best Loss: 0.000252523 in Epoch 209
Epoch 214
Epoch 214, Loss: 0.000946877, Improvement: -0.000229169, Best Loss: 0.000252523 in Epoch 209
Epoch 215
Epoch 215, Loss: 0.000905487, Improvement: -0.000041390, Best Loss: 0.000252523 in Epoch 209
Epoch 216
Epoch 216, Loss: 0.000875347, Improvement: -0.000030140, Best Loss: 0.000252523 in Epoch 209
Epoch 217
Epoch 217, Loss: 0.001631306, Improvement: 0.000755959, Best Loss: 0.000252523 in Epoch 209
Epoch 218
Epoch 218, Loss: 0.000794748, Improvement: -0.000836557, Best Loss: 0.000252523 in Epoch 209
Epoch 219
Epoch 219, Loss: 0.000535132, Improvement: -0.000259616, Best Loss: 0.000252523 in Epoch 209
Epoch 220
Epoch 220, Loss: 0.000457457, Improvement: -0.000077675, Best Loss: 0.000252523 in Epoch 209
Epoch 221
A best model at epoch 221 has been saved with training error 0.000226779.
Epoch 221, Loss: 0.000318555, Improvement: -0.000138901, Best Loss: 0.000226779 in Epoch 221
Epoch 222
Epoch 222, Loss: 0.000452844, Improvement: 0.000134288, Best Loss: 0.000226779 in Epoch 221
Epoch 223
Epoch 223, Loss: 0.000582533, Improvement: 0.000129689, Best Loss: 0.000226779 in Epoch 221
Epoch 224
A best model at epoch 224 has been saved with training error 0.000184163.
Epoch 224, Loss: 0.000375845, Improvement: -0.000206688, Best Loss: 0.000184163 in Epoch 224
Epoch 225
Epoch 225, Loss: 0.000297625, Improvement: -0.000078220, Best Loss: 0.000184163 in Epoch 224
Epoch 226
Epoch 226, Loss: 0.000268978, Improvement: -0.000028647, Best Loss: 0.000184163 in Epoch 224
Epoch 227
A best model at epoch 227 has been saved with training error 0.000150639.
Epoch 227, Loss: 0.000252353, Improvement: -0.000016625, Best Loss: 0.000150639 in Epoch 227
Epoch 228
Epoch 228, Loss: 0.000259426, Improvement: 0.000007073, Best Loss: 0.000150639 in Epoch 227
Epoch 229
Epoch 229, Loss: 0.000277700, Improvement: 0.000018274, Best Loss: 0.000150639 in Epoch 227
Epoch 230
Epoch 230, Loss: 0.000261393, Improvement: -0.000016307, Best Loss: 0.000150639 in Epoch 227
Epoch 231
Epoch 231, Loss: 0.000295252, Improvement: 0.000033858, Best Loss: 0.000150639 in Epoch 227
Epoch 232
Epoch 232, Loss: 0.000249305, Improvement: -0.000045946, Best Loss: 0.000150639 in Epoch 227
Epoch 233
Epoch 233, Loss: 0.000297592, Improvement: 0.000048287, Best Loss: 0.000150639 in Epoch 227
Epoch 234
Epoch 234, Loss: 0.000327892, Improvement: 0.000030300, Best Loss: 0.000150639 in Epoch 227
Epoch 235
A best model at epoch 235 has been saved with training error 0.000136204.
Epoch 235, Loss: 0.000271330, Improvement: -0.000056562, Best Loss: 0.000136204 in Epoch 235
Epoch 236
Epoch 236, Loss: 0.000289205, Improvement: 0.000017876, Best Loss: 0.000136204 in Epoch 235
Epoch 237
Epoch 237, Loss: 0.000406152, Improvement: 0.000116947, Best Loss: 0.000136204 in Epoch 235
Epoch 238
Epoch 238, Loss: 0.000395692, Improvement: -0.000010460, Best Loss: 0.000136204 in Epoch 235
Epoch 239
Epoch 239, Loss: 0.000291110, Improvement: -0.000104582, Best Loss: 0.000136204 in Epoch 235
Epoch 240
Epoch 240, Loss: 0.000267580, Improvement: -0.000023530, Best Loss: 0.000136204 in Epoch 235
Epoch 241
Epoch 241, Loss: 0.000324153, Improvement: 0.000056573, Best Loss: 0.000136204 in Epoch 235
Epoch 242
Epoch 242, Loss: 0.000243571, Improvement: -0.000080582, Best Loss: 0.000136204 in Epoch 235
Epoch 243
Epoch 243, Loss: 0.000230918, Improvement: -0.000012653, Best Loss: 0.000136204 in Epoch 235
Epoch 244
Epoch 244, Loss: 0.000462210, Improvement: 0.000231292, Best Loss: 0.000136204 in Epoch 235
Epoch 245
Epoch 245, Loss: 0.000994062, Improvement: 0.000531851, Best Loss: 0.000136204 in Epoch 235
Epoch 246
Epoch 246, Loss: 0.001671076, Improvement: 0.000677015, Best Loss: 0.000136204 in Epoch 235
Epoch 247
Epoch 247, Loss: 0.001742907, Improvement: 0.000071831, Best Loss: 0.000136204 in Epoch 235
Epoch 248
Epoch 248, Loss: 0.000865013, Improvement: -0.000877895, Best Loss: 0.000136204 in Epoch 235
Epoch 249
Epoch 249, Loss: 0.000632646, Improvement: -0.000232366, Best Loss: 0.000136204 in Epoch 235
Epoch 250
Model saving checkpoint: the model trained after epoch 250 has been saved with the training errors.
Epoch 250, Loss: 0.000419595, Improvement: -0.000213051, Best Loss: 0.000136204 in Epoch 235
Epoch 251
Epoch 251, Loss: 0.000267544, Improvement: -0.000152051, Best Loss: 0.000136204 in Epoch 235
Epoch 252
Epoch 252, Loss: 0.000225215, Improvement: -0.000042330, Best Loss: 0.000136204 in Epoch 235
Epoch 253
Epoch 253, Loss: 0.000203283, Improvement: -0.000021932, Best Loss: 0.000136204 in Epoch 235
Epoch 254
Epoch 254, Loss: 0.000202658, Improvement: -0.000000625, Best Loss: 0.000136204 in Epoch 235
Epoch 255
A best model at epoch 255 has been saved with training error 0.000110754.
Epoch 255, Loss: 0.000194732, Improvement: -0.000007926, Best Loss: 0.000110754 in Epoch 255
Epoch 256
Epoch 256, Loss: 0.000192456, Improvement: -0.000002277, Best Loss: 0.000110754 in Epoch 255
Epoch 257
Epoch 257, Loss: 0.000180382, Improvement: -0.000012073, Best Loss: 0.000110754 in Epoch 255
Epoch 258
A best model at epoch 258 has been saved with training error 0.000106190.
Epoch 258, Loss: 0.000177184, Improvement: -0.000003198, Best Loss: 0.000106190 in Epoch 258
Epoch 259
Epoch 259, Loss: 0.000173265, Improvement: -0.000003919, Best Loss: 0.000106190 in Epoch 258
Epoch 260
Epoch 260, Loss: 0.000174419, Improvement: 0.000001153, Best Loss: 0.000106190 in Epoch 258
Epoch 261
Epoch 261, Loss: 0.000170448, Improvement: -0.000003970, Best Loss: 0.000106190 in Epoch 258
Epoch 262
A best model at epoch 262 has been saved with training error 0.000088289.
Epoch 262, Loss: 0.000174158, Improvement: 0.000003710, Best Loss: 0.000088289 in Epoch 262
Epoch 263
Epoch 263, Loss: 0.000172501, Improvement: -0.000001657, Best Loss: 0.000088289 in Epoch 262
Epoch 264
Epoch 264, Loss: 0.000165796, Improvement: -0.000006706, Best Loss: 0.000088289 in Epoch 262
Epoch 265
Epoch 265, Loss: 0.000159483, Improvement: -0.000006313, Best Loss: 0.000088289 in Epoch 262
Epoch 266
Epoch 266, Loss: 0.000158380, Improvement: -0.000001103, Best Loss: 0.000088289 in Epoch 262
Epoch 267
Epoch 267, Loss: 0.000154780, Improvement: -0.000003600, Best Loss: 0.000088289 in Epoch 262
Epoch 268
Epoch 268, Loss: 0.000152358, Improvement: -0.000002422, Best Loss: 0.000088289 in Epoch 262
Epoch 269
A best model at epoch 269 has been saved with training error 0.000087669.
Epoch 269, Loss: 0.000158457, Improvement: 0.000006099, Best Loss: 0.000087669 in Epoch 269
Epoch 270
Epoch 270, Loss: 0.000160783, Improvement: 0.000002326, Best Loss: 0.000087669 in Epoch 269
Epoch 271
Epoch 271, Loss: 0.000158506, Improvement: -0.000002278, Best Loss: 0.000087669 in Epoch 269
Epoch 272
Epoch 272, Loss: 0.000155973, Improvement: -0.000002533, Best Loss: 0.000087669 in Epoch 269
Epoch 273
Epoch 273, Loss: 0.000184566, Improvement: 0.000028593, Best Loss: 0.000087669 in Epoch 269
Epoch 274
Epoch 274, Loss: 0.000197921, Improvement: 0.000013355, Best Loss: 0.000087669 in Epoch 269
Epoch 275
Epoch 275, Loss: 0.000194760, Improvement: -0.000003161, Best Loss: 0.000087669 in Epoch 269
Epoch 276
Epoch 276, Loss: 0.000190178, Improvement: -0.000004583, Best Loss: 0.000087669 in Epoch 269
Epoch 277
Epoch 277, Loss: 0.000264721, Improvement: 0.000074543, Best Loss: 0.000087669 in Epoch 269
Epoch 278
Epoch 278, Loss: 0.000389233, Improvement: 0.000124512, Best Loss: 0.000087669 in Epoch 269
Epoch 279
Epoch 279, Loss: 0.000453835, Improvement: 0.000064602, Best Loss: 0.000087669 in Epoch 269
Epoch 280
Epoch 280, Loss: 0.000498013, Improvement: 0.000044178, Best Loss: 0.000087669 in Epoch 269
Epoch 281
Epoch 281, Loss: 0.000579720, Improvement: 0.000081707, Best Loss: 0.000087669 in Epoch 269
Epoch 282
Epoch 282, Loss: 0.000574772, Improvement: -0.000004947, Best Loss: 0.000087669 in Epoch 269
Epoch 283
Epoch 283, Loss: 0.000273062, Improvement: -0.000301711, Best Loss: 0.000087669 in Epoch 269
Epoch 284
Epoch 284, Loss: 0.000229227, Improvement: -0.000043835, Best Loss: 0.000087669 in Epoch 269
Epoch 285
Epoch 285, Loss: 0.000184803, Improvement: -0.000044424, Best Loss: 0.000087669 in Epoch 269
Epoch 286
Epoch 286, Loss: 0.000167219, Improvement: -0.000017584, Best Loss: 0.000087669 in Epoch 269
Epoch 287
Epoch 287, Loss: 0.000155699, Improvement: -0.000011521, Best Loss: 0.000087669 in Epoch 269
Epoch 288
Epoch 288, Loss: 0.000191133, Improvement: 0.000035434, Best Loss: 0.000087669 in Epoch 269
Epoch 289
Epoch 289, Loss: 0.000243825, Improvement: 0.000052692, Best Loss: 0.000087669 in Epoch 269
Epoch 290
Epoch 290, Loss: 0.000415495, Improvement: 0.000171670, Best Loss: 0.000087669 in Epoch 269
Epoch 291
Epoch 291, Loss: 0.000419440, Improvement: 0.000003945, Best Loss: 0.000087669 in Epoch 269
Epoch 292
Epoch 292, Loss: 0.000328863, Improvement: -0.000090577, Best Loss: 0.000087669 in Epoch 269
Epoch 293
Epoch 293, Loss: 0.000162672, Improvement: -0.000166191, Best Loss: 0.000087669 in Epoch 269
Epoch 294
Epoch 294, Loss: 0.000150088, Improvement: -0.000012583, Best Loss: 0.000087669 in Epoch 269
Epoch 295
Epoch 295, Loss: 0.000146033, Improvement: -0.000004056, Best Loss: 0.000087669 in Epoch 269
Epoch 296
Epoch 296, Loss: 0.000140154, Improvement: -0.000005879, Best Loss: 0.000087669 in Epoch 269
Epoch 297
Epoch 297, Loss: 0.000185551, Improvement: 0.000045397, Best Loss: 0.000087669 in Epoch 269
Epoch 298
Epoch 298, Loss: 0.000245899, Improvement: 0.000060348, Best Loss: 0.000087669 in Epoch 269
Epoch 299
Epoch 299, Loss: 0.000180677, Improvement: -0.000065222, Best Loss: 0.000087669 in Epoch 269
Epoch 300
Model saving checkpoint: the model trained after epoch 300 has been saved with the training errors.
Epoch 300, Loss: 0.000168061, Improvement: -0.000012616, Best Loss: 0.000087669 in Epoch 269
Epoch 301
Epoch 301, Loss: 0.000159879, Improvement: -0.000008182, Best Loss: 0.000087669 in Epoch 269
Epoch 302
Epoch 302, Loss: 0.000206197, Improvement: 0.000046318, Best Loss: 0.000087669 in Epoch 269
Epoch 303
Epoch 303, Loss: 0.000254878, Improvement: 0.000048681, Best Loss: 0.000087669 in Epoch 269
Epoch 304
Epoch 304, Loss: 0.000403902, Improvement: 0.000149024, Best Loss: 0.000087669 in Epoch 269
Epoch 305
Epoch 305, Loss: 0.000439609, Improvement: 0.000035707, Best Loss: 0.000087669 in Epoch 269
Epoch 306
Epoch 306, Loss: 0.000536641, Improvement: 0.000097033, Best Loss: 0.000087669 in Epoch 269
Epoch 307
Epoch 307, Loss: 0.000493381, Improvement: -0.000043260, Best Loss: 0.000087669 in Epoch 269
Epoch 308
Epoch 308, Loss: 0.000314062, Improvement: -0.000179319, Best Loss: 0.000087669 in Epoch 269
Epoch 309
Epoch 309, Loss: 0.000237783, Improvement: -0.000076279, Best Loss: 0.000087669 in Epoch 269
Epoch 310
Epoch 310, Loss: 0.000174472, Improvement: -0.000063311, Best Loss: 0.000087669 in Epoch 269
Epoch 311
A best model at epoch 311 has been saved with training error 0.000085801.
Epoch 311, Loss: 0.000145578, Improvement: -0.000028895, Best Loss: 0.000085801 in Epoch 311
Epoch 312
Epoch 312, Loss: 0.000150384, Improvement: 0.000004806, Best Loss: 0.000085801 in Epoch 311
Epoch 313
Epoch 313, Loss: 0.000183275, Improvement: 0.000032892, Best Loss: 0.000085801 in Epoch 311
Epoch 314
Epoch 314, Loss: 0.000226201, Improvement: 0.000042926, Best Loss: 0.000085801 in Epoch 311
Epoch 315
Epoch 315, Loss: 0.000235268, Improvement: 0.000009067, Best Loss: 0.000085801 in Epoch 311
Epoch 316
Epoch 316, Loss: 0.000223901, Improvement: -0.000011367, Best Loss: 0.000085801 in Epoch 311
Epoch 317
Epoch 317, Loss: 0.000234932, Improvement: 0.000011030, Best Loss: 0.000085801 in Epoch 311
Epoch 318
Epoch 318, Loss: 0.000183674, Improvement: -0.000051258, Best Loss: 0.000085801 in Epoch 311
Epoch 319
Epoch 319, Loss: 0.000392886, Improvement: 0.000209212, Best Loss: 0.000085801 in Epoch 311
Epoch 320
Epoch 320, Loss: 0.000461137, Improvement: 0.000068252, Best Loss: 0.000085801 in Epoch 311
Epoch 321
Epoch 321, Loss: 0.000792728, Improvement: 0.000331591, Best Loss: 0.000085801 in Epoch 311
Epoch 322
Epoch 322, Loss: 0.000688903, Improvement: -0.000103826, Best Loss: 0.000085801 in Epoch 311
Epoch 323
Epoch 323, Loss: 0.000434040, Improvement: -0.000254862, Best Loss: 0.000085801 in Epoch 311
Epoch 324
Epoch 324, Loss: 0.000264892, Improvement: -0.000169148, Best Loss: 0.000085801 in Epoch 311
Epoch 325
Epoch 325, Loss: 0.000285283, Improvement: 0.000020390, Best Loss: 0.000085801 in Epoch 311
Epoch 326
Epoch 326, Loss: 0.000356961, Improvement: 0.000071678, Best Loss: 0.000085801 in Epoch 311
Epoch 327
Epoch 327, Loss: 0.000383069, Improvement: 0.000026108, Best Loss: 0.000085801 in Epoch 311
Epoch 328
Epoch 328, Loss: 0.000314001, Improvement: -0.000069068, Best Loss: 0.000085801 in Epoch 311
Epoch 329
Epoch 329, Loss: 0.000335938, Improvement: 0.000021937, Best Loss: 0.000085801 in Epoch 311
Epoch 330
Epoch 330, Loss: 0.000594750, Improvement: 0.000258812, Best Loss: 0.000085801 in Epoch 311
Epoch 331
Epoch 331, Loss: 0.000806585, Improvement: 0.000211835, Best Loss: 0.000085801 in Epoch 311
Epoch 332
Epoch 332, Loss: 0.000648485, Improvement: -0.000158100, Best Loss: 0.000085801 in Epoch 311
Epoch 333
Epoch 333, Loss: 0.000479103, Improvement: -0.000169381, Best Loss: 0.000085801 in Epoch 311
Epoch 334
Epoch 334, Loss: 0.000557947, Improvement: 0.000078844, Best Loss: 0.000085801 in Epoch 311
Epoch 335
Epoch 335, Loss: 0.000557305, Improvement: -0.000000642, Best Loss: 0.000085801 in Epoch 311
Epoch 336
Epoch 336, Loss: 0.000703249, Improvement: 0.000145944, Best Loss: 0.000085801 in Epoch 311
Epoch 337
Epoch 337, Loss: 0.000314077, Improvement: -0.000389172, Best Loss: 0.000085801 in Epoch 311
Epoch 338
Epoch 338, Loss: 0.000602719, Improvement: 0.000288641, Best Loss: 0.000085801 in Epoch 311
Epoch 339
Epoch 339, Loss: 0.000325632, Improvement: -0.000277086, Best Loss: 0.000085801 in Epoch 311
Epoch 340
Epoch 340, Loss: 0.000240462, Improvement: -0.000085171, Best Loss: 0.000085801 in Epoch 311
Epoch 341
Epoch 341, Loss: 0.000189129, Improvement: -0.000051333, Best Loss: 0.000085801 in Epoch 311
Epoch 342
Epoch 342, Loss: 0.000268927, Improvement: 0.000079798, Best Loss: 0.000085801 in Epoch 311
Epoch 343
Epoch 343, Loss: 0.000324635, Improvement: 0.000055709, Best Loss: 0.000085801 in Epoch 311
Epoch 344
Epoch 344, Loss: 0.000292865, Improvement: -0.000031770, Best Loss: 0.000085801 in Epoch 311
Epoch 345
Epoch 345, Loss: 0.000231462, Improvement: -0.000061403, Best Loss: 0.000085801 in Epoch 311
Epoch 346
Epoch 346, Loss: 0.000253129, Improvement: 0.000021666, Best Loss: 0.000085801 in Epoch 311
Epoch 347
Epoch 347, Loss: 0.000277172, Improvement: 0.000024043, Best Loss: 0.000085801 in Epoch 311
Epoch 348
Epoch 348, Loss: 0.000335766, Improvement: 0.000058594, Best Loss: 0.000085801 in Epoch 311
Epoch 349
Epoch 349, Loss: 0.000252389, Improvement: -0.000083378, Best Loss: 0.000085801 in Epoch 311
Epoch 350
Model saving checkpoint: the model trained after epoch 350 has been saved with the training errors.
Epoch 350, Loss: 0.000203110, Improvement: -0.000049278, Best Loss: 0.000085801 in Epoch 311
Epoch 351
Epoch 351, Loss: 0.000237961, Improvement: 0.000034851, Best Loss: 0.000085801 in Epoch 311
Epoch 352
Epoch 352, Loss: 0.000274476, Improvement: 0.000036515, Best Loss: 0.000085801 in Epoch 311
Epoch 353
Epoch 353, Loss: 0.000226532, Improvement: -0.000047943, Best Loss: 0.000085801 in Epoch 311
Epoch 354
Epoch 354, Loss: 0.000158142, Improvement: -0.000068390, Best Loss: 0.000085801 in Epoch 311
Epoch 355
Epoch 355, Loss: 0.000196648, Improvement: 0.000038506, Best Loss: 0.000085801 in Epoch 311
Epoch 356
Epoch 356, Loss: 0.000166105, Improvement: -0.000030543, Best Loss: 0.000085801 in Epoch 311
Epoch 357
A best model at epoch 357 has been saved with training error 0.000084309.
A best model at epoch 357 has been saved with training error 0.000076045.
Epoch 357, Loss: 0.000121792, Improvement: -0.000044313, Best Loss: 0.000076045 in Epoch 357
Epoch 358
A best model at epoch 358 has been saved with training error 0.000075954.
Epoch 358, Loss: 0.000131361, Improvement: 0.000009569, Best Loss: 0.000075954 in Epoch 358
Epoch 359
A best model at epoch 359 has been saved with training error 0.000075161.
Epoch 359, Loss: 0.000160841, Improvement: 0.000029480, Best Loss: 0.000075161 in Epoch 359
Epoch 360
A best model at epoch 360 has been saved with training error 0.000072658.
Epoch 360, Loss: 0.000118165, Improvement: -0.000042677, Best Loss: 0.000072658 in Epoch 360
Epoch 361
Epoch 361, Loss: 0.000133270, Improvement: 0.000015105, Best Loss: 0.000072658 in Epoch 360
Epoch 362
A best model at epoch 362 has been saved with training error 0.000060824.
Epoch 362, Loss: 0.000177943, Improvement: 0.000044673, Best Loss: 0.000060824 in Epoch 362
Epoch 363
Epoch 363, Loss: 0.000607448, Improvement: 0.000429505, Best Loss: 0.000060824 in Epoch 362
Epoch 364
Epoch 364, Loss: 0.000817433, Improvement: 0.000209985, Best Loss: 0.000060824 in Epoch 362
Epoch 365
Epoch 365, Loss: 0.000314217, Improvement: -0.000503216, Best Loss: 0.000060824 in Epoch 362
Epoch 366
Epoch 366, Loss: 0.000285816, Improvement: -0.000028401, Best Loss: 0.000060824 in Epoch 362
Epoch 367
Epoch 367, Loss: 0.000200905, Improvement: -0.000084910, Best Loss: 0.000060824 in Epoch 362
Epoch 368
Epoch 368, Loss: 0.000165577, Improvement: -0.000035329, Best Loss: 0.000060824 in Epoch 362
Epoch 369
Epoch 369, Loss: 0.000106614, Improvement: -0.000058963, Best Loss: 0.000060824 in Epoch 362
Epoch 370
Epoch 370, Loss: 0.000158477, Improvement: 0.000051863, Best Loss: 0.000060824 in Epoch 362
Epoch 371
Epoch 371, Loss: 0.000210377, Improvement: 0.000051900, Best Loss: 0.000060824 in Epoch 362
Epoch 372
Epoch 372, Loss: 0.000136290, Improvement: -0.000074087, Best Loss: 0.000060824 in Epoch 362
Epoch 373
Epoch 373, Loss: 0.000094390, Improvement: -0.000041900, Best Loss: 0.000060824 in Epoch 362
Epoch 374
Epoch 374, Loss: 0.000091013, Improvement: -0.000003377, Best Loss: 0.000060824 in Epoch 362
Epoch 375
Epoch 375, Loss: 0.000091974, Improvement: 0.000000961, Best Loss: 0.000060824 in Epoch 362
Epoch 376
A best model at epoch 376 has been saved with training error 0.000058661.
Epoch 376, Loss: 0.000088787, Improvement: -0.000003187, Best Loss: 0.000058661 in Epoch 376
Epoch 377
Epoch 377, Loss: 0.000100647, Improvement: 0.000011860, Best Loss: 0.000058661 in Epoch 376
Epoch 378
Epoch 378, Loss: 0.000111397, Improvement: 0.000010750, Best Loss: 0.000058661 in Epoch 376
Epoch 379
A best model at epoch 379 has been saved with training error 0.000058445.
Epoch 379, Loss: 0.000102267, Improvement: -0.000009130, Best Loss: 0.000058445 in Epoch 379
Epoch 380
Epoch 380, Loss: 0.000106878, Improvement: 0.000004610, Best Loss: 0.000058445 in Epoch 379
Epoch 381
Epoch 381, Loss: 0.000118648, Improvement: 0.000011771, Best Loss: 0.000058445 in Epoch 379
Epoch 382
Epoch 382, Loss: 0.000111785, Improvement: -0.000006864, Best Loss: 0.000058445 in Epoch 379
Epoch 383
A best model at epoch 383 has been saved with training error 0.000057381.
Epoch 383, Loss: 0.000082487, Improvement: -0.000029297, Best Loss: 0.000057381 in Epoch 383
Epoch 384
A best model at epoch 384 has been saved with training error 0.000046390.
Epoch 384, Loss: 0.000076535, Improvement: -0.000005952, Best Loss: 0.000046390 in Epoch 384
Epoch 385
Epoch 385, Loss: 0.000080501, Improvement: 0.000003966, Best Loss: 0.000046390 in Epoch 384
Epoch 386
Epoch 386, Loss: 0.000097431, Improvement: 0.000016930, Best Loss: 0.000046390 in Epoch 384
Epoch 387
Epoch 387, Loss: 0.000102020, Improvement: 0.000004589, Best Loss: 0.000046390 in Epoch 384
Epoch 388
Epoch 388, Loss: 0.000093770, Improvement: -0.000008249, Best Loss: 0.000046390 in Epoch 384
Epoch 389
Epoch 389, Loss: 0.000105039, Improvement: 0.000011268, Best Loss: 0.000046390 in Epoch 384
Epoch 390
A best model at epoch 390 has been saved with training error 0.000043672.
Epoch 390, Loss: 0.000146732, Improvement: 0.000041694, Best Loss: 0.000043672 in Epoch 390
Epoch 391
Epoch 391, Loss: 0.000262887, Improvement: 0.000116155, Best Loss: 0.000043672 in Epoch 390
Epoch 392
Epoch 392, Loss: 0.000333189, Improvement: 0.000070301, Best Loss: 0.000043672 in Epoch 390
Epoch 393
Epoch 393, Loss: 0.000403406, Improvement: 0.000070217, Best Loss: 0.000043672 in Epoch 390
Epoch 394
Epoch 394, Loss: 0.000431903, Improvement: 0.000028498, Best Loss: 0.000043672 in Epoch 390
Epoch 395
Epoch 395, Loss: 0.000819816, Improvement: 0.000387913, Best Loss: 0.000043672 in Epoch 390
Epoch 396
Epoch 396, Loss: 0.000367836, Improvement: -0.000451980, Best Loss: 0.000043672 in Epoch 390
Epoch 397
Epoch 397, Loss: 0.000374178, Improvement: 0.000006342, Best Loss: 0.000043672 in Epoch 390
Epoch 398
Epoch 398, Loss: 0.000152447, Improvement: -0.000221730, Best Loss: 0.000043672 in Epoch 390
Epoch 399
Epoch 399, Loss: 0.000124811, Improvement: -0.000027636, Best Loss: 0.000043672 in Epoch 390
Epoch 400
Model saving checkpoint: the model trained after epoch 400 has been saved with the training errors.
Epoch 400, Loss: 0.000087746, Improvement: -0.000037065, Best Loss: 0.000043672 in Epoch 390
Epoch 401
Epoch 401, Loss: 0.000083017, Improvement: -0.000004729, Best Loss: 0.000043672 in Epoch 390
Epoch 402
Epoch 402, Loss: 0.000081056, Improvement: -0.000001961, Best Loss: 0.000043672 in Epoch 390
Epoch 403
Epoch 403, Loss: 0.000073887, Improvement: -0.000007169, Best Loss: 0.000043672 in Epoch 390
Epoch 404
Epoch 404, Loss: 0.000107476, Improvement: 0.000033589, Best Loss: 0.000043672 in Epoch 390
Epoch 405
Epoch 405, Loss: 0.000137243, Improvement: 0.000029767, Best Loss: 0.000043672 in Epoch 390
Epoch 406
Epoch 406, Loss: 0.000182683, Improvement: 0.000045440, Best Loss: 0.000043672 in Epoch 390
Epoch 407
Epoch 407, Loss: 0.000228280, Improvement: 0.000045597, Best Loss: 0.000043672 in Epoch 390
Epoch 408
Epoch 408, Loss: 0.000174577, Improvement: -0.000053703, Best Loss: 0.000043672 in Epoch 390
Epoch 409
Epoch 409, Loss: 0.000129192, Improvement: -0.000045385, Best Loss: 0.000043672 in Epoch 390
Epoch 410
Epoch 410, Loss: 0.000235975, Improvement: 0.000106783, Best Loss: 0.000043672 in Epoch 390
Epoch 411
Epoch 411, Loss: 0.000348848, Improvement: 0.000112873, Best Loss: 0.000043672 in Epoch 390
Epoch 412
Epoch 412, Loss: 0.000258258, Improvement: -0.000090589, Best Loss: 0.000043672 in Epoch 390
Epoch 413
Epoch 413, Loss: 0.000199526, Improvement: -0.000058732, Best Loss: 0.000043672 in Epoch 390
Epoch 414
Epoch 414, Loss: 0.000254115, Improvement: 0.000054589, Best Loss: 0.000043672 in Epoch 390
Epoch 415
Epoch 415, Loss: 0.000193282, Improvement: -0.000060833, Best Loss: 0.000043672 in Epoch 390
Epoch 416
Epoch 416, Loss: 0.000123251, Improvement: -0.000070031, Best Loss: 0.000043672 in Epoch 390
Epoch 417
Epoch 417, Loss: 0.000090939, Improvement: -0.000032312, Best Loss: 0.000043672 in Epoch 390
Epoch 418
Epoch 418, Loss: 0.000192769, Improvement: 0.000101830, Best Loss: 0.000043672 in Epoch 390
Epoch 419
Epoch 419, Loss: 0.000467088, Improvement: 0.000274319, Best Loss: 0.000043672 in Epoch 390
Epoch 420
Epoch 420, Loss: 0.000461961, Improvement: -0.000005127, Best Loss: 0.000043672 in Epoch 390
Epoch 421
Epoch 421, Loss: 0.000311779, Improvement: -0.000150182, Best Loss: 0.000043672 in Epoch 390
Epoch 422
Epoch 422, Loss: 0.000525859, Improvement: 0.000214080, Best Loss: 0.000043672 in Epoch 390
Epoch 423
Epoch 423, Loss: 0.000529194, Improvement: 0.000003335, Best Loss: 0.000043672 in Epoch 390
Epoch 424
Epoch 424, Loss: 0.000320106, Improvement: -0.000209088, Best Loss: 0.000043672 in Epoch 390
Epoch 425
Epoch 425, Loss: 0.000459482, Improvement: 0.000139376, Best Loss: 0.000043672 in Epoch 390
Epoch 426
Epoch 426, Loss: 0.000436983, Improvement: -0.000022499, Best Loss: 0.000043672 in Epoch 390
Epoch 427
Epoch 427, Loss: 0.000601290, Improvement: 0.000164307, Best Loss: 0.000043672 in Epoch 390
Epoch 428
Epoch 428, Loss: 0.000296972, Improvement: -0.000304318, Best Loss: 0.000043672 in Epoch 390
Epoch 429
Epoch 429, Loss: 0.000166162, Improvement: -0.000130810, Best Loss: 0.000043672 in Epoch 390
Epoch 430
Epoch 430, Loss: 0.000108499, Improvement: -0.000057663, Best Loss: 0.000043672 in Epoch 390
Epoch 431
Epoch 431, Loss: 0.000143645, Improvement: 0.000035146, Best Loss: 0.000043672 in Epoch 390
Epoch 432
Epoch 432, Loss: 0.000151881, Improvement: 0.000008236, Best Loss: 0.000043672 in Epoch 390
Epoch 433
Epoch 433, Loss: 0.000131144, Improvement: -0.000020737, Best Loss: 0.000043672 in Epoch 390
Epoch 434
Epoch 434, Loss: 0.000103299, Improvement: -0.000027845, Best Loss: 0.000043672 in Epoch 390
Epoch 435
Epoch 435, Loss: 0.000082724, Improvement: -0.000020575, Best Loss: 0.000043672 in Epoch 390
Epoch 436
Epoch 436, Loss: 0.000071056, Improvement: -0.000011668, Best Loss: 0.000043672 in Epoch 390
Epoch 437
A best model at epoch 437 has been saved with training error 0.000042354.
Epoch 437, Loss: 0.000081394, Improvement: 0.000010338, Best Loss: 0.000042354 in Epoch 437
Epoch 438
Epoch 438, Loss: 0.000084732, Improvement: 0.000003338, Best Loss: 0.000042354 in Epoch 437
Epoch 439
Epoch 439, Loss: 0.000093689, Improvement: 0.000008957, Best Loss: 0.000042354 in Epoch 437
Epoch 440
Epoch 440, Loss: 0.000358729, Improvement: 0.000265041, Best Loss: 0.000042354 in Epoch 437
Epoch 441
Epoch 441, Loss: 0.000355503, Improvement: -0.000003226, Best Loss: 0.000042354 in Epoch 437
Epoch 442
Epoch 442, Loss: 0.000151978, Improvement: -0.000203526, Best Loss: 0.000042354 in Epoch 437
Epoch 443
Epoch 443, Loss: 0.000095092, Improvement: -0.000056886, Best Loss: 0.000042354 in Epoch 437
Epoch 444
Epoch 444, Loss: 0.000127798, Improvement: 0.000032706, Best Loss: 0.000042354 in Epoch 437
Epoch 445
Epoch 445, Loss: 0.000174004, Improvement: 0.000046206, Best Loss: 0.000042354 in Epoch 437
Epoch 446
Epoch 446, Loss: 0.000280647, Improvement: 0.000106643, Best Loss: 0.000042354 in Epoch 437
Epoch 447
Epoch 447, Loss: 0.000184375, Improvement: -0.000096272, Best Loss: 0.000042354 in Epoch 437
Epoch 448
Epoch 448, Loss: 0.000165623, Improvement: -0.000018752, Best Loss: 0.000042354 in Epoch 437
Epoch 449
Epoch 449, Loss: 0.000230341, Improvement: 0.000064718, Best Loss: 0.000042354 in Epoch 437
Epoch 450
Model saving checkpoint: the model trained after epoch 450 has been saved with the training errors.
Epoch 450, Loss: 0.000182400, Improvement: -0.000047940, Best Loss: 0.000042354 in Epoch 437
Epoch 451
Epoch 451, Loss: 0.000167098, Improvement: -0.000015303, Best Loss: 0.000042354 in Epoch 437
Epoch 452
Epoch 452, Loss: 0.000193946, Improvement: 0.000026849, Best Loss: 0.000042354 in Epoch 437
Epoch 453
Epoch 453, Loss: 0.000415888, Improvement: 0.000221942, Best Loss: 0.000042354 in Epoch 437
Epoch 454
Epoch 454, Loss: 0.000248649, Improvement: -0.000167239, Best Loss: 0.000042354 in Epoch 437
Epoch 455
Epoch 455, Loss: 0.000157206, Improvement: -0.000091443, Best Loss: 0.000042354 in Epoch 437
Epoch 456
Epoch 456, Loss: 0.000145224, Improvement: -0.000011982, Best Loss: 0.000042354 in Epoch 437
Epoch 457
Epoch 457, Loss: 0.000141158, Improvement: -0.000004066, Best Loss: 0.000042354 in Epoch 437
Epoch 458
Epoch 458, Loss: 0.000138484, Improvement: -0.000002675, Best Loss: 0.000042354 in Epoch 437
Epoch 459
Epoch 459, Loss: 0.000297271, Improvement: 0.000158787, Best Loss: 0.000042354 in Epoch 437
Epoch 460
Epoch 460, Loss: 0.000455659, Improvement: 0.000158388, Best Loss: 0.000042354 in Epoch 437
Epoch 461
Epoch 461, Loss: 0.000442470, Improvement: -0.000013189, Best Loss: 0.000042354 in Epoch 437
Epoch 462
Epoch 462, Loss: 0.000211081, Improvement: -0.000231389, Best Loss: 0.000042354 in Epoch 437
Epoch 463
Epoch 463, Loss: 0.000147351, Improvement: -0.000063730, Best Loss: 0.000042354 in Epoch 437
Epoch 464
Epoch 464, Loss: 0.000080840, Improvement: -0.000066510, Best Loss: 0.000042354 in Epoch 437
Epoch 465
Epoch 465, Loss: 0.000081343, Improvement: 0.000000502, Best Loss: 0.000042354 in Epoch 437
Epoch 466
Epoch 466, Loss: 0.000135443, Improvement: 0.000054101, Best Loss: 0.000042354 in Epoch 437
Epoch 467
Epoch 467, Loss: 0.000427121, Improvement: 0.000291678, Best Loss: 0.000042354 in Epoch 437
Epoch 468
Epoch 468, Loss: 0.000286146, Improvement: -0.000140975, Best Loss: 0.000042354 in Epoch 437
Epoch 469
Epoch 469, Loss: 0.000119326, Improvement: -0.000166820, Best Loss: 0.000042354 in Epoch 437
Epoch 470
Epoch 470, Loss: 0.000106685, Improvement: -0.000012641, Best Loss: 0.000042354 in Epoch 437
Epoch 471
Epoch 471, Loss: 0.000084304, Improvement: -0.000022381, Best Loss: 0.000042354 in Epoch 437
Epoch 472
A best model at epoch 472 has been saved with training error 0.000032420.
Epoch 472, Loss: 0.000088931, Improvement: 0.000004627, Best Loss: 0.000032420 in Epoch 472
Epoch 473
Epoch 473, Loss: 0.000084370, Improvement: -0.000004561, Best Loss: 0.000032420 in Epoch 472
Epoch 474
Epoch 474, Loss: 0.000077087, Improvement: -0.000007283, Best Loss: 0.000032420 in Epoch 472
Epoch 475
Epoch 475, Loss: 0.000075118, Improvement: -0.000001969, Best Loss: 0.000032420 in Epoch 472
Epoch 476
Epoch 476, Loss: 0.000078658, Improvement: 0.000003540, Best Loss: 0.000032420 in Epoch 472
Epoch 477
Epoch 477, Loss: 0.000088196, Improvement: 0.000009539, Best Loss: 0.000032420 in Epoch 472
Epoch 478
Epoch 478, Loss: 0.000217111, Improvement: 0.000128915, Best Loss: 0.000032420 in Epoch 472
Epoch 479
Epoch 479, Loss: 0.000372432, Improvement: 0.000155320, Best Loss: 0.000032420 in Epoch 472
Epoch 480
Epoch 480, Loss: 0.000451447, Improvement: 0.000079016, Best Loss: 0.000032420 in Epoch 472
Epoch 481
Epoch 481, Loss: 0.000422275, Improvement: -0.000029172, Best Loss: 0.000032420 in Epoch 472
Epoch 482
Epoch 482, Loss: 0.000181721, Improvement: -0.000240554, Best Loss: 0.000032420 in Epoch 472
Epoch 483
Epoch 483, Loss: 0.000097897, Improvement: -0.000083824, Best Loss: 0.000032420 in Epoch 472
Epoch 484
Epoch 484, Loss: 0.000053673, Improvement: -0.000044225, Best Loss: 0.000032420 in Epoch 472
Epoch 485
Epoch 485, Loss: 0.000045738, Improvement: -0.000007935, Best Loss: 0.000032420 in Epoch 472
Epoch 486
A best model at epoch 486 has been saved with training error 0.000025291.
Epoch 486, Loss: 0.000047503, Improvement: 0.000001766, Best Loss: 0.000025291 in Epoch 486
Epoch 487
Epoch 487, Loss: 0.000044765, Improvement: -0.000002738, Best Loss: 0.000025291 in Epoch 486
Epoch 488
Epoch 488, Loss: 0.000042200, Improvement: -0.000002565, Best Loss: 0.000025291 in Epoch 486
Epoch 489
Epoch 489, Loss: 0.000044199, Improvement: 0.000001999, Best Loss: 0.000025291 in Epoch 486
Epoch 490
Epoch 490, Loss: 0.000040199, Improvement: -0.000004001, Best Loss: 0.000025291 in Epoch 486
Epoch 491
Epoch 491, Loss: 0.000037871, Improvement: -0.000002327, Best Loss: 0.000025291 in Epoch 486
Epoch 492
Epoch 492, Loss: 0.000036045, Improvement: -0.000001826, Best Loss: 0.000025291 in Epoch 486
Epoch 493
A best model at epoch 493 has been saved with training error 0.000024380.
Epoch 493, Loss: 0.000037238, Improvement: 0.000001193, Best Loss: 0.000024380 in Epoch 493
Epoch 494
Epoch 494, Loss: 0.000050928, Improvement: 0.000013690, Best Loss: 0.000024380 in Epoch 493
Epoch 495
Epoch 495, Loss: 0.000048348, Improvement: -0.000002580, Best Loss: 0.000024380 in Epoch 493
Epoch 496
Epoch 496, Loss: 0.000050717, Improvement: 0.000002369, Best Loss: 0.000024380 in Epoch 493
Epoch 497
Epoch 497, Loss: 0.000046981, Improvement: -0.000003736, Best Loss: 0.000024380 in Epoch 493
Epoch 498
Epoch 498, Loss: 0.000051343, Improvement: 0.000004363, Best Loss: 0.000024380 in Epoch 493
Epoch 499
Epoch 499, Loss: 0.000055314, Improvement: 0.000003971, Best Loss: 0.000024380 in Epoch 493
Epoch 500
Model saving checkpoint: the model trained after epoch 500 has been saved with the training errors.
Epoch 500, Loss: 0.000065763, Improvement: 0.000010449, Best Loss: 0.000024380 in Epoch 493
Epoch 501
Epoch 501, Loss: 0.000115929, Improvement: 0.000050166, Best Loss: 0.000024380 in Epoch 493
Epoch 502
Epoch 502, Loss: 0.000088495, Improvement: -0.000027434, Best Loss: 0.000024380 in Epoch 493
Epoch 503
Epoch 503, Loss: 0.000107823, Improvement: 0.000019328, Best Loss: 0.000024380 in Epoch 493
Epoch 504
Epoch 504, Loss: 0.000120839, Improvement: 0.000013016, Best Loss: 0.000024380 in Epoch 493
Epoch 505
Epoch 505, Loss: 0.000195985, Improvement: 0.000075146, Best Loss: 0.000024380 in Epoch 493
Epoch 506
Epoch 506, Loss: 0.000287006, Improvement: 0.000091021, Best Loss: 0.000024380 in Epoch 493
Epoch 507
Epoch 507, Loss: 0.000149107, Improvement: -0.000137900, Best Loss: 0.000024380 in Epoch 493
Epoch 508
Epoch 508, Loss: 0.000145317, Improvement: -0.000003790, Best Loss: 0.000024380 in Epoch 493
Epoch 509
Epoch 509, Loss: 0.000123658, Improvement: -0.000021659, Best Loss: 0.000024380 in Epoch 493
Epoch 510
Epoch 510, Loss: 0.000132415, Improvement: 0.000008758, Best Loss: 0.000024380 in Epoch 493
Epoch 511
Epoch 511, Loss: 0.000079753, Improvement: -0.000052663, Best Loss: 0.000024380 in Epoch 493
Epoch 512
Epoch 512, Loss: 0.000099763, Improvement: 0.000020010, Best Loss: 0.000024380 in Epoch 493
Epoch 513
Epoch 513, Loss: 0.000127316, Improvement: 0.000027554, Best Loss: 0.000024380 in Epoch 493
Epoch 514
Epoch 514, Loss: 0.000192155, Improvement: 0.000064839, Best Loss: 0.000024380 in Epoch 493
Epoch 515
Epoch 515, Loss: 0.000214202, Improvement: 0.000022047, Best Loss: 0.000024380 in Epoch 493
Epoch 516
Epoch 516, Loss: 0.000198961, Improvement: -0.000015241, Best Loss: 0.000024380 in Epoch 493
Epoch 517
Epoch 517, Loss: 0.000110552, Improvement: -0.000088409, Best Loss: 0.000024380 in Epoch 493
Epoch 518
Epoch 518, Loss: 0.000105420, Improvement: -0.000005132, Best Loss: 0.000024380 in Epoch 493
Epoch 519
Epoch 519, Loss: 0.000091994, Improvement: -0.000013426, Best Loss: 0.000024380 in Epoch 493
Epoch 520
Epoch 520, Loss: 0.000198103, Improvement: 0.000106109, Best Loss: 0.000024380 in Epoch 493
Epoch 521
Epoch 521, Loss: 0.000177022, Improvement: -0.000021081, Best Loss: 0.000024380 in Epoch 493
Epoch 522
Epoch 522, Loss: 0.000216719, Improvement: 0.000039697, Best Loss: 0.000024380 in Epoch 493
Epoch 523
Epoch 523, Loss: 0.000297821, Improvement: 0.000081103, Best Loss: 0.000024380 in Epoch 493
Epoch 524
Epoch 524, Loss: 0.000112533, Improvement: -0.000185288, Best Loss: 0.000024380 in Epoch 493
Epoch 525
Epoch 525, Loss: 0.000109450, Improvement: -0.000003083, Best Loss: 0.000024380 in Epoch 493
Epoch 526
Epoch 526, Loss: 0.000204680, Improvement: 0.000095230, Best Loss: 0.000024380 in Epoch 493
Epoch 527
Epoch 527, Loss: 0.000272539, Improvement: 0.000067860, Best Loss: 0.000024380 in Epoch 493
Epoch 528
Epoch 528, Loss: 0.000259721, Improvement: -0.000012819, Best Loss: 0.000024380 in Epoch 493
Epoch 529
Epoch 529, Loss: 0.000265994, Improvement: 0.000006274, Best Loss: 0.000024380 in Epoch 493
Epoch 530
Epoch 530, Loss: 0.000243609, Improvement: -0.000022386, Best Loss: 0.000024380 in Epoch 493
Epoch 531
Epoch 531, Loss: 0.000383011, Improvement: 0.000139402, Best Loss: 0.000024380 in Epoch 493
Epoch 532
Epoch 532, Loss: 0.000427004, Improvement: 0.000043993, Best Loss: 0.000024380 in Epoch 493
Epoch 533
Epoch 533, Loss: 0.000296534, Improvement: -0.000130470, Best Loss: 0.000024380 in Epoch 493
Epoch 534
Epoch 534, Loss: 0.000229495, Improvement: -0.000067039, Best Loss: 0.000024380 in Epoch 493
Epoch 535
Epoch 535, Loss: 0.000240529, Improvement: 0.000011034, Best Loss: 0.000024380 in Epoch 493
Epoch 536
Epoch 536, Loss: 0.000388156, Improvement: 0.000147627, Best Loss: 0.000024380 in Epoch 493
Epoch 537
Epoch 537, Loss: 0.000216464, Improvement: -0.000171692, Best Loss: 0.000024380 in Epoch 493
Epoch 538
Epoch 538, Loss: 0.000090412, Improvement: -0.000126052, Best Loss: 0.000024380 in Epoch 493
Epoch 539
Epoch 539, Loss: 0.000045851, Improvement: -0.000044562, Best Loss: 0.000024380 in Epoch 493
Epoch 540
Epoch 540, Loss: 0.000046922, Improvement: 0.000001071, Best Loss: 0.000024380 in Epoch 493
Epoch 541
Epoch 541, Loss: 0.000056750, Improvement: 0.000009828, Best Loss: 0.000024380 in Epoch 493
Epoch 542
Epoch 542, Loss: 0.000053117, Improvement: -0.000003632, Best Loss: 0.000024380 in Epoch 493
Epoch 543
Epoch 543, Loss: 0.000049470, Improvement: -0.000003647, Best Loss: 0.000024380 in Epoch 493
Epoch 544
Epoch 544, Loss: 0.000037308, Improvement: -0.000012163, Best Loss: 0.000024380 in Epoch 493
Epoch 545
A best model at epoch 545 has been saved with training error 0.000022176.
A best model at epoch 545 has been saved with training error 0.000018998.
Epoch 545, Loss: 0.000034672, Improvement: -0.000002636, Best Loss: 0.000018998 in Epoch 545
Epoch 546
Epoch 546, Loss: 0.000036952, Improvement: 0.000002280, Best Loss: 0.000018998 in Epoch 545
Epoch 547
Epoch 547, Loss: 0.000037524, Improvement: 0.000000572, Best Loss: 0.000018998 in Epoch 545
Epoch 548
Epoch 548, Loss: 0.000037656, Improvement: 0.000000132, Best Loss: 0.000018998 in Epoch 545
Epoch 549
Epoch 549, Loss: 0.000038959, Improvement: 0.000001303, Best Loss: 0.000018998 in Epoch 545
Epoch 550
Model saving checkpoint: the model trained after epoch 550 has been saved with the training errors.
Epoch 550, Loss: 0.000028721, Improvement: -0.000010239, Best Loss: 0.000018998 in Epoch 545
Epoch 551
A best model at epoch 551 has been saved with training error 0.000017634.
Epoch 551, Loss: 0.000032553, Improvement: 0.000003832, Best Loss: 0.000017634 in Epoch 551
Epoch 552
Epoch 552, Loss: 0.000068931, Improvement: 0.000036378, Best Loss: 0.000017634 in Epoch 551
Epoch 553
Epoch 553, Loss: 0.000152790, Improvement: 0.000083859, Best Loss: 0.000017634 in Epoch 551
Epoch 554
Epoch 554, Loss: 0.000238487, Improvement: 0.000085696, Best Loss: 0.000017634 in Epoch 551
Epoch 555
Epoch 555, Loss: 0.000451940, Improvement: 0.000213453, Best Loss: 0.000017634 in Epoch 551
Epoch 556
Epoch 556, Loss: 0.000477694, Improvement: 0.000025754, Best Loss: 0.000017634 in Epoch 551
Epoch 557
Epoch 557, Loss: 0.000409840, Improvement: -0.000067854, Best Loss: 0.000017634 in Epoch 551
Epoch 558
Epoch 558, Loss: 0.000369559, Improvement: -0.000040281, Best Loss: 0.000017634 in Epoch 551
Epoch 559
Epoch 559, Loss: 0.000372778, Improvement: 0.000003219, Best Loss: 0.000017634 in Epoch 551
Epoch 560
Epoch 560, Loss: 0.000240175, Improvement: -0.000132603, Best Loss: 0.000017634 in Epoch 551
Epoch 561
Epoch 561, Loss: 0.000077835, Improvement: -0.000162340, Best Loss: 0.000017634 in Epoch 551
Epoch 562
Epoch 562, Loss: 0.000048578, Improvement: -0.000029256, Best Loss: 0.000017634 in Epoch 551
Epoch 563
Epoch 563, Loss: 0.000035233, Improvement: -0.000013346, Best Loss: 0.000017634 in Epoch 551
Epoch 564
Epoch 564, Loss: 0.000030862, Improvement: -0.000004371, Best Loss: 0.000017634 in Epoch 551
Epoch 565
Epoch 565, Loss: 0.000032125, Improvement: 0.000001263, Best Loss: 0.000017634 in Epoch 551
Epoch 566
Epoch 566, Loss: 0.000038377, Improvement: 0.000006252, Best Loss: 0.000017634 in Epoch 551
Epoch 567
Epoch 567, Loss: 0.000042913, Improvement: 0.000004536, Best Loss: 0.000017634 in Epoch 551
Epoch 568
Epoch 568, Loss: 0.000032918, Improvement: -0.000009995, Best Loss: 0.000017634 in Epoch 551
Epoch 569
A best model at epoch 569 has been saved with training error 0.000015556.
Epoch 569, Loss: 0.000032575, Improvement: -0.000000342, Best Loss: 0.000015556 in Epoch 569
Epoch 570
Epoch 570, Loss: 0.000030773, Improvement: -0.000001803, Best Loss: 0.000015556 in Epoch 569
Epoch 571
Epoch 571, Loss: 0.000028640, Improvement: -0.000002133, Best Loss: 0.000015556 in Epoch 569
Epoch 572
Epoch 572, Loss: 0.000030785, Improvement: 0.000002145, Best Loss: 0.000015556 in Epoch 569
Epoch 573
Epoch 573, Loss: 0.000027412, Improvement: -0.000003373, Best Loss: 0.000015556 in Epoch 569
Epoch 574
A best model at epoch 574 has been saved with training error 0.000014726.
Epoch 574, Loss: 0.000027651, Improvement: 0.000000238, Best Loss: 0.000014726 in Epoch 574
Epoch 575
Epoch 575, Loss: 0.000026846, Improvement: -0.000000804, Best Loss: 0.000014726 in Epoch 574
Epoch 576
Epoch 576, Loss: 0.000030805, Improvement: 0.000003959, Best Loss: 0.000014726 in Epoch 574
Epoch 577
Epoch 577, Loss: 0.000033115, Improvement: 0.000002310, Best Loss: 0.000014726 in Epoch 574
Epoch 578
Epoch 578, Loss: 0.000041965, Improvement: 0.000008850, Best Loss: 0.000014726 in Epoch 574
Epoch 579
Epoch 579, Loss: 0.000039016, Improvement: -0.000002949, Best Loss: 0.000014726 in Epoch 574
Epoch 580
Epoch 580, Loss: 0.000027502, Improvement: -0.000011514, Best Loss: 0.000014726 in Epoch 574
Epoch 581
Epoch 581, Loss: 0.000025196, Improvement: -0.000002306, Best Loss: 0.000014726 in Epoch 574
Epoch 582
Epoch 582, Loss: 0.000024440, Improvement: -0.000000756, Best Loss: 0.000014726 in Epoch 574
Epoch 583
Epoch 583, Loss: 0.000023037, Improvement: -0.000001403, Best Loss: 0.000014726 in Epoch 574
Epoch 584
Epoch 584, Loss: 0.000025875, Improvement: 0.000002838, Best Loss: 0.000014726 in Epoch 574
Epoch 585
Epoch 585, Loss: 0.000026207, Improvement: 0.000000332, Best Loss: 0.000014726 in Epoch 574
Epoch 586
Epoch 586, Loss: 0.000033387, Improvement: 0.000007181, Best Loss: 0.000014726 in Epoch 574
Epoch 587
Epoch 587, Loss: 0.000034529, Improvement: 0.000001142, Best Loss: 0.000014726 in Epoch 574
Epoch 588
Epoch 588, Loss: 0.000116131, Improvement: 0.000081601, Best Loss: 0.000014726 in Epoch 574
Epoch 589
Epoch 589, Loss: 0.000144650, Improvement: 0.000028519, Best Loss: 0.000014726 in Epoch 574
Epoch 590
Epoch 590, Loss: 0.000440331, Improvement: 0.000295681, Best Loss: 0.000014726 in Epoch 574
Epoch 591
Epoch 591, Loss: 0.000274730, Improvement: -0.000165600, Best Loss: 0.000014726 in Epoch 574
Epoch 592
Epoch 592, Loss: 0.000100740, Improvement: -0.000173990, Best Loss: 0.000014726 in Epoch 574
Epoch 593
Epoch 593, Loss: 0.000061640, Improvement: -0.000039101, Best Loss: 0.000014726 in Epoch 574
Epoch 594
Epoch 594, Loss: 0.000034273, Improvement: -0.000027367, Best Loss: 0.000014726 in Epoch 574
Epoch 595
Epoch 595, Loss: 0.000027471, Improvement: -0.000006802, Best Loss: 0.000014726 in Epoch 574
Epoch 596
Epoch 596, Loss: 0.000027328, Improvement: -0.000000142, Best Loss: 0.000014726 in Epoch 574
Epoch 597
Epoch 597, Loss: 0.000029794, Improvement: 0.000002466, Best Loss: 0.000014726 in Epoch 574
Epoch 598
Epoch 598, Loss: 0.000031147, Improvement: 0.000001352, Best Loss: 0.000014726 in Epoch 574
Epoch 599
Epoch 599, Loss: 0.000030502, Improvement: -0.000000645, Best Loss: 0.000014726 in Epoch 574
Epoch 600
Model saving checkpoint: the model trained after epoch 600 has been saved with the training errors.
Epoch 600, Loss: 0.000048107, Improvement: 0.000017605, Best Loss: 0.000014726 in Epoch 574
Epoch 601
Epoch 601, Loss: 0.000038625, Improvement: -0.000009482, Best Loss: 0.000014726 in Epoch 574
Epoch 602
Epoch 602, Loss: 0.000048387, Improvement: 0.000009762, Best Loss: 0.000014726 in Epoch 574
Epoch 603
Epoch 603, Loss: 0.000050248, Improvement: 0.000001861, Best Loss: 0.000014726 in Epoch 574
Epoch 604
Epoch 604, Loss: 0.000050061, Improvement: -0.000000187, Best Loss: 0.000014726 in Epoch 574
Epoch 605
Epoch 605, Loss: 0.000062351, Improvement: 0.000012290, Best Loss: 0.000014726 in Epoch 574
Epoch 606
Epoch 606, Loss: 0.000055600, Improvement: -0.000006750, Best Loss: 0.000014726 in Epoch 574
Epoch 607
Epoch 607, Loss: 0.000062780, Improvement: 0.000007179, Best Loss: 0.000014726 in Epoch 574
Epoch 608
Epoch 608, Loss: 0.000109647, Improvement: 0.000046867, Best Loss: 0.000014726 in Epoch 574
Epoch 609
Epoch 609, Loss: 0.000232370, Improvement: 0.000122723, Best Loss: 0.000014726 in Epoch 574
Epoch 610
Epoch 610, Loss: 0.000231406, Improvement: -0.000000964, Best Loss: 0.000014726 in Epoch 574
Epoch 611
Epoch 611, Loss: 0.000120003, Improvement: -0.000111402, Best Loss: 0.000014726 in Epoch 574
Epoch 612
Epoch 612, Loss: 0.000084012, Improvement: -0.000035992, Best Loss: 0.000014726 in Epoch 574
Epoch 613
Epoch 613, Loss: 0.000144180, Improvement: 0.000060169, Best Loss: 0.000014726 in Epoch 574
Epoch 614
Epoch 614, Loss: 0.000314475, Improvement: 0.000170295, Best Loss: 0.000014726 in Epoch 574
Epoch 615
Epoch 615, Loss: 0.000633781, Improvement: 0.000319306, Best Loss: 0.000014726 in Epoch 574
Epoch 616
Epoch 616, Loss: 0.000456270, Improvement: -0.000177512, Best Loss: 0.000014726 in Epoch 574
Epoch 617
Epoch 617, Loss: 0.000278966, Improvement: -0.000177303, Best Loss: 0.000014726 in Epoch 574
Epoch 618
Epoch 618, Loss: 0.000137541, Improvement: -0.000141425, Best Loss: 0.000014726 in Epoch 574
Epoch 619
Epoch 619, Loss: 0.000102780, Improvement: -0.000034762, Best Loss: 0.000014726 in Epoch 574
Epoch 620
Epoch 620, Loss: 0.000076938, Improvement: -0.000025842, Best Loss: 0.000014726 in Epoch 574
Epoch 621
Epoch 621, Loss: 0.000083217, Improvement: 0.000006279, Best Loss: 0.000014726 in Epoch 574
Epoch 622
Epoch 622, Loss: 0.000072418, Improvement: -0.000010799, Best Loss: 0.000014726 in Epoch 574
Epoch 623
Epoch 623, Loss: 0.000048446, Improvement: -0.000023972, Best Loss: 0.000014726 in Epoch 574
Epoch 624
Epoch 624, Loss: 0.000041198, Improvement: -0.000007248, Best Loss: 0.000014726 in Epoch 574
Epoch 625
Epoch 625, Loss: 0.000046438, Improvement: 0.000005240, Best Loss: 0.000014726 in Epoch 574
Epoch 626
Epoch 626, Loss: 0.000034422, Improvement: -0.000012016, Best Loss: 0.000014726 in Epoch 574
Epoch 627
Epoch 627, Loss: 0.000033135, Improvement: -0.000001287, Best Loss: 0.000014726 in Epoch 574
Epoch 628
Epoch 628, Loss: 0.000024076, Improvement: -0.000009060, Best Loss: 0.000014726 in Epoch 574
Epoch 629
Epoch 629, Loss: 0.000022973, Improvement: -0.000001103, Best Loss: 0.000014726 in Epoch 574
Epoch 630
A best model at epoch 630 has been saved with training error 0.000014511.
A best model at epoch 630 has been saved with training error 0.000013571.
Epoch 630, Loss: 0.000022882, Improvement: -0.000000091, Best Loss: 0.000013571 in Epoch 630
Epoch 631
Epoch 631, Loss: 0.000028484, Improvement: 0.000005602, Best Loss: 0.000013571 in Epoch 630
Epoch 632
Epoch 632, Loss: 0.000051530, Improvement: 0.000023046, Best Loss: 0.000013571 in Epoch 630
Epoch 633
Epoch 633, Loss: 0.000153901, Improvement: 0.000102371, Best Loss: 0.000013571 in Epoch 630
Epoch 634
Epoch 634, Loss: 0.000336463, Improvement: 0.000182561, Best Loss: 0.000013571 in Epoch 630
Epoch 635
Epoch 635, Loss: 0.000146619, Improvement: -0.000189843, Best Loss: 0.000013571 in Epoch 630
Epoch 636
Epoch 636, Loss: 0.000201151, Improvement: 0.000054531, Best Loss: 0.000013571 in Epoch 630
Epoch 637
Epoch 637, Loss: 0.000291928, Improvement: 0.000090777, Best Loss: 0.000013571 in Epoch 630
Epoch 638
Epoch 638, Loss: 0.000231910, Improvement: -0.000060018, Best Loss: 0.000013571 in Epoch 630
Epoch 639
Epoch 639, Loss: 0.000212084, Improvement: -0.000019825, Best Loss: 0.000013571 in Epoch 630
Epoch 640
Epoch 640, Loss: 0.000195372, Improvement: -0.000016712, Best Loss: 0.000013571 in Epoch 630
Epoch 641
Epoch 641, Loss: 0.000159155, Improvement: -0.000036217, Best Loss: 0.000013571 in Epoch 630
Epoch 642
Epoch 642, Loss: 0.000235640, Improvement: 0.000076485, Best Loss: 0.000013571 in Epoch 630
Epoch 643
Epoch 643, Loss: 0.000361387, Improvement: 0.000125746, Best Loss: 0.000013571 in Epoch 630
Epoch 644
Epoch 644, Loss: 0.000126431, Improvement: -0.000234956, Best Loss: 0.000013571 in Epoch 630
Epoch 645
Epoch 645, Loss: 0.000076098, Improvement: -0.000050332, Best Loss: 0.000013571 in Epoch 630
Epoch 646
Epoch 646, Loss: 0.000043149, Improvement: -0.000032949, Best Loss: 0.000013571 in Epoch 630
Epoch 647
Epoch 647, Loss: 0.000038457, Improvement: -0.000004692, Best Loss: 0.000013571 in Epoch 630
Epoch 648
Epoch 648, Loss: 0.000032561, Improvement: -0.000005896, Best Loss: 0.000013571 in Epoch 630
Epoch 649
Epoch 649, Loss: 0.000028981, Improvement: -0.000003580, Best Loss: 0.000013571 in Epoch 630
Epoch 650
Model saving checkpoint: the model trained after epoch 650 has been saved with the training errors.
Epoch 650, Loss: 0.000028760, Improvement: -0.000000221, Best Loss: 0.000013571 in Epoch 630
Epoch 651
Epoch 651, Loss: 0.000028380, Improvement: -0.000000380, Best Loss: 0.000013571 in Epoch 630
Epoch 652
Epoch 652, Loss: 0.000026451, Improvement: -0.000001930, Best Loss: 0.000013571 in Epoch 630
Epoch 653
Epoch 653, Loss: 0.000030743, Improvement: 0.000004292, Best Loss: 0.000013571 in Epoch 630
Epoch 654
Epoch 654, Loss: 0.000026077, Improvement: -0.000004666, Best Loss: 0.000013571 in Epoch 630
Epoch 655
Epoch 655, Loss: 0.000037697, Improvement: 0.000011620, Best Loss: 0.000013571 in Epoch 630
Epoch 656
Epoch 656, Loss: 0.000026119, Improvement: -0.000011577, Best Loss: 0.000013571 in Epoch 630
Epoch 657
Epoch 657, Loss: 0.000025623, Improvement: -0.000000496, Best Loss: 0.000013571 in Epoch 630
Epoch 658
Epoch 658, Loss: 0.000025895, Improvement: 0.000000272, Best Loss: 0.000013571 in Epoch 630
Epoch 659
Epoch 659, Loss: 0.000028340, Improvement: 0.000002445, Best Loss: 0.000013571 in Epoch 630
Epoch 660
Epoch 660, Loss: 0.000030942, Improvement: 0.000002603, Best Loss: 0.000013571 in Epoch 630
Epoch 661
Epoch 661, Loss: 0.000049261, Improvement: 0.000018318, Best Loss: 0.000013571 in Epoch 630
Epoch 662
Epoch 662, Loss: 0.000046516, Improvement: -0.000002745, Best Loss: 0.000013571 in Epoch 630
Epoch 663
Epoch 663, Loss: 0.000031213, Improvement: -0.000015302, Best Loss: 0.000013571 in Epoch 630
Epoch 664
Epoch 664, Loss: 0.000026971, Improvement: -0.000004243, Best Loss: 0.000013571 in Epoch 630
Epoch 665
Epoch 665, Loss: 0.000035525, Improvement: 0.000008554, Best Loss: 0.000013571 in Epoch 630
Epoch 666
Epoch 666, Loss: 0.000103767, Improvement: 0.000068242, Best Loss: 0.000013571 in Epoch 630
Epoch 667
Epoch 667, Loss: 0.000145178, Improvement: 0.000041412, Best Loss: 0.000013571 in Epoch 630
Epoch 668
Epoch 668, Loss: 0.000438234, Improvement: 0.000293056, Best Loss: 0.000013571 in Epoch 630
Epoch 669
Epoch 669, Loss: 0.000205532, Improvement: -0.000232702, Best Loss: 0.000013571 in Epoch 630
Epoch 670
Epoch 670, Loss: 0.000114951, Improvement: -0.000090581, Best Loss: 0.000013571 in Epoch 630
Epoch 671
Epoch 671, Loss: 0.000094773, Improvement: -0.000020178, Best Loss: 0.000013571 in Epoch 630
Epoch 672
Epoch 672, Loss: 0.000417186, Improvement: 0.000322413, Best Loss: 0.000013571 in Epoch 630
Epoch 673
Epoch 673, Loss: 0.000204822, Improvement: -0.000212364, Best Loss: 0.000013571 in Epoch 630
Epoch 674
Epoch 674, Loss: 0.000139701, Improvement: -0.000065121, Best Loss: 0.000013571 in Epoch 630
Epoch 675
