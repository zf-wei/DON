/people/weiz828/.conda/envs/test/lib/python3.12/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/people/weiz828/.conda/envs/test/lib/python3.12/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
The dimension of y_tensor is torch.Size([5000, 2]).
The dimension of y_expanded is torch.Size([500, 5000, 2]) after expanding.
The dimensions of the initial conditions are: (500, 50)
The dimensions of the solutions are: (500, 100, 50)
The dimension of u_tensor is torch.Size([500, 50]).
The dimension of u_expanded is torch.Size([500, 5000, 50]) after expanding.
The loaded solution dataset has dimension (500, 100, 50),
	 while the arranged linearized dataset has dimension (500, 5000).
The dimension of s_tensor is torch.Size([500, 5000]).
The dimension of s_expanded is torch.Size([500, 5000, 1]) after expanding.
Epoch 1
A best model at epoch 1 has been saved with training error 0.022380449.
A best model at epoch 1 has been saved with training error 0.018901497.
A best model at epoch 1 has been saved with training error 0.018365612.
A best model at epoch 1 has been saved with training error 0.017963264.
A best model at epoch 1 has been saved with training error 0.017879587.
A best model at epoch 1 has been saved with training error 0.016546192.
A best model at epoch 1 has been saved with training error 0.007068422.
A best model at epoch 1 has been saved with training error 0.005961511.
Epoch 1, Loss: 0.016331968, Improvement: 0.016331968, Best Loss: 0.005961511 in Epoch 1
Epoch 2
A best model at epoch 2 has been saved with training error 0.005093758.
Epoch 2, Loss: 0.010800416, Improvement: -0.005531552, Best Loss: 0.005093758 in Epoch 2
Epoch 3
Epoch 3, Loss: 0.010351903, Improvement: -0.000448513, Best Loss: 0.005093758 in Epoch 2
Epoch 4
Epoch 4, Loss: 0.010034602, Improvement: -0.000317301, Best Loss: 0.005093758 in Epoch 2
Epoch 5
Epoch 5, Loss: 0.009608086, Improvement: -0.000426516, Best Loss: 0.005093758 in Epoch 2
Epoch 6
Epoch 6, Loss: 0.008707879, Improvement: -0.000900207, Best Loss: 0.005093758 in Epoch 2
Epoch 7
A best model at epoch 7 has been saved with training error 0.004779141.
A best model at epoch 7 has been saved with training error 0.004706402.
Epoch 7, Loss: 0.006918896, Improvement: -0.001788983, Best Loss: 0.004706402 in Epoch 7
Epoch 8
A best model at epoch 8 has been saved with training error 0.004058064.
Epoch 8, Loss: 0.006829487, Improvement: -0.000089409, Best Loss: 0.004058064 in Epoch 8
Epoch 9
A best model at epoch 9 has been saved with training error 0.003232434.
Epoch 9, Loss: 0.005836320, Improvement: -0.000993167, Best Loss: 0.003232434 in Epoch 9
Epoch 10
Epoch 10, Loss: 0.005432978, Improvement: -0.000403342, Best Loss: 0.003232434 in Epoch 9
Epoch 11
Epoch 11, Loss: 0.005347794, Improvement: -0.000085184, Best Loss: 0.003232434 in Epoch 9
Epoch 12
Epoch 12, Loss: 0.005423110, Improvement: 0.000075316, Best Loss: 0.003232434 in Epoch 9
Epoch 13
Epoch 13, Loss: 0.005019533, Improvement: -0.000403577, Best Loss: 0.003232434 in Epoch 9
Epoch 14
A best model at epoch 14 has been saved with training error 0.002273221.
Epoch 14, Loss: 0.004914882, Improvement: -0.000104651, Best Loss: 0.002273221 in Epoch 14
Epoch 15
Epoch 15, Loss: 0.004751186, Improvement: -0.000163696, Best Loss: 0.002273221 in Epoch 14
Epoch 16
Epoch 16, Loss: 0.004827239, Improvement: 0.000076053, Best Loss: 0.002273221 in Epoch 14
Epoch 17
Epoch 17, Loss: 0.004538229, Improvement: -0.000289010, Best Loss: 0.002273221 in Epoch 14
Epoch 18
Epoch 18, Loss: 0.004301667, Improvement: -0.000236562, Best Loss: 0.002273221 in Epoch 14
Epoch 19
Epoch 19, Loss: 0.004018068, Improvement: -0.000283599, Best Loss: 0.002273221 in Epoch 14
Epoch 20
Epoch 20, Loss: 0.004447352, Improvement: 0.000429284, Best Loss: 0.002273221 in Epoch 14
Epoch 21
Epoch 21, Loss: 0.004754474, Improvement: 0.000307121, Best Loss: 0.002273221 in Epoch 14
Epoch 22
Epoch 22, Loss: 0.004376075, Improvement: -0.000378399, Best Loss: 0.002273221 in Epoch 14
Epoch 23
Epoch 23, Loss: 0.004100022, Improvement: -0.000276053, Best Loss: 0.002273221 in Epoch 14
Epoch 24
A best model at epoch 24 has been saved with training error 0.002236331.
Epoch 24, Loss: 0.003414730, Improvement: -0.000685292, Best Loss: 0.002236331 in Epoch 24
Epoch 25
A best model at epoch 25 has been saved with training error 0.002128095.
A best model at epoch 25 has been saved with training error 0.001859226.
Epoch 25, Loss: 0.003086709, Improvement: -0.000328021, Best Loss: 0.001859226 in Epoch 25
Epoch 26
A best model at epoch 26 has been saved with training error 0.001710406.
A best model at epoch 26 has been saved with training error 0.001642848.
Epoch 26, Loss: 0.003042931, Improvement: -0.000043778, Best Loss: 0.001642848 in Epoch 26
Epoch 27
Epoch 27, Loss: 0.004363788, Improvement: 0.001320857, Best Loss: 0.001642848 in Epoch 26
Epoch 28
Epoch 28, Loss: 0.003745036, Improvement: -0.000618752, Best Loss: 0.001642848 in Epoch 26
Epoch 29
Epoch 29, Loss: 0.003256907, Improvement: -0.000488129, Best Loss: 0.001642848 in Epoch 26
Epoch 30
Epoch 30, Loss: 0.002773580, Improvement: -0.000483327, Best Loss: 0.001642848 in Epoch 26
Epoch 31
Epoch 31, Loss: 0.002568182, Improvement: -0.000205398, Best Loss: 0.001642848 in Epoch 26
Epoch 32
Epoch 32, Loss: 0.002510192, Improvement: -0.000057990, Best Loss: 0.001642848 in Epoch 26
Epoch 33
A best model at epoch 33 has been saved with training error 0.001594979.
Epoch 33, Loss: 0.002417533, Improvement: -0.000092659, Best Loss: 0.001594979 in Epoch 33
Epoch 34
Epoch 34, Loss: 0.004175171, Improvement: 0.001757638, Best Loss: 0.001594979 in Epoch 33
Epoch 35
Epoch 35, Loss: 0.003385636, Improvement: -0.000789535, Best Loss: 0.001594979 in Epoch 33
Epoch 36
Epoch 36, Loss: 0.002722496, Improvement: -0.000663140, Best Loss: 0.001594979 in Epoch 33
Epoch 37
A best model at epoch 37 has been saved with training error 0.001339616.
Epoch 37, Loss: 0.002414680, Improvement: -0.000307815, Best Loss: 0.001339616 in Epoch 37
Epoch 38
Epoch 38, Loss: 0.002275254, Improvement: -0.000139427, Best Loss: 0.001339616 in Epoch 37
Epoch 39
A best model at epoch 39 has been saved with training error 0.001176973.
Epoch 39, Loss: 0.002204184, Improvement: -0.000071070, Best Loss: 0.001176973 in Epoch 39
Epoch 40
Epoch 40, Loss: 0.002252240, Improvement: 0.000048056, Best Loss: 0.001176973 in Epoch 39
Epoch 41
Epoch 41, Loss: 0.002351057, Improvement: 0.000098817, Best Loss: 0.001176973 in Epoch 39
Epoch 42
Epoch 42, Loss: 0.002154092, Improvement: -0.000196965, Best Loss: 0.001176973 in Epoch 39
Epoch 43
Epoch 43, Loss: 0.002076253, Improvement: -0.000077840, Best Loss: 0.001176973 in Epoch 39
Epoch 44
Epoch 44, Loss: 0.002196018, Improvement: 0.000119765, Best Loss: 0.001176973 in Epoch 39
Epoch 45
Epoch 45, Loss: 0.003536301, Improvement: 0.001340283, Best Loss: 0.001176973 in Epoch 39
Epoch 46
Epoch 46, Loss: 0.002485494, Improvement: -0.001050806, Best Loss: 0.001176973 in Epoch 39
Epoch 47
Epoch 47, Loss: 0.002085688, Improvement: -0.000399807, Best Loss: 0.001176973 in Epoch 39
Epoch 48
A best model at epoch 48 has been saved with training error 0.000958358.
Epoch 48, Loss: 0.001976429, Improvement: -0.000109259, Best Loss: 0.000958358 in Epoch 48
Epoch 49
Epoch 49, Loss: 0.001936119, Improvement: -0.000040310, Best Loss: 0.000958358 in Epoch 48
Epoch 50
Model saving checkpoint: the model trained after epoch 50 has been saved with the training errors.
Epoch 50, Loss: 0.001895724, Improvement: -0.000040395, Best Loss: 0.000958358 in Epoch 48
Epoch 51
A best model at epoch 51 has been saved with training error 0.000940846.
Epoch 51, Loss: 0.001826165, Improvement: -0.000069559, Best Loss: 0.000940846 in Epoch 51
Epoch 52
Epoch 52, Loss: 0.001744455, Improvement: -0.000081710, Best Loss: 0.000940846 in Epoch 51
Epoch 53
Epoch 53, Loss: 0.001859451, Improvement: 0.000114996, Best Loss: 0.000940846 in Epoch 51
Epoch 54
Epoch 54, Loss: 0.004075656, Improvement: 0.002216205, Best Loss: 0.000940846 in Epoch 51
Epoch 55
Epoch 55, Loss: 0.002642682, Improvement: -0.001432974, Best Loss: 0.000940846 in Epoch 51
Epoch 56
Epoch 56, Loss: 0.002110690, Improvement: -0.000531992, Best Loss: 0.000940846 in Epoch 51
Epoch 57
Epoch 57, Loss: 0.001872321, Improvement: -0.000238369, Best Loss: 0.000940846 in Epoch 51
Epoch 58
Epoch 58, Loss: 0.001950772, Improvement: 0.000078451, Best Loss: 0.000940846 in Epoch 51
Epoch 59
Epoch 59, Loss: 0.001817342, Improvement: -0.000133430, Best Loss: 0.000940846 in Epoch 51
Epoch 60
Epoch 60, Loss: 0.001681714, Improvement: -0.000135628, Best Loss: 0.000940846 in Epoch 51
Epoch 61
A best model at epoch 61 has been saved with training error 0.000923777.
Epoch 61, Loss: 0.001609963, Improvement: -0.000071751, Best Loss: 0.000923777 in Epoch 61
Epoch 62
Epoch 62, Loss: 0.001577124, Improvement: -0.000032839, Best Loss: 0.000923777 in Epoch 61
Epoch 63
A best model at epoch 63 has been saved with training error 0.000910515.
Epoch 63, Loss: 0.001528940, Improvement: -0.000048184, Best Loss: 0.000910515 in Epoch 63
Epoch 64
Epoch 64, Loss: 0.001569445, Improvement: 0.000040505, Best Loss: 0.000910515 in Epoch 63
Epoch 65
Epoch 65, Loss: 0.001578613, Improvement: 0.000009168, Best Loss: 0.000910515 in Epoch 63
Epoch 66
Epoch 66, Loss: 0.001718483, Improvement: 0.000139870, Best Loss: 0.000910515 in Epoch 63
Epoch 67
Epoch 67, Loss: 0.004778923, Improvement: 0.003060440, Best Loss: 0.000910515 in Epoch 63
Epoch 68
Epoch 68, Loss: 0.002830217, Improvement: -0.001948706, Best Loss: 0.000910515 in Epoch 63
Epoch 69
Epoch 69, Loss: 0.002006737, Improvement: -0.000823479, Best Loss: 0.000910515 in Epoch 63
Epoch 70
Epoch 70, Loss: 0.001709673, Improvement: -0.000297065, Best Loss: 0.000910515 in Epoch 63
Epoch 71
A best model at epoch 71 has been saved with training error 0.000662002.
Epoch 71, Loss: 0.001578506, Improvement: -0.000131167, Best Loss: 0.000662002 in Epoch 71
Epoch 72
Epoch 72, Loss: 0.001502909, Improvement: -0.000075597, Best Loss: 0.000662002 in Epoch 71
Epoch 73
Epoch 73, Loss: 0.001430366, Improvement: -0.000072542, Best Loss: 0.000662002 in Epoch 71
Epoch 74
Epoch 74, Loss: 0.001392215, Improvement: -0.000038151, Best Loss: 0.000662002 in Epoch 71
Epoch 75
Epoch 75, Loss: 0.001397073, Improvement: 0.000004858, Best Loss: 0.000662002 in Epoch 71
Epoch 76
Epoch 76, Loss: 0.001389378, Improvement: -0.000007695, Best Loss: 0.000662002 in Epoch 71
Epoch 77
Epoch 77, Loss: 0.001419121, Improvement: 0.000029743, Best Loss: 0.000662002 in Epoch 71
Epoch 78
Epoch 78, Loss: 0.001605264, Improvement: 0.000186143, Best Loss: 0.000662002 in Epoch 71
Epoch 79
Epoch 79, Loss: 0.001542105, Improvement: -0.000063159, Best Loss: 0.000662002 in Epoch 71
Epoch 80
Epoch 80, Loss: 0.001354155, Improvement: -0.000187950, Best Loss: 0.000662002 in Epoch 71
Epoch 81
Epoch 81, Loss: 0.001425758, Improvement: 0.000071602, Best Loss: 0.000662002 in Epoch 71
Epoch 82
Epoch 82, Loss: 0.001339849, Improvement: -0.000085909, Best Loss: 0.000662002 in Epoch 71
Epoch 83
Epoch 83, Loss: 0.001427169, Improvement: 0.000087321, Best Loss: 0.000662002 in Epoch 71
Epoch 84
Epoch 84, Loss: 0.002848893, Improvement: 0.001421724, Best Loss: 0.000662002 in Epoch 71
Epoch 85
Epoch 85, Loss: 0.002240733, Improvement: -0.000608160, Best Loss: 0.000662002 in Epoch 71
Epoch 86
Epoch 86, Loss: 0.001635999, Improvement: -0.000604734, Best Loss: 0.000662002 in Epoch 71
Epoch 87
Epoch 87, Loss: 0.001450778, Improvement: -0.000185221, Best Loss: 0.000662002 in Epoch 71
Epoch 88
Epoch 88, Loss: 0.001332353, Improvement: -0.000118424, Best Loss: 0.000662002 in Epoch 71
Epoch 89
Epoch 89, Loss: 0.001217598, Improvement: -0.000114756, Best Loss: 0.000662002 in Epoch 71
Epoch 90
Epoch 90, Loss: 0.001145779, Improvement: -0.000071818, Best Loss: 0.000662002 in Epoch 71
Epoch 91
A best model at epoch 91 has been saved with training error 0.000627634.
Epoch 91, Loss: 0.001122447, Improvement: -0.000023332, Best Loss: 0.000627634 in Epoch 91
Epoch 92
Epoch 92, Loss: 0.001185882, Improvement: 0.000063436, Best Loss: 0.000627634 in Epoch 91
Epoch 93
Epoch 93, Loss: 0.001544264, Improvement: 0.000358382, Best Loss: 0.000627634 in Epoch 91
Epoch 94
Epoch 94, Loss: 0.001204808, Improvement: -0.000339456, Best Loss: 0.000627634 in Epoch 91
Epoch 95
A best model at epoch 95 has been saved with training error 0.000599722.
Epoch 95, Loss: 0.001273490, Improvement: 0.000068682, Best Loss: 0.000599722 in Epoch 95
Epoch 96
Epoch 96, Loss: 0.002684365, Improvement: 0.001410875, Best Loss: 0.000599722 in Epoch 95
Epoch 97
Epoch 97, Loss: 0.001722266, Improvement: -0.000962100, Best Loss: 0.000599722 in Epoch 95
Epoch 98
Epoch 98, Loss: 0.001322037, Improvement: -0.000400229, Best Loss: 0.000599722 in Epoch 95
Epoch 99
Epoch 99, Loss: 0.001153299, Improvement: -0.000168738, Best Loss: 0.000599722 in Epoch 95
Epoch 100
Model saving checkpoint: the model trained after epoch 100 has been saved with the training errors.
Epoch 100, Loss: 0.001102523, Improvement: -0.000050776, Best Loss: 0.000599722 in Epoch 95
Epoch 101
Epoch 101, Loss: 0.001047891, Improvement: -0.000054632, Best Loss: 0.000599722 in Epoch 95
Epoch 102
Epoch 102, Loss: 0.000931674, Improvement: -0.000116217, Best Loss: 0.000599722 in Epoch 95
Epoch 103
A best model at epoch 103 has been saved with training error 0.000439312.
Epoch 103, Loss: 0.000930649, Improvement: -0.000001025, Best Loss: 0.000439312 in Epoch 103
Epoch 104
Epoch 104, Loss: 0.002641619, Improvement: 0.001710970, Best Loss: 0.000439312 in Epoch 103
Epoch 105
Epoch 105, Loss: 0.002317341, Improvement: -0.000324278, Best Loss: 0.000439312 in Epoch 103
Epoch 106
Epoch 106, Loss: 0.001424941, Improvement: -0.000892400, Best Loss: 0.000439312 in Epoch 103
Epoch 107
Epoch 107, Loss: 0.001144931, Improvement: -0.000280010, Best Loss: 0.000439312 in Epoch 103
Epoch 108
Epoch 108, Loss: 0.001078869, Improvement: -0.000066061, Best Loss: 0.000439312 in Epoch 103
Epoch 109
Epoch 109, Loss: 0.001097968, Improvement: 0.000019098, Best Loss: 0.000439312 in Epoch 103
Epoch 110
Epoch 110, Loss: 0.000990964, Improvement: -0.000107004, Best Loss: 0.000439312 in Epoch 103
Epoch 111
Epoch 111, Loss: 0.000882695, Improvement: -0.000108269, Best Loss: 0.000439312 in Epoch 103
Epoch 112
Epoch 112, Loss: 0.000819225, Improvement: -0.000063469, Best Loss: 0.000439312 in Epoch 103
Epoch 113
Epoch 113, Loss: 0.000838331, Improvement: 0.000019106, Best Loss: 0.000439312 in Epoch 103
Epoch 114
Epoch 114, Loss: 0.000780866, Improvement: -0.000057466, Best Loss: 0.000439312 in Epoch 103
Epoch 115
A best model at epoch 115 has been saved with training error 0.000427398.
Epoch 115, Loss: 0.000914154, Improvement: 0.000133289, Best Loss: 0.000427398 in Epoch 115
Epoch 116
Epoch 116, Loss: 0.001859056, Improvement: 0.000944902, Best Loss: 0.000427398 in Epoch 115
Epoch 117
Epoch 117, Loss: 0.001181306, Improvement: -0.000677750, Best Loss: 0.000427398 in Epoch 115
Epoch 118
Epoch 118, Loss: 0.000892954, Improvement: -0.000288352, Best Loss: 0.000427398 in Epoch 115
Epoch 119
Epoch 119, Loss: 0.000797211, Improvement: -0.000095743, Best Loss: 0.000427398 in Epoch 115
Epoch 120
Epoch 120, Loss: 0.000717793, Improvement: -0.000079418, Best Loss: 0.000427398 in Epoch 115
Epoch 121
A best model at epoch 121 has been saved with training error 0.000415422.
Epoch 121, Loss: 0.000663521, Improvement: -0.000054272, Best Loss: 0.000415422 in Epoch 121
Epoch 122
Epoch 122, Loss: 0.000659048, Improvement: -0.000004474, Best Loss: 0.000415422 in Epoch 121
Epoch 123
Epoch 123, Loss: 0.001137716, Improvement: 0.000478669, Best Loss: 0.000415422 in Epoch 121
Epoch 124
Epoch 124, Loss: 0.000948647, Improvement: -0.000189070, Best Loss: 0.000415422 in Epoch 121
Epoch 125
A best model at epoch 125 has been saved with training error 0.000382549.
Epoch 125, Loss: 0.001039429, Improvement: 0.000090782, Best Loss: 0.000382549 in Epoch 125
Epoch 126
Epoch 126, Loss: 0.001049593, Improvement: 0.000010164, Best Loss: 0.000382549 in Epoch 125
Epoch 127
Epoch 127, Loss: 0.000822551, Improvement: -0.000227042, Best Loss: 0.000382549 in Epoch 125
Epoch 128
Epoch 128, Loss: 0.000722217, Improvement: -0.000100334, Best Loss: 0.000382549 in Epoch 125
Epoch 129
Epoch 129, Loss: 0.001392531, Improvement: 0.000670314, Best Loss: 0.000382549 in Epoch 125
Epoch 130
Epoch 130, Loss: 0.001180199, Improvement: -0.000212332, Best Loss: 0.000382549 in Epoch 125
Epoch 131
Epoch 131, Loss: 0.000750283, Improvement: -0.000429916, Best Loss: 0.000382549 in Epoch 125
Epoch 132
Epoch 132, Loss: 0.000642581, Improvement: -0.000107702, Best Loss: 0.000382549 in Epoch 125
Epoch 133
Epoch 133, Loss: 0.000598484, Improvement: -0.000044097, Best Loss: 0.000382549 in Epoch 125
Epoch 134
Epoch 134, Loss: 0.000991391, Improvement: 0.000392908, Best Loss: 0.000382549 in Epoch 125
Epoch 135
Epoch 135, Loss: 0.001427939, Improvement: 0.000436547, Best Loss: 0.000382549 in Epoch 125
Epoch 136
Epoch 136, Loss: 0.001233792, Improvement: -0.000194147, Best Loss: 0.000382549 in Epoch 125
Epoch 137
Epoch 137, Loss: 0.001146752, Improvement: -0.000087040, Best Loss: 0.000382549 in Epoch 125
Epoch 138
Epoch 138, Loss: 0.000802017, Improvement: -0.000344735, Best Loss: 0.000382549 in Epoch 125
Epoch 139
Epoch 139, Loss: 0.000654802, Improvement: -0.000147215, Best Loss: 0.000382549 in Epoch 125
Epoch 140
Epoch 140, Loss: 0.000582321, Improvement: -0.000072481, Best Loss: 0.000382549 in Epoch 125
Epoch 141
Epoch 141, Loss: 0.000541486, Improvement: -0.000040835, Best Loss: 0.000382549 in Epoch 125
Epoch 142
Epoch 142, Loss: 0.000541473, Improvement: -0.000000013, Best Loss: 0.000382549 in Epoch 125
Epoch 143
Epoch 143, Loss: 0.001941671, Improvement: 0.001400198, Best Loss: 0.000382549 in Epoch 125
Epoch 144
Epoch 144, Loss: 0.001827598, Improvement: -0.000114074, Best Loss: 0.000382549 in Epoch 125
Epoch 145
Epoch 145, Loss: 0.001328771, Improvement: -0.000498826, Best Loss: 0.000382549 in Epoch 125
Epoch 146
Epoch 146, Loss: 0.001048371, Improvement: -0.000280400, Best Loss: 0.000382549 in Epoch 125
Epoch 147
Epoch 147, Loss: 0.000833961, Improvement: -0.000214410, Best Loss: 0.000382549 in Epoch 125
Epoch 148
A best model at epoch 148 has been saved with training error 0.000362664.
Epoch 148, Loss: 0.000699203, Improvement: -0.000134759, Best Loss: 0.000362664 in Epoch 148
Epoch 149
Epoch 149, Loss: 0.000619101, Improvement: -0.000080102, Best Loss: 0.000362664 in Epoch 148
Epoch 150
Model saving checkpoint: the model trained after epoch 150 has been saved with the training errors.
Epoch 150, Loss: 0.000595882, Improvement: -0.000023219, Best Loss: 0.000362664 in Epoch 148
Epoch 151
Epoch 151, Loss: 0.000587407, Improvement: -0.000008475, Best Loss: 0.000362664 in Epoch 148
Epoch 152
Epoch 152, Loss: 0.000874110, Improvement: 0.000286703, Best Loss: 0.000362664 in Epoch 148
Epoch 153
Epoch 153, Loss: 0.000902000, Improvement: 0.000027890, Best Loss: 0.000362664 in Epoch 148
Epoch 154
A best model at epoch 154 has been saved with training error 0.000324545.
Epoch 154, Loss: 0.000607517, Improvement: -0.000294483, Best Loss: 0.000324545 in Epoch 154
Epoch 155
Epoch 155, Loss: 0.000531381, Improvement: -0.000076136, Best Loss: 0.000324545 in Epoch 154
Epoch 156
A best model at epoch 156 has been saved with training error 0.000289811.
Epoch 156, Loss: 0.000522750, Improvement: -0.000008631, Best Loss: 0.000289811 in Epoch 156
Epoch 157
Epoch 157, Loss: 0.000480919, Improvement: -0.000041831, Best Loss: 0.000289811 in Epoch 156
Epoch 158
Epoch 158, Loss: 0.000511407, Improvement: 0.000030488, Best Loss: 0.000289811 in Epoch 156
Epoch 159
Epoch 159, Loss: 0.001108963, Improvement: 0.000597556, Best Loss: 0.000289811 in Epoch 156
Epoch 160
Epoch 160, Loss: 0.000812940, Improvement: -0.000296023, Best Loss: 0.000289811 in Epoch 156
Epoch 161
Epoch 161, Loss: 0.000559566, Improvement: -0.000253374, Best Loss: 0.000289811 in Epoch 156
Epoch 162
Epoch 162, Loss: 0.000475298, Improvement: -0.000084268, Best Loss: 0.000289811 in Epoch 156
Epoch 163
A best model at epoch 163 has been saved with training error 0.000248877.
Epoch 163, Loss: 0.000437244, Improvement: -0.000038054, Best Loss: 0.000248877 in Epoch 163
Epoch 164
A best model at epoch 164 has been saved with training error 0.000244247.
Epoch 164, Loss: 0.000424746, Improvement: -0.000012498, Best Loss: 0.000244247 in Epoch 164
Epoch 165
Epoch 165, Loss: 0.000791466, Improvement: 0.000366720, Best Loss: 0.000244247 in Epoch 164
Epoch 166
Epoch 166, Loss: 0.001363858, Improvement: 0.000572391, Best Loss: 0.000244247 in Epoch 164
Epoch 167
Epoch 167, Loss: 0.000932797, Improvement: -0.000431061, Best Loss: 0.000244247 in Epoch 164
Epoch 168
Epoch 168, Loss: 0.000600757, Improvement: -0.000332040, Best Loss: 0.000244247 in Epoch 164
Epoch 169
Epoch 169, Loss: 0.000480270, Improvement: -0.000120487, Best Loss: 0.000244247 in Epoch 164
Epoch 170
Epoch 170, Loss: 0.000437519, Improvement: -0.000042750, Best Loss: 0.000244247 in Epoch 164
Epoch 171
Epoch 171, Loss: 0.000435031, Improvement: -0.000002488, Best Loss: 0.000244247 in Epoch 164
Epoch 172
Epoch 172, Loss: 0.000624010, Improvement: 0.000188978, Best Loss: 0.000244247 in Epoch 164
Epoch 173
Epoch 173, Loss: 0.000861057, Improvement: 0.000237047, Best Loss: 0.000244247 in Epoch 164
Epoch 174
Epoch 174, Loss: 0.000749969, Improvement: -0.000111088, Best Loss: 0.000244247 in Epoch 164
Epoch 175
Epoch 175, Loss: 0.000660808, Improvement: -0.000089160, Best Loss: 0.000244247 in Epoch 164
Epoch 176
Epoch 176, Loss: 0.000586948, Improvement: -0.000073861, Best Loss: 0.000244247 in Epoch 164
Epoch 177
Epoch 177, Loss: 0.000672587, Improvement: 0.000085639, Best Loss: 0.000244247 in Epoch 164
Epoch 178
Epoch 178, Loss: 0.000564145, Improvement: -0.000108442, Best Loss: 0.000244247 in Epoch 164
Epoch 179
Epoch 179, Loss: 0.000838286, Improvement: 0.000274141, Best Loss: 0.000244247 in Epoch 164
Epoch 180
Epoch 180, Loss: 0.000625353, Improvement: -0.000212933, Best Loss: 0.000244247 in Epoch 164
Epoch 181
Epoch 181, Loss: 0.000483411, Improvement: -0.000141942, Best Loss: 0.000244247 in Epoch 164
Epoch 182
Epoch 182, Loss: 0.000420103, Improvement: -0.000063308, Best Loss: 0.000244247 in Epoch 164
Epoch 183
A best model at epoch 183 has been saved with training error 0.000239555.
A best model at epoch 183 has been saved with training error 0.000222435.
Epoch 183, Loss: 0.000389063, Improvement: -0.000031041, Best Loss: 0.000222435 in Epoch 183
Epoch 184
Epoch 184, Loss: 0.000403317, Improvement: 0.000014254, Best Loss: 0.000222435 in Epoch 183
Epoch 185
Epoch 185, Loss: 0.001009382, Improvement: 0.000606065, Best Loss: 0.000222435 in Epoch 183
Epoch 186
Epoch 186, Loss: 0.000619270, Improvement: -0.000390112, Best Loss: 0.000222435 in Epoch 183
Epoch 187
Epoch 187, Loss: 0.000511797, Improvement: -0.000107473, Best Loss: 0.000222435 in Epoch 183
Epoch 188
Epoch 188, Loss: 0.000428930, Improvement: -0.000082867, Best Loss: 0.000222435 in Epoch 183
Epoch 189
Epoch 189, Loss: 0.000395294, Improvement: -0.000033636, Best Loss: 0.000222435 in Epoch 183
Epoch 190
A best model at epoch 190 has been saved with training error 0.000218517.
Epoch 190, Loss: 0.000415940, Improvement: 0.000020646, Best Loss: 0.000218517 in Epoch 190
Epoch 191
Epoch 191, Loss: 0.000356464, Improvement: -0.000059476, Best Loss: 0.000218517 in Epoch 190
Epoch 192
A best model at epoch 192 has been saved with training error 0.000210854.
Epoch 192, Loss: 0.000349351, Improvement: -0.000007112, Best Loss: 0.000210854 in Epoch 192
Epoch 193
Epoch 193, Loss: 0.000334567, Improvement: -0.000014784, Best Loss: 0.000210854 in Epoch 192
Epoch 194
Epoch 194, Loss: 0.000335722, Improvement: 0.000001155, Best Loss: 0.000210854 in Epoch 192
Epoch 195
Epoch 195, Loss: 0.000354064, Improvement: 0.000018341, Best Loss: 0.000210854 in Epoch 192
Epoch 196
Epoch 196, Loss: 0.000377588, Improvement: 0.000023524, Best Loss: 0.000210854 in Epoch 192
Epoch 197
Epoch 197, Loss: 0.000438216, Improvement: 0.000060629, Best Loss: 0.000210854 in Epoch 192
Epoch 198
Epoch 198, Loss: 0.000422908, Improvement: -0.000015309, Best Loss: 0.000210854 in Epoch 192
Epoch 199
Epoch 199, Loss: 0.000366904, Improvement: -0.000056004, Best Loss: 0.000210854 in Epoch 192
Epoch 200
Model saving checkpoint: the model trained after epoch 200 has been saved with the training errors.
Epoch 200, Loss: 0.000337879, Improvement: -0.000029025, Best Loss: 0.000210854 in Epoch 192
Epoch 201
Epoch 201, Loss: 0.000840941, Improvement: 0.000503062, Best Loss: 0.000210854 in Epoch 192
Epoch 202
Epoch 202, Loss: 0.000578894, Improvement: -0.000262047, Best Loss: 0.000210854 in Epoch 192
Epoch 203
Epoch 203, Loss: 0.000494741, Improvement: -0.000084152, Best Loss: 0.000210854 in Epoch 192
Epoch 204
Epoch 204, Loss: 0.000444364, Improvement: -0.000050378, Best Loss: 0.000210854 in Epoch 192
Epoch 205
Epoch 205, Loss: 0.000396561, Improvement: -0.000047802, Best Loss: 0.000210854 in Epoch 192
Epoch 206
Epoch 206, Loss: 0.000358350, Improvement: -0.000038211, Best Loss: 0.000210854 in Epoch 192
Epoch 207
Epoch 207, Loss: 0.000350227, Improvement: -0.000008123, Best Loss: 0.000210854 in Epoch 192
Epoch 208
Epoch 208, Loss: 0.000376740, Improvement: 0.000026512, Best Loss: 0.000210854 in Epoch 192
Epoch 209
Epoch 209, Loss: 0.000742163, Improvement: 0.000365423, Best Loss: 0.000210854 in Epoch 192
Epoch 210
Epoch 210, Loss: 0.000822923, Improvement: 0.000080760, Best Loss: 0.000210854 in Epoch 192
Epoch 211
Epoch 211, Loss: 0.000451314, Improvement: -0.000371608, Best Loss: 0.000210854 in Epoch 192
Epoch 212
Epoch 212, Loss: 0.000366737, Improvement: -0.000084577, Best Loss: 0.000210854 in Epoch 192
Epoch 213
Epoch 213, Loss: 0.000326124, Improvement: -0.000040614, Best Loss: 0.000210854 in Epoch 192
Epoch 214
A best model at epoch 214 has been saved with training error 0.000210486.
Epoch 214, Loss: 0.000309287, Improvement: -0.000016836, Best Loss: 0.000210486 in Epoch 214
Epoch 215
Epoch 215, Loss: 0.000556754, Improvement: 0.000247467, Best Loss: 0.000210486 in Epoch 214
Epoch 216
Epoch 216, Loss: 0.001123933, Improvement: 0.000567179, Best Loss: 0.000210486 in Epoch 214
Epoch 217
Epoch 217, Loss: 0.000767761, Improvement: -0.000356172, Best Loss: 0.000210486 in Epoch 214
Epoch 218
Epoch 218, Loss: 0.000506692, Improvement: -0.000261069, Best Loss: 0.000210486 in Epoch 214
Epoch 219
A best model at epoch 219 has been saved with training error 0.000202644.
Epoch 219, Loss: 0.000377997, Improvement: -0.000128695, Best Loss: 0.000202644 in Epoch 219
Epoch 220
A best model at epoch 220 has been saved with training error 0.000202202.
Epoch 220, Loss: 0.000337047, Improvement: -0.000040950, Best Loss: 0.000202202 in Epoch 220
Epoch 221
Epoch 221, Loss: 0.000311348, Improvement: -0.000025699, Best Loss: 0.000202202 in Epoch 220
Epoch 222
A best model at epoch 222 has been saved with training error 0.000178489.
Epoch 222, Loss: 0.000304192, Improvement: -0.000007155, Best Loss: 0.000178489 in Epoch 222
Epoch 223
Epoch 223, Loss: 0.000305911, Improvement: 0.000001718, Best Loss: 0.000178489 in Epoch 222
Epoch 224
Epoch 224, Loss: 0.000482752, Improvement: 0.000176841, Best Loss: 0.000178489 in Epoch 222
Epoch 225
Epoch 225, Loss: 0.000395621, Improvement: -0.000087131, Best Loss: 0.000178489 in Epoch 222
Epoch 226
Epoch 226, Loss: 0.000351626, Improvement: -0.000043994, Best Loss: 0.000178489 in Epoch 222
Epoch 227
Epoch 227, Loss: 0.000363714, Improvement: 0.000012087, Best Loss: 0.000178489 in Epoch 222
Epoch 228
Epoch 228, Loss: 0.000343744, Improvement: -0.000019969, Best Loss: 0.000178489 in Epoch 222
Epoch 229
Epoch 229, Loss: 0.000491044, Improvement: 0.000147299, Best Loss: 0.000178489 in Epoch 222
Epoch 230
Epoch 230, Loss: 0.000823957, Improvement: 0.000332913, Best Loss: 0.000178489 in Epoch 222
Epoch 231
Epoch 231, Loss: 0.000922022, Improvement: 0.000098066, Best Loss: 0.000178489 in Epoch 222
Epoch 232
Epoch 232, Loss: 0.000717257, Improvement: -0.000204765, Best Loss: 0.000178489 in Epoch 222
Epoch 233
Epoch 233, Loss: 0.000443601, Improvement: -0.000273656, Best Loss: 0.000178489 in Epoch 222
Epoch 234
Epoch 234, Loss: 0.000385476, Improvement: -0.000058125, Best Loss: 0.000178489 in Epoch 222
Epoch 235
Epoch 235, Loss: 0.000376121, Improvement: -0.000009355, Best Loss: 0.000178489 in Epoch 222
Epoch 236
Epoch 236, Loss: 0.000428314, Improvement: 0.000052192, Best Loss: 0.000178489 in Epoch 222
Epoch 237
Epoch 237, Loss: 0.000356195, Improvement: -0.000072119, Best Loss: 0.000178489 in Epoch 222
Epoch 238
Epoch 238, Loss: 0.000303099, Improvement: -0.000053096, Best Loss: 0.000178489 in Epoch 222
Epoch 239
Epoch 239, Loss: 0.000387513, Improvement: 0.000084414, Best Loss: 0.000178489 in Epoch 222
Epoch 240
Epoch 240, Loss: 0.000781175, Improvement: 0.000393662, Best Loss: 0.000178489 in Epoch 222
Epoch 241
Epoch 241, Loss: 0.000633498, Improvement: -0.000147678, Best Loss: 0.000178489 in Epoch 222
Epoch 242
Epoch 242, Loss: 0.000418797, Improvement: -0.000214701, Best Loss: 0.000178489 in Epoch 222
Epoch 243
Epoch 243, Loss: 0.000320170, Improvement: -0.000098627, Best Loss: 0.000178489 in Epoch 222
Epoch 244
A best model at epoch 244 has been saved with training error 0.000175304.
Epoch 244, Loss: 0.000277233, Improvement: -0.000042936, Best Loss: 0.000175304 in Epoch 244
Epoch 245
A best model at epoch 245 has been saved with training error 0.000173735.
Epoch 245, Loss: 0.000258885, Improvement: -0.000018348, Best Loss: 0.000173735 in Epoch 245
Epoch 246
Epoch 246, Loss: 0.000298254, Improvement: 0.000039369, Best Loss: 0.000173735 in Epoch 245
Epoch 247
Epoch 247, Loss: 0.000273085, Improvement: -0.000025169, Best Loss: 0.000173735 in Epoch 245
Epoch 248
Epoch 248, Loss: 0.000571809, Improvement: 0.000298724, Best Loss: 0.000173735 in Epoch 245
Epoch 249
Epoch 249, Loss: 0.000498473, Improvement: -0.000073336, Best Loss: 0.000173735 in Epoch 245
Epoch 250
Model saving checkpoint: the model trained after epoch 250 has been saved with the training errors.
Epoch 250, Loss: 0.000418814, Improvement: -0.000079660, Best Loss: 0.000173735 in Epoch 245
Epoch 251
Epoch 251, Loss: 0.000349056, Improvement: -0.000069758, Best Loss: 0.000173735 in Epoch 245
Epoch 252
Epoch 252, Loss: 0.000329418, Improvement: -0.000019638, Best Loss: 0.000173735 in Epoch 245
Epoch 253
Epoch 253, Loss: 0.000359744, Improvement: 0.000030326, Best Loss: 0.000173735 in Epoch 245
Epoch 254
Epoch 254, Loss: 0.000353114, Improvement: -0.000006630, Best Loss: 0.000173735 in Epoch 245
Epoch 255
Epoch 255, Loss: 0.000349610, Improvement: -0.000003503, Best Loss: 0.000173735 in Epoch 245
Epoch 256
Epoch 256, Loss: 0.000303656, Improvement: -0.000045954, Best Loss: 0.000173735 in Epoch 245
Epoch 257
Epoch 257, Loss: 0.000342013, Improvement: 0.000038357, Best Loss: 0.000173735 in Epoch 245
Epoch 258
Epoch 258, Loss: 0.000471880, Improvement: 0.000129867, Best Loss: 0.000173735 in Epoch 245
Epoch 259
Epoch 259, Loss: 0.000985330, Improvement: 0.000513450, Best Loss: 0.000173735 in Epoch 245
Epoch 260
Epoch 260, Loss: 0.000601010, Improvement: -0.000384320, Best Loss: 0.000173735 in Epoch 245
Epoch 261
Epoch 261, Loss: 0.000412701, Improvement: -0.000188309, Best Loss: 0.000173735 in Epoch 245
Epoch 262
Epoch 262, Loss: 0.000309455, Improvement: -0.000103246, Best Loss: 0.000173735 in Epoch 245
Epoch 263
Epoch 263, Loss: 0.000267984, Improvement: -0.000041471, Best Loss: 0.000173735 in Epoch 245
Epoch 264
A best model at epoch 264 has been saved with training error 0.000163218.
Epoch 264, Loss: 0.000297171, Improvement: 0.000029187, Best Loss: 0.000163218 in Epoch 264
Epoch 265
Epoch 265, Loss: 0.000374440, Improvement: 0.000077268, Best Loss: 0.000163218 in Epoch 264
Epoch 266
Epoch 266, Loss: 0.000322756, Improvement: -0.000051683, Best Loss: 0.000163218 in Epoch 264
Epoch 267
Epoch 267, Loss: 0.000423291, Improvement: 0.000100534, Best Loss: 0.000163218 in Epoch 264
Epoch 268
Epoch 268, Loss: 0.000443616, Improvement: 0.000020325, Best Loss: 0.000163218 in Epoch 264
Epoch 269
Epoch 269, Loss: 0.000619098, Improvement: 0.000175483, Best Loss: 0.000163218 in Epoch 264
Epoch 270
Epoch 270, Loss: 0.000473549, Improvement: -0.000145549, Best Loss: 0.000163218 in Epoch 264
Epoch 271
Epoch 271, Loss: 0.000455056, Improvement: -0.000018494, Best Loss: 0.000163218 in Epoch 264
Epoch 272
Epoch 272, Loss: 0.000322549, Improvement: -0.000132507, Best Loss: 0.000163218 in Epoch 264
Epoch 273
Epoch 273, Loss: 0.000279797, Improvement: -0.000042752, Best Loss: 0.000163218 in Epoch 264
Epoch 274
Epoch 274, Loss: 0.000283730, Improvement: 0.000003933, Best Loss: 0.000163218 in Epoch 264
Epoch 275
Epoch 275, Loss: 0.000316615, Improvement: 0.000032886, Best Loss: 0.000163218 in Epoch 264
Epoch 276
Epoch 276, Loss: 0.000387546, Improvement: 0.000070931, Best Loss: 0.000163218 in Epoch 264
Epoch 277
Epoch 277, Loss: 0.000525767, Improvement: 0.000138221, Best Loss: 0.000163218 in Epoch 264
Epoch 278
Epoch 278, Loss: 0.000332120, Improvement: -0.000193647, Best Loss: 0.000163218 in Epoch 264
Epoch 279
Epoch 279, Loss: 0.000255906, Improvement: -0.000076215, Best Loss: 0.000163218 in Epoch 264
Epoch 280
A best model at epoch 280 has been saved with training error 0.000142860.
Epoch 280, Loss: 0.000253954, Improvement: -0.000001952, Best Loss: 0.000142860 in Epoch 280
Epoch 281
Epoch 281, Loss: 0.000267822, Improvement: 0.000013868, Best Loss: 0.000142860 in Epoch 280
Epoch 282
Epoch 282, Loss: 0.000374511, Improvement: 0.000106690, Best Loss: 0.000142860 in Epoch 280
Epoch 283
Epoch 283, Loss: 0.000695744, Improvement: 0.000321233, Best Loss: 0.000142860 in Epoch 280
Epoch 284
Epoch 284, Loss: 0.000476406, Improvement: -0.000219338, Best Loss: 0.000142860 in Epoch 280
Epoch 285
Epoch 285, Loss: 0.000310096, Improvement: -0.000166310, Best Loss: 0.000142860 in Epoch 280
Epoch 286
Epoch 286, Loss: 0.000249145, Improvement: -0.000060951, Best Loss: 0.000142860 in Epoch 280
Epoch 287
A best model at epoch 287 has been saved with training error 0.000141277.
Epoch 287, Loss: 0.000218313, Improvement: -0.000030831, Best Loss: 0.000141277 in Epoch 287
Epoch 288
A best model at epoch 288 has been saved with training error 0.000136438.
Epoch 288, Loss: 0.000205783, Improvement: -0.000012531, Best Loss: 0.000136438 in Epoch 288
Epoch 289
A best model at epoch 289 has been saved with training error 0.000121507.
Epoch 289, Loss: 0.000194580, Improvement: -0.000011203, Best Loss: 0.000121507 in Epoch 289
Epoch 290
Epoch 290, Loss: 0.000221938, Improvement: 0.000027358, Best Loss: 0.000121507 in Epoch 289
Epoch 291
Epoch 291, Loss: 0.000223345, Improvement: 0.000001407, Best Loss: 0.000121507 in Epoch 289
Epoch 292
Epoch 292, Loss: 0.000346574, Improvement: 0.000123229, Best Loss: 0.000121507 in Epoch 289
Epoch 293
Epoch 293, Loss: 0.000348545, Improvement: 0.000001971, Best Loss: 0.000121507 in Epoch 289
Epoch 294
Epoch 294, Loss: 0.000357862, Improvement: 0.000009317, Best Loss: 0.000121507 in Epoch 289
Epoch 295
Epoch 295, Loss: 0.000303003, Improvement: -0.000054859, Best Loss: 0.000121507 in Epoch 289
Epoch 296
Epoch 296, Loss: 0.000394712, Improvement: 0.000091709, Best Loss: 0.000121507 in Epoch 289
Epoch 297
Epoch 297, Loss: 0.000318071, Improvement: -0.000076640, Best Loss: 0.000121507 in Epoch 289
Epoch 298
Epoch 298, Loss: 0.000234520, Improvement: -0.000083551, Best Loss: 0.000121507 in Epoch 289
Epoch 299
Epoch 299, Loss: 0.000202789, Improvement: -0.000031731, Best Loss: 0.000121507 in Epoch 289
Epoch 300
Model saving checkpoint: the model trained after epoch 300 has been saved with the training errors.
Epoch 300, Loss: 0.000238305, Improvement: 0.000035516, Best Loss: 0.000121507 in Epoch 289
Epoch 301
Epoch 301, Loss: 0.000603356, Improvement: 0.000365051, Best Loss: 0.000121507 in Epoch 289
Epoch 302
Epoch 302, Loss: 0.000504728, Improvement: -0.000098628, Best Loss: 0.000121507 in Epoch 289
Epoch 303
Epoch 303, Loss: 0.000345010, Improvement: -0.000159718, Best Loss: 0.000121507 in Epoch 289
Epoch 304
Epoch 304, Loss: 0.000240067, Improvement: -0.000104943, Best Loss: 0.000121507 in Epoch 289
Epoch 305
A best model at epoch 305 has been saved with training error 0.000119416.
Epoch 305, Loss: 0.000206741, Improvement: -0.000033326, Best Loss: 0.000119416 in Epoch 305
Epoch 306
Epoch 306, Loss: 0.000240588, Improvement: 0.000033847, Best Loss: 0.000119416 in Epoch 305
Epoch 307
Epoch 307, Loss: 0.000235589, Improvement: -0.000004999, Best Loss: 0.000119416 in Epoch 305
Epoch 308
Epoch 308, Loss: 0.000509645, Improvement: 0.000274056, Best Loss: 0.000119416 in Epoch 305
Epoch 309
Epoch 309, Loss: 0.000379574, Improvement: -0.000130071, Best Loss: 0.000119416 in Epoch 305
Epoch 310
Epoch 310, Loss: 0.000286192, Improvement: -0.000093382, Best Loss: 0.000119416 in Epoch 305
Epoch 311
Epoch 311, Loss: 0.000429709, Improvement: 0.000143517, Best Loss: 0.000119416 in Epoch 305
Epoch 312
Epoch 312, Loss: 0.000483507, Improvement: 0.000053798, Best Loss: 0.000119416 in Epoch 305
Epoch 313
Epoch 313, Loss: 0.000294979, Improvement: -0.000188528, Best Loss: 0.000119416 in Epoch 305
Epoch 314
Epoch 314, Loss: 0.000245197, Improvement: -0.000049782, Best Loss: 0.000119416 in Epoch 305
Epoch 315
Epoch 315, Loss: 0.000199022, Improvement: -0.000046175, Best Loss: 0.000119416 in Epoch 305
Epoch 316
A best model at epoch 316 has been saved with training error 0.000118792.
Epoch 316, Loss: 0.000172438, Improvement: -0.000026584, Best Loss: 0.000118792 in Epoch 316
Epoch 317
Epoch 317, Loss: 0.000209470, Improvement: 0.000037032, Best Loss: 0.000118792 in Epoch 316
Epoch 318
A best model at epoch 318 has been saved with training error 0.000107470.
Epoch 318, Loss: 0.000188953, Improvement: -0.000020517, Best Loss: 0.000107470 in Epoch 318
Epoch 319
Epoch 319, Loss: 0.000396952, Improvement: 0.000207999, Best Loss: 0.000107470 in Epoch 318
Epoch 320
Epoch 320, Loss: 0.000289603, Improvement: -0.000107349, Best Loss: 0.000107470 in Epoch 318
Epoch 321
Epoch 321, Loss: 0.000211714, Improvement: -0.000077889, Best Loss: 0.000107470 in Epoch 318
Epoch 322
A best model at epoch 322 has been saved with training error 0.000086578.
Epoch 322, Loss: 0.000172675, Improvement: -0.000039039, Best Loss: 0.000086578 in Epoch 322
Epoch 323
Epoch 323, Loss: 0.000151015, Improvement: -0.000021660, Best Loss: 0.000086578 in Epoch 322
Epoch 324
Epoch 324, Loss: 0.000165518, Improvement: 0.000014503, Best Loss: 0.000086578 in Epoch 322
Epoch 325
Epoch 325, Loss: 0.000248714, Improvement: 0.000083196, Best Loss: 0.000086578 in Epoch 322
Epoch 326
Epoch 326, Loss: 0.000570633, Improvement: 0.000321919, Best Loss: 0.000086578 in Epoch 322
Epoch 327
Epoch 327, Loss: 0.000360921, Improvement: -0.000209711, Best Loss: 0.000086578 in Epoch 322
Epoch 328
Epoch 328, Loss: 0.000224773, Improvement: -0.000136148, Best Loss: 0.000086578 in Epoch 322
Epoch 329
Epoch 329, Loss: 0.000221822, Improvement: -0.000002950, Best Loss: 0.000086578 in Epoch 322
Epoch 330
Epoch 330, Loss: 0.000312095, Improvement: 0.000090273, Best Loss: 0.000086578 in Epoch 322
Epoch 331
Epoch 331, Loss: 0.000194342, Improvement: -0.000117753, Best Loss: 0.000086578 in Epoch 322
Epoch 332
Epoch 332, Loss: 0.000149327, Improvement: -0.000045015, Best Loss: 0.000086578 in Epoch 322
Epoch 333
Epoch 333, Loss: 0.000147241, Improvement: -0.000002086, Best Loss: 0.000086578 in Epoch 322
Epoch 334
Epoch 334, Loss: 0.000152053, Improvement: 0.000004812, Best Loss: 0.000086578 in Epoch 322
Epoch 335
Epoch 335, Loss: 0.000160360, Improvement: 0.000008306, Best Loss: 0.000086578 in Epoch 322
Epoch 336
Epoch 336, Loss: 0.000192680, Improvement: 0.000032320, Best Loss: 0.000086578 in Epoch 322
Epoch 337
Epoch 337, Loss: 0.000433231, Improvement: 0.000240551, Best Loss: 0.000086578 in Epoch 322
Epoch 338
Epoch 338, Loss: 0.000253018, Improvement: -0.000180213, Best Loss: 0.000086578 in Epoch 322
Epoch 339
Epoch 339, Loss: 0.000263512, Improvement: 0.000010494, Best Loss: 0.000086578 in Epoch 322
Epoch 340
Epoch 340, Loss: 0.000198080, Improvement: -0.000065432, Best Loss: 0.000086578 in Epoch 322
Epoch 341
Epoch 341, Loss: 0.000167180, Improvement: -0.000030900, Best Loss: 0.000086578 in Epoch 322
Epoch 342
Epoch 342, Loss: 0.000142215, Improvement: -0.000024965, Best Loss: 0.000086578 in Epoch 322
Epoch 343
Epoch 343, Loss: 0.000131245, Improvement: -0.000010970, Best Loss: 0.000086578 in Epoch 322
Epoch 344
A best model at epoch 344 has been saved with training error 0.000079265.
A best model at epoch 344 has been saved with training error 0.000076380.
Epoch 344, Loss: 0.000122581, Improvement: -0.000008664, Best Loss: 0.000076380 in Epoch 344
Epoch 345
Epoch 345, Loss: 0.000175364, Improvement: 0.000052783, Best Loss: 0.000076380 in Epoch 344
Epoch 346
Epoch 346, Loss: 0.000239234, Improvement: 0.000063871, Best Loss: 0.000076380 in Epoch 344
Epoch 347
Epoch 347, Loss: 0.000476463, Improvement: 0.000237229, Best Loss: 0.000076380 in Epoch 344
Epoch 348
Epoch 348, Loss: 0.000286571, Improvement: -0.000189892, Best Loss: 0.000076380 in Epoch 344
Epoch 349
Epoch 349, Loss: 0.000260324, Improvement: -0.000026248, Best Loss: 0.000076380 in Epoch 344
Epoch 350
Model saving checkpoint: the model trained after epoch 350 has been saved with the training errors.
Epoch 350, Loss: 0.000374810, Improvement: 0.000114487, Best Loss: 0.000076380 in Epoch 344
Epoch 351
Epoch 351, Loss: 0.000214819, Improvement: -0.000159992, Best Loss: 0.000076380 in Epoch 344
Epoch 352
Epoch 352, Loss: 0.000161774, Improvement: -0.000053045, Best Loss: 0.000076380 in Epoch 344
Epoch 353
Epoch 353, Loss: 0.000135494, Improvement: -0.000026281, Best Loss: 0.000076380 in Epoch 344
Epoch 354
Epoch 354, Loss: 0.000179876, Improvement: 0.000044382, Best Loss: 0.000076380 in Epoch 344
Epoch 355
Epoch 355, Loss: 0.000255574, Improvement: 0.000075698, Best Loss: 0.000076380 in Epoch 344
Epoch 356
Epoch 356, Loss: 0.000286175, Improvement: 0.000030601, Best Loss: 0.000076380 in Epoch 344
Epoch 357
Epoch 357, Loss: 0.000269245, Improvement: -0.000016930, Best Loss: 0.000076380 in Epoch 344
Epoch 358
Epoch 358, Loss: 0.000194116, Improvement: -0.000075129, Best Loss: 0.000076380 in Epoch 344
Epoch 359
Epoch 359, Loss: 0.000136189, Improvement: -0.000057927, Best Loss: 0.000076380 in Epoch 344
Epoch 360
Epoch 360, Loss: 0.000155559, Improvement: 0.000019370, Best Loss: 0.000076380 in Epoch 344
Epoch 361
Epoch 361, Loss: 0.000208173, Improvement: 0.000052614, Best Loss: 0.000076380 in Epoch 344
Epoch 362
Epoch 362, Loss: 0.000161658, Improvement: -0.000046515, Best Loss: 0.000076380 in Epoch 344
Epoch 363
A best model at epoch 363 has been saved with training error 0.000065936.
Epoch 363, Loss: 0.000115392, Improvement: -0.000046266, Best Loss: 0.000065936 in Epoch 363
Epoch 364
Epoch 364, Loss: 0.000105341, Improvement: -0.000010051, Best Loss: 0.000065936 in Epoch 363
Epoch 365
A best model at epoch 365 has been saved with training error 0.000063163.
A best model at epoch 365 has been saved with training error 0.000059663.
Epoch 365, Loss: 0.000130860, Improvement: 0.000025520, Best Loss: 0.000059663 in Epoch 365
Epoch 366
Epoch 366, Loss: 0.000159270, Improvement: 0.000028410, Best Loss: 0.000059663 in Epoch 365
Epoch 367
Epoch 367, Loss: 0.000167841, Improvement: 0.000008571, Best Loss: 0.000059663 in Epoch 365
Epoch 368
Epoch 368, Loss: 0.000201723, Improvement: 0.000033882, Best Loss: 0.000059663 in Epoch 365
Epoch 369
Epoch 369, Loss: 0.000261051, Improvement: 0.000059329, Best Loss: 0.000059663 in Epoch 365
Epoch 370
Epoch 370, Loss: 0.000230020, Improvement: -0.000031031, Best Loss: 0.000059663 in Epoch 365
Epoch 371
Epoch 371, Loss: 0.000147162, Improvement: -0.000082858, Best Loss: 0.000059663 in Epoch 365
Epoch 372
Epoch 372, Loss: 0.000186939, Improvement: 0.000039777, Best Loss: 0.000059663 in Epoch 365
Epoch 373
Epoch 373, Loss: 0.000389276, Improvement: 0.000202337, Best Loss: 0.000059663 in Epoch 365
Epoch 374
Epoch 374, Loss: 0.000437803, Improvement: 0.000048527, Best Loss: 0.000059663 in Epoch 365
Epoch 375
Epoch 375, Loss: 0.000301656, Improvement: -0.000136147, Best Loss: 0.000059663 in Epoch 365
Epoch 376
Epoch 376, Loss: 0.000154896, Improvement: -0.000146760, Best Loss: 0.000059663 in Epoch 365
Epoch 377
Epoch 377, Loss: 0.000111696, Improvement: -0.000043200, Best Loss: 0.000059663 in Epoch 365
Epoch 378
Epoch 378, Loss: 0.000087722, Improvement: -0.000023974, Best Loss: 0.000059663 in Epoch 365
Epoch 379
Epoch 379, Loss: 0.000154113, Improvement: 0.000066390, Best Loss: 0.000059663 in Epoch 365
Epoch 380
Epoch 380, Loss: 0.000312567, Improvement: 0.000158454, Best Loss: 0.000059663 in Epoch 365
Epoch 381
Epoch 381, Loss: 0.000206968, Improvement: -0.000105599, Best Loss: 0.000059663 in Epoch 365
Epoch 382
Epoch 382, Loss: 0.000123161, Improvement: -0.000083807, Best Loss: 0.000059663 in Epoch 365
Epoch 383
Epoch 383, Loss: 0.000102157, Improvement: -0.000021004, Best Loss: 0.000059663 in Epoch 365
Epoch 384
Epoch 384, Loss: 0.000098099, Improvement: -0.000004058, Best Loss: 0.000059663 in Epoch 365
Epoch 385
Epoch 385, Loss: 0.000087547, Improvement: -0.000010552, Best Loss: 0.000059663 in Epoch 365
Epoch 386
A best model at epoch 386 has been saved with training error 0.000054857.
Epoch 386, Loss: 0.000084585, Improvement: -0.000002962, Best Loss: 0.000054857 in Epoch 386
Epoch 387
Epoch 387, Loss: 0.000099964, Improvement: 0.000015379, Best Loss: 0.000054857 in Epoch 386
Epoch 388
Epoch 388, Loss: 0.000251539, Improvement: 0.000151575, Best Loss: 0.000054857 in Epoch 386
Epoch 389
Epoch 389, Loss: 0.000183605, Improvement: -0.000067934, Best Loss: 0.000054857 in Epoch 386
Epoch 390
Epoch 390, Loss: 0.000116655, Improvement: -0.000066950, Best Loss: 0.000054857 in Epoch 386
Epoch 391
Epoch 391, Loss: 0.000151699, Improvement: 0.000035043, Best Loss: 0.000054857 in Epoch 386
Epoch 392
Epoch 392, Loss: 0.000319154, Improvement: 0.000167455, Best Loss: 0.000054857 in Epoch 386
Epoch 393
Epoch 393, Loss: 0.000253275, Improvement: -0.000065879, Best Loss: 0.000054857 in Epoch 386
Epoch 394
Epoch 394, Loss: 0.000320562, Improvement: 0.000067288, Best Loss: 0.000054857 in Epoch 386
Epoch 395
Epoch 395, Loss: 0.000203530, Improvement: -0.000117032, Best Loss: 0.000054857 in Epoch 386
Epoch 396
Epoch 396, Loss: 0.000103725, Improvement: -0.000099805, Best Loss: 0.000054857 in Epoch 386
Epoch 397
Epoch 397, Loss: 0.000078217, Improvement: -0.000025509, Best Loss: 0.000054857 in Epoch 386
Epoch 398
A best model at epoch 398 has been saved with training error 0.000053058.
A best model at epoch 398 has been saved with training error 0.000050116.
Epoch 398, Loss: 0.000067281, Improvement: -0.000010936, Best Loss: 0.000050116 in Epoch 398
Epoch 399
A best model at epoch 399 has been saved with training error 0.000046626.
Epoch 399, Loss: 0.000070801, Improvement: 0.000003519, Best Loss: 0.000046626 in Epoch 399
Epoch 400
Model saving checkpoint: the model trained after epoch 400 has been saved with the training errors.
Epoch 400, Loss: 0.000066491, Improvement: -0.000004310, Best Loss: 0.000046626 in Epoch 399
Epoch 401
Epoch 401, Loss: 0.000092471, Improvement: 0.000025980, Best Loss: 0.000046626 in Epoch 399
Epoch 402
Epoch 402, Loss: 0.000243999, Improvement: 0.000151529, Best Loss: 0.000046626 in Epoch 399
Epoch 403
Epoch 403, Loss: 0.000156142, Improvement: -0.000087857, Best Loss: 0.000046626 in Epoch 399
Epoch 404
Epoch 404, Loss: 0.000107391, Improvement: -0.000048751, Best Loss: 0.000046626 in Epoch 399
Epoch 405
Epoch 405, Loss: 0.000080773, Improvement: -0.000026618, Best Loss: 0.000046626 in Epoch 399
Epoch 406
Epoch 406, Loss: 0.000071302, Improvement: -0.000009471, Best Loss: 0.000046626 in Epoch 399
Epoch 407
Epoch 407, Loss: 0.000073713, Improvement: 0.000002411, Best Loss: 0.000046626 in Epoch 399
Epoch 408
Epoch 408, Loss: 0.000071636, Improvement: -0.000002076, Best Loss: 0.000046626 in Epoch 399
Epoch 409
Epoch 409, Loss: 0.000135941, Improvement: 0.000064305, Best Loss: 0.000046626 in Epoch 399
Epoch 410
Epoch 410, Loss: 0.000264441, Improvement: 0.000128500, Best Loss: 0.000046626 in Epoch 399
Epoch 411
Epoch 411, Loss: 0.000195742, Improvement: -0.000068698, Best Loss: 0.000046626 in Epoch 399
Epoch 412
Epoch 412, Loss: 0.000144465, Improvement: -0.000051277, Best Loss: 0.000046626 in Epoch 399
Epoch 413
Epoch 413, Loss: 0.000113513, Improvement: -0.000030952, Best Loss: 0.000046626 in Epoch 399
Epoch 414
Epoch 414, Loss: 0.000094103, Improvement: -0.000019410, Best Loss: 0.000046626 in Epoch 399
Epoch 415
Epoch 415, Loss: 0.000088939, Improvement: -0.000005164, Best Loss: 0.000046626 in Epoch 399
Epoch 416
Epoch 416, Loss: 0.000124313, Improvement: 0.000035374, Best Loss: 0.000046626 in Epoch 399
Epoch 417
Epoch 417, Loss: 0.000206026, Improvement: 0.000081713, Best Loss: 0.000046626 in Epoch 399
Epoch 418
Epoch 418, Loss: 0.000215191, Improvement: 0.000009165, Best Loss: 0.000046626 in Epoch 399
Epoch 419
Epoch 419, Loss: 0.000124795, Improvement: -0.000090396, Best Loss: 0.000046626 in Epoch 399
Epoch 420
Epoch 420, Loss: 0.000077721, Improvement: -0.000047074, Best Loss: 0.000046626 in Epoch 399
Epoch 421
A best model at epoch 421 has been saved with training error 0.000046170.
A best model at epoch 421 has been saved with training error 0.000045151.
Epoch 421, Loss: 0.000059391, Improvement: -0.000018330, Best Loss: 0.000045151 in Epoch 421
Epoch 422
A best model at epoch 422 has been saved with training error 0.000033613.
Epoch 422, Loss: 0.000057632, Improvement: -0.000001758, Best Loss: 0.000033613 in Epoch 422
Epoch 423
Epoch 423, Loss: 0.000086351, Improvement: 0.000028719, Best Loss: 0.000033613 in Epoch 422
Epoch 424
Epoch 424, Loss: 0.000078885, Improvement: -0.000007466, Best Loss: 0.000033613 in Epoch 422
Epoch 425
Epoch 425, Loss: 0.000075299, Improvement: -0.000003587, Best Loss: 0.000033613 in Epoch 422
Epoch 426
Epoch 426, Loss: 0.000074307, Improvement: -0.000000992, Best Loss: 0.000033613 in Epoch 422
Epoch 427
Epoch 427, Loss: 0.000129859, Improvement: 0.000055552, Best Loss: 0.000033613 in Epoch 422
Epoch 428
Epoch 428, Loss: 0.000114672, Improvement: -0.000015187, Best Loss: 0.000033613 in Epoch 422
Epoch 429
Epoch 429, Loss: 0.000132326, Improvement: 0.000017654, Best Loss: 0.000033613 in Epoch 422
Epoch 430
Epoch 430, Loss: 0.000082024, Improvement: -0.000050302, Best Loss: 0.000033613 in Epoch 422
Epoch 431
Epoch 431, Loss: 0.000070440, Improvement: -0.000011584, Best Loss: 0.000033613 in Epoch 422
Epoch 432
Epoch 432, Loss: 0.000085170, Improvement: 0.000014730, Best Loss: 0.000033613 in Epoch 422
Epoch 433
Epoch 433, Loss: 0.000077216, Improvement: -0.000007954, Best Loss: 0.000033613 in Epoch 422
Epoch 434
Epoch 434, Loss: 0.000093195, Improvement: 0.000015979, Best Loss: 0.000033613 in Epoch 422
Epoch 435
Epoch 435, Loss: 0.000116620, Improvement: 0.000023426, Best Loss: 0.000033613 in Epoch 422
Epoch 436
Epoch 436, Loss: 0.000074559, Improvement: -0.000042061, Best Loss: 0.000033613 in Epoch 422
Epoch 437
Epoch 437, Loss: 0.000077083, Improvement: 0.000002524, Best Loss: 0.000033613 in Epoch 422
Epoch 438
Epoch 438, Loss: 0.000086428, Improvement: 0.000009344, Best Loss: 0.000033613 in Epoch 422
Epoch 439
Epoch 439, Loss: 0.000096730, Improvement: 0.000010302, Best Loss: 0.000033613 in Epoch 422
Epoch 440
Epoch 440, Loss: 0.000081931, Improvement: -0.000014799, Best Loss: 0.000033613 in Epoch 422
Epoch 441
Epoch 441, Loss: 0.000080725, Improvement: -0.000001206, Best Loss: 0.000033613 in Epoch 422
Epoch 442
Epoch 442, Loss: 0.000099871, Improvement: 0.000019146, Best Loss: 0.000033613 in Epoch 422
Epoch 443
Epoch 443, Loss: 0.000132691, Improvement: 0.000032819, Best Loss: 0.000033613 in Epoch 422
Epoch 444
Epoch 444, Loss: 0.000110947, Improvement: -0.000021743, Best Loss: 0.000033613 in Epoch 422
Epoch 445
Epoch 445, Loss: 0.000068375, Improvement: -0.000042573, Best Loss: 0.000033613 in Epoch 422
Epoch 446
Epoch 446, Loss: 0.000072682, Improvement: 0.000004307, Best Loss: 0.000033613 in Epoch 422
Epoch 447
Epoch 447, Loss: 0.000069735, Improvement: -0.000002946, Best Loss: 0.000033613 in Epoch 422
Epoch 448
Epoch 448, Loss: 0.000084741, Improvement: 0.000015006, Best Loss: 0.000033613 in Epoch 422
Epoch 449
Epoch 449, Loss: 0.000227280, Improvement: 0.000142538, Best Loss: 0.000033613 in Epoch 422
Epoch 450
Model saving checkpoint: the model trained after epoch 450 has been saved with the training errors.
Epoch 450, Loss: 0.000173394, Improvement: -0.000053886, Best Loss: 0.000033613 in Epoch 422
Epoch 451
Epoch 451, Loss: 0.000097497, Improvement: -0.000075897, Best Loss: 0.000033613 in Epoch 422
Epoch 452
Epoch 452, Loss: 0.000142554, Improvement: 0.000045057, Best Loss: 0.000033613 in Epoch 422
Epoch 453
Epoch 453, Loss: 0.000187860, Improvement: 0.000045306, Best Loss: 0.000033613 in Epoch 422
Epoch 454
Epoch 454, Loss: 0.000139101, Improvement: -0.000048760, Best Loss: 0.000033613 in Epoch 422
Epoch 455
Epoch 455, Loss: 0.000136890, Improvement: -0.000002210, Best Loss: 0.000033613 in Epoch 422
Epoch 456
Epoch 456, Loss: 0.000170772, Improvement: 0.000033882, Best Loss: 0.000033613 in Epoch 422
Epoch 457
Epoch 457, Loss: 0.000086141, Improvement: -0.000084631, Best Loss: 0.000033613 in Epoch 422
Epoch 458
Epoch 458, Loss: 0.000061050, Improvement: -0.000025090, Best Loss: 0.000033613 in Epoch 422
Epoch 459
Epoch 459, Loss: 0.000076123, Improvement: 0.000015073, Best Loss: 0.000033613 in Epoch 422
Epoch 460
Epoch 460, Loss: 0.000072990, Improvement: -0.000003133, Best Loss: 0.000033613 in Epoch 422
Epoch 461
Epoch 461, Loss: 0.000055921, Improvement: -0.000017068, Best Loss: 0.000033613 in Epoch 422
Epoch 462
A best model at epoch 462 has been saved with training error 0.000033005.
A best model at epoch 462 has been saved with training error 0.000030910.
A best model at epoch 462 has been saved with training error 0.000030031.
Epoch 462, Loss: 0.000042198, Improvement: -0.000013723, Best Loss: 0.000030031 in Epoch 462
Epoch 463
A best model at epoch 463 has been saved with training error 0.000029909.
A best model at epoch 463 has been saved with training error 0.000029252.
A best model at epoch 463 has been saved with training error 0.000023831.
Epoch 463, Loss: 0.000034852, Improvement: -0.000007347, Best Loss: 0.000023831 in Epoch 463
Epoch 464
Epoch 464, Loss: 0.000031588, Improvement: -0.000003263, Best Loss: 0.000023831 in Epoch 463
Epoch 465
A best model at epoch 465 has been saved with training error 0.000021231.
Epoch 465, Loss: 0.000032229, Improvement: 0.000000640, Best Loss: 0.000021231 in Epoch 465
Epoch 466
Epoch 466, Loss: 0.000041138, Improvement: 0.000008909, Best Loss: 0.000021231 in Epoch 465
Epoch 467
Epoch 467, Loss: 0.000132984, Improvement: 0.000091846, Best Loss: 0.000021231 in Epoch 465
Epoch 468
Epoch 468, Loss: 0.000129739, Improvement: -0.000003244, Best Loss: 0.000021231 in Epoch 465
Epoch 469
Epoch 469, Loss: 0.000082432, Improvement: -0.000047307, Best Loss: 0.000021231 in Epoch 465
Epoch 470
Epoch 470, Loss: 0.000055183, Improvement: -0.000027249, Best Loss: 0.000021231 in Epoch 465
Epoch 471
Epoch 471, Loss: 0.000042002, Improvement: -0.000013181, Best Loss: 0.000021231 in Epoch 465
Epoch 472
Epoch 472, Loss: 0.000054034, Improvement: 0.000012032, Best Loss: 0.000021231 in Epoch 465
Epoch 473
Epoch 473, Loss: 0.000035865, Improvement: -0.000018169, Best Loss: 0.000021231 in Epoch 465
Epoch 474
Epoch 474, Loss: 0.000035366, Improvement: -0.000000499, Best Loss: 0.000021231 in Epoch 465
Epoch 475
Epoch 475, Loss: 0.000039491, Improvement: 0.000004125, Best Loss: 0.000021231 in Epoch 465
Epoch 476
Epoch 476, Loss: 0.000035464, Improvement: -0.000004027, Best Loss: 0.000021231 in Epoch 465
Epoch 477
Epoch 477, Loss: 0.000041751, Improvement: 0.000006287, Best Loss: 0.000021231 in Epoch 465
Epoch 478
Epoch 478, Loss: 0.000068441, Improvement: 0.000026690, Best Loss: 0.000021231 in Epoch 465
Epoch 479
Epoch 479, Loss: 0.000074555, Improvement: 0.000006114, Best Loss: 0.000021231 in Epoch 465
Epoch 480
Epoch 480, Loss: 0.000099095, Improvement: 0.000024540, Best Loss: 0.000021231 in Epoch 465
Epoch 481
Epoch 481, Loss: 0.000166331, Improvement: 0.000067236, Best Loss: 0.000021231 in Epoch 465
Epoch 482
Epoch 482, Loss: 0.000097889, Improvement: -0.000068442, Best Loss: 0.000021231 in Epoch 465
Epoch 483
Epoch 483, Loss: 0.000062853, Improvement: -0.000035035, Best Loss: 0.000021231 in Epoch 465
Epoch 484
Epoch 484, Loss: 0.000060641, Improvement: -0.000002213, Best Loss: 0.000021231 in Epoch 465
Epoch 485
Epoch 485, Loss: 0.000043002, Improvement: -0.000017639, Best Loss: 0.000021231 in Epoch 465
Epoch 486
Epoch 486, Loss: 0.000035153, Improvement: -0.000007848, Best Loss: 0.000021231 in Epoch 465
Epoch 487
Epoch 487, Loss: 0.000058789, Improvement: 0.000023636, Best Loss: 0.000021231 in Epoch 465
Epoch 488
Epoch 488, Loss: 0.000116381, Improvement: 0.000057592, Best Loss: 0.000021231 in Epoch 465
Epoch 489
Epoch 489, Loss: 0.000150254, Improvement: 0.000033873, Best Loss: 0.000021231 in Epoch 465
Epoch 490
Epoch 490, Loss: 0.000092902, Improvement: -0.000057352, Best Loss: 0.000021231 in Epoch 465
Epoch 491
Epoch 491, Loss: 0.000064282, Improvement: -0.000028620, Best Loss: 0.000021231 in Epoch 465
Epoch 492
Epoch 492, Loss: 0.000047020, Improvement: -0.000017262, Best Loss: 0.000021231 in Epoch 465
Epoch 493
Epoch 493, Loss: 0.000038619, Improvement: -0.000008400, Best Loss: 0.000021231 in Epoch 465
Epoch 494
Epoch 494, Loss: 0.000036316, Improvement: -0.000002303, Best Loss: 0.000021231 in Epoch 465
Epoch 495
A best model at epoch 495 has been saved with training error 0.000020994.
Epoch 495, Loss: 0.000030814, Improvement: -0.000005502, Best Loss: 0.000020994 in Epoch 495
Epoch 496
Epoch 496, Loss: 0.000029904, Improvement: -0.000000910, Best Loss: 0.000020994 in Epoch 495
Epoch 497
A best model at epoch 497 has been saved with training error 0.000020842.
Epoch 497, Loss: 0.000029507, Improvement: -0.000000396, Best Loss: 0.000020842 in Epoch 497
Epoch 498
A best model at epoch 498 has been saved with training error 0.000019342.
Epoch 498, Loss: 0.000031355, Improvement: 0.000001848, Best Loss: 0.000019342 in Epoch 498
Epoch 499
Epoch 499, Loss: 0.000122091, Improvement: 0.000090736, Best Loss: 0.000019342 in Epoch 498
Epoch 500
Model saving checkpoint: the model trained after epoch 500 has been saved with the training errors.
Epoch 500, Loss: 0.000152667, Improvement: 0.000030575, Best Loss: 0.000019342 in Epoch 498
Epoch 501
Epoch 501, Loss: 0.000094335, Improvement: -0.000058332, Best Loss: 0.000019342 in Epoch 498
Epoch 502
Epoch 502, Loss: 0.000092613, Improvement: -0.000001722, Best Loss: 0.000019342 in Epoch 498
Epoch 503
Epoch 503, Loss: 0.000077609, Improvement: -0.000015004, Best Loss: 0.000019342 in Epoch 498
Epoch 504
Epoch 504, Loss: 0.000050986, Improvement: -0.000026623, Best Loss: 0.000019342 in Epoch 498
Epoch 505
Epoch 505, Loss: 0.000041346, Improvement: -0.000009640, Best Loss: 0.000019342 in Epoch 498
Epoch 506
Epoch 506, Loss: 0.000044576, Improvement: 0.000003230, Best Loss: 0.000019342 in Epoch 498
Epoch 507
Epoch 507, Loss: 0.000140988, Improvement: 0.000096412, Best Loss: 0.000019342 in Epoch 498
Epoch 508
Epoch 508, Loss: 0.000078250, Improvement: -0.000062738, Best Loss: 0.000019342 in Epoch 498
Epoch 509
Epoch 509, Loss: 0.000047192, Improvement: -0.000031058, Best Loss: 0.000019342 in Epoch 498
Epoch 510
Epoch 510, Loss: 0.000055624, Improvement: 0.000008432, Best Loss: 0.000019342 in Epoch 498
Epoch 511
Epoch 511, Loss: 0.000053433, Improvement: -0.000002192, Best Loss: 0.000019342 in Epoch 498
Epoch 512
Epoch 512, Loss: 0.000054060, Improvement: 0.000000627, Best Loss: 0.000019342 in Epoch 498
Epoch 513
Epoch 513, Loss: 0.000071874, Improvement: 0.000017815, Best Loss: 0.000019342 in Epoch 498
Epoch 514
Epoch 514, Loss: 0.000065706, Improvement: -0.000006168, Best Loss: 0.000019342 in Epoch 498
Epoch 515
Epoch 515, Loss: 0.000061821, Improvement: -0.000003885, Best Loss: 0.000019342 in Epoch 498
Epoch 516
Epoch 516, Loss: 0.000044199, Improvement: -0.000017622, Best Loss: 0.000019342 in Epoch 498
Epoch 517
Epoch 517, Loss: 0.000030209, Improvement: -0.000013990, Best Loss: 0.000019342 in Epoch 498
Epoch 518
Epoch 518, Loss: 0.000031567, Improvement: 0.000001358, Best Loss: 0.000019342 in Epoch 498
Epoch 519
Epoch 519, Loss: 0.000051941, Improvement: 0.000020374, Best Loss: 0.000019342 in Epoch 498
Epoch 520
Epoch 520, Loss: 0.000101824, Improvement: 0.000049883, Best Loss: 0.000019342 in Epoch 498
Epoch 521
Epoch 521, Loss: 0.000130491, Improvement: 0.000028668, Best Loss: 0.000019342 in Epoch 498
Epoch 522
Epoch 522, Loss: 0.000087334, Improvement: -0.000043157, Best Loss: 0.000019342 in Epoch 498
Epoch 523
Epoch 523, Loss: 0.000082544, Improvement: -0.000004790, Best Loss: 0.000019342 in Epoch 498
Epoch 524
Epoch 524, Loss: 0.000063409, Improvement: -0.000019135, Best Loss: 0.000019342 in Epoch 498
Epoch 525
Epoch 525, Loss: 0.000052090, Improvement: -0.000011319, Best Loss: 0.000019342 in Epoch 498
Epoch 526
Epoch 526, Loss: 0.000045968, Improvement: -0.000006123, Best Loss: 0.000019342 in Epoch 498
Epoch 527
A best model at epoch 527 has been saved with training error 0.000018893.
Epoch 527, Loss: 0.000033177, Improvement: -0.000012790, Best Loss: 0.000018893 in Epoch 527
Epoch 528
Epoch 528, Loss: 0.000037033, Improvement: 0.000003856, Best Loss: 0.000018893 in Epoch 527
Epoch 529
Epoch 529, Loss: 0.000095163, Improvement: 0.000058130, Best Loss: 0.000018893 in Epoch 527
Epoch 530
Epoch 530, Loss: 0.000106085, Improvement: 0.000010922, Best Loss: 0.000018893 in Epoch 527
Epoch 531
Epoch 531, Loss: 0.000083913, Improvement: -0.000022172, Best Loss: 0.000018893 in Epoch 527
Epoch 532
Epoch 532, Loss: 0.000053961, Improvement: -0.000029952, Best Loss: 0.000018893 in Epoch 527
Epoch 533
Epoch 533, Loss: 0.000044138, Improvement: -0.000009823, Best Loss: 0.000018893 in Epoch 527
Epoch 534
Epoch 534, Loss: 0.000050445, Improvement: 0.000006307, Best Loss: 0.000018893 in Epoch 527
Epoch 535
Epoch 535, Loss: 0.000036130, Improvement: -0.000014315, Best Loss: 0.000018893 in Epoch 527
Epoch 536
A best model at epoch 536 has been saved with training error 0.000018107.
A best model at epoch 536 has been saved with training error 0.000017784.
Epoch 536, Loss: 0.000027397, Improvement: -0.000008733, Best Loss: 0.000017784 in Epoch 536
Epoch 537
A best model at epoch 537 has been saved with training error 0.000015155.
Epoch 537, Loss: 0.000028898, Improvement: 0.000001500, Best Loss: 0.000015155 in Epoch 537
Epoch 538
Epoch 538, Loss: 0.000061793, Improvement: 0.000032895, Best Loss: 0.000015155 in Epoch 537
Epoch 539
Epoch 539, Loss: 0.000079396, Improvement: 0.000017603, Best Loss: 0.000015155 in Epoch 537
Epoch 540
Epoch 540, Loss: 0.000108016, Improvement: 0.000028619, Best Loss: 0.000015155 in Epoch 537
Epoch 541
Epoch 541, Loss: 0.000072803, Improvement: -0.000035213, Best Loss: 0.000015155 in Epoch 537
Epoch 542
Epoch 542, Loss: 0.000082102, Improvement: 0.000009299, Best Loss: 0.000015155 in Epoch 537
Epoch 543
Epoch 543, Loss: 0.000058305, Improvement: -0.000023797, Best Loss: 0.000015155 in Epoch 537
Epoch 544
Epoch 544, Loss: 0.000045611, Improvement: -0.000012695, Best Loss: 0.000015155 in Epoch 537
Epoch 545
Epoch 545, Loss: 0.000054122, Improvement: 0.000008511, Best Loss: 0.000015155 in Epoch 537
Epoch 546
Epoch 546, Loss: 0.000094870, Improvement: 0.000040748, Best Loss: 0.000015155 in Epoch 537
Epoch 547
Epoch 547, Loss: 0.000080336, Improvement: -0.000014534, Best Loss: 0.000015155 in Epoch 537
Epoch 548
Epoch 548, Loss: 0.000078766, Improvement: -0.000001570, Best Loss: 0.000015155 in Epoch 537
Epoch 549
Epoch 549, Loss: 0.000069548, Improvement: -0.000009218, Best Loss: 0.000015155 in Epoch 537
Epoch 550
Model saving checkpoint: the model trained after epoch 550 has been saved with the training errors.
Epoch 550, Loss: 0.000033553, Improvement: -0.000035995, Best Loss: 0.000015155 in Epoch 537
Epoch 551
A best model at epoch 551 has been saved with training error 0.000015098.
Epoch 551, Loss: 0.000026737, Improvement: -0.000006816, Best Loss: 0.000015098 in Epoch 551
Epoch 552
Epoch 552, Loss: 0.000022280, Improvement: -0.000004457, Best Loss: 0.000015098 in Epoch 551
Epoch 553
Epoch 553, Loss: 0.000029043, Improvement: 0.000006763, Best Loss: 0.000015098 in Epoch 551
Epoch 554
Epoch 554, Loss: 0.000031437, Improvement: 0.000002394, Best Loss: 0.000015098 in Epoch 551
Epoch 555
Epoch 555, Loss: 0.000033596, Improvement: 0.000002158, Best Loss: 0.000015098 in Epoch 551
Epoch 556
Epoch 556, Loss: 0.000038770, Improvement: 0.000005174, Best Loss: 0.000015098 in Epoch 551
Epoch 557
Epoch 557, Loss: 0.000038934, Improvement: 0.000000165, Best Loss: 0.000015098 in Epoch 551
Epoch 558
Epoch 558, Loss: 0.000031272, Improvement: -0.000007663, Best Loss: 0.000015098 in Epoch 551
Epoch 559
Epoch 559, Loss: 0.000047350, Improvement: 0.000016079, Best Loss: 0.000015098 in Epoch 551
Epoch 560
Epoch 560, Loss: 0.000088600, Improvement: 0.000041249, Best Loss: 0.000015098 in Epoch 551
Epoch 561
Epoch 561, Loss: 0.000066234, Improvement: -0.000022366, Best Loss: 0.000015098 in Epoch 551
Epoch 562
Epoch 562, Loss: 0.000084342, Improvement: 0.000018108, Best Loss: 0.000015098 in Epoch 551
Epoch 563
Epoch 563, Loss: 0.000054770, Improvement: -0.000029572, Best Loss: 0.000015098 in Epoch 551
Epoch 564
Epoch 564, Loss: 0.000077504, Improvement: 0.000022734, Best Loss: 0.000015098 in Epoch 551
Epoch 565
Epoch 565, Loss: 0.000186225, Improvement: 0.000108721, Best Loss: 0.000015098 in Epoch 551
Epoch 566
Epoch 566, Loss: 0.000115815, Improvement: -0.000070410, Best Loss: 0.000015098 in Epoch 551
Epoch 567
Epoch 567, Loss: 0.000078670, Improvement: -0.000037145, Best Loss: 0.000015098 in Epoch 551
Epoch 568
Epoch 568, Loss: 0.000066671, Improvement: -0.000011999, Best Loss: 0.000015098 in Epoch 551
Epoch 569
Epoch 569, Loss: 0.000041802, Improvement: -0.000024869, Best Loss: 0.000015098 in Epoch 551
Epoch 570
Epoch 570, Loss: 0.000055548, Improvement: 0.000013746, Best Loss: 0.000015098 in Epoch 551
Epoch 571
Epoch 571, Loss: 0.000040937, Improvement: -0.000014611, Best Loss: 0.000015098 in Epoch 551
Epoch 572
Epoch 572, Loss: 0.000030545, Improvement: -0.000010392, Best Loss: 0.000015098 in Epoch 551
Epoch 573
Epoch 573, Loss: 0.000033962, Improvement: 0.000003417, Best Loss: 0.000015098 in Epoch 551
Epoch 574
Epoch 574, Loss: 0.000039046, Improvement: 0.000005084, Best Loss: 0.000015098 in Epoch 551
Epoch 575
Epoch 575, Loss: 0.000037247, Improvement: -0.000001799, Best Loss: 0.000015098 in Epoch 551
Epoch 576
Epoch 576, Loss: 0.000046191, Improvement: 0.000008944, Best Loss: 0.000015098 in Epoch 551
Epoch 577
Epoch 577, Loss: 0.000069503, Improvement: 0.000023312, Best Loss: 0.000015098 in Epoch 551
Epoch 578
Epoch 578, Loss: 0.000106751, Improvement: 0.000037248, Best Loss: 0.000015098 in Epoch 551
Epoch 579
Epoch 579, Loss: 0.000119542, Improvement: 0.000012791, Best Loss: 0.000015098 in Epoch 551
Epoch 580
Epoch 580, Loss: 0.000074187, Improvement: -0.000045355, Best Loss: 0.000015098 in Epoch 551
Epoch 581
Epoch 581, Loss: 0.000044630, Improvement: -0.000029557, Best Loss: 0.000015098 in Epoch 551
Epoch 582
Epoch 582, Loss: 0.000038125, Improvement: -0.000006505, Best Loss: 0.000015098 in Epoch 551
Epoch 583
Epoch 583, Loss: 0.000040183, Improvement: 0.000002057, Best Loss: 0.000015098 in Epoch 551
Epoch 584
Epoch 584, Loss: 0.000042678, Improvement: 0.000002496, Best Loss: 0.000015098 in Epoch 551
Epoch 585
Epoch 585, Loss: 0.000037477, Improvement: -0.000005202, Best Loss: 0.000015098 in Epoch 551
Epoch 586
A best model at epoch 586 has been saved with training error 0.000013955.
Epoch 586, Loss: 0.000026620, Improvement: -0.000010857, Best Loss: 0.000013955 in Epoch 586
Epoch 587
A best model at epoch 587 has been saved with training error 0.000010980.
Epoch 587, Loss: 0.000021883, Improvement: -0.000004736, Best Loss: 0.000010980 in Epoch 587
Epoch 588
Epoch 588, Loss: 0.000044739, Improvement: 0.000022856, Best Loss: 0.000010980 in Epoch 587
Epoch 589
Epoch 589, Loss: 0.000043587, Improvement: -0.000001152, Best Loss: 0.000010980 in Epoch 587
Epoch 590
Epoch 590, Loss: 0.000070501, Improvement: 0.000026914, Best Loss: 0.000010980 in Epoch 587
Epoch 591
Epoch 591, Loss: 0.000060067, Improvement: -0.000010434, Best Loss: 0.000010980 in Epoch 587
Epoch 592
Epoch 592, Loss: 0.000038249, Improvement: -0.000021818, Best Loss: 0.000010980 in Epoch 587
Epoch 593
Epoch 593, Loss: 0.000042415, Improvement: 0.000004166, Best Loss: 0.000010980 in Epoch 587
Epoch 594
Epoch 594, Loss: 0.000050574, Improvement: 0.000008159, Best Loss: 0.000010980 in Epoch 587
Epoch 595
Epoch 595, Loss: 0.000025125, Improvement: -0.000025448, Best Loss: 0.000010980 in Epoch 587
Epoch 596
Epoch 596, Loss: 0.000033237, Improvement: 0.000008112, Best Loss: 0.000010980 in Epoch 587
Epoch 597
Epoch 597, Loss: 0.000078831, Improvement: 0.000045594, Best Loss: 0.000010980 in Epoch 587
Epoch 598
Epoch 598, Loss: 0.000161347, Improvement: 0.000082516, Best Loss: 0.000010980 in Epoch 587
Epoch 599
Epoch 599, Loss: 0.000119258, Improvement: -0.000042089, Best Loss: 0.000010980 in Epoch 587
Epoch 600
Model saving checkpoint: the model trained after epoch 600 has been saved with the training errors.
Epoch 600, Loss: 0.000043093, Improvement: -0.000076166, Best Loss: 0.000010980 in Epoch 587
Epoch 601
Epoch 601, Loss: 0.000027135, Improvement: -0.000015958, Best Loss: 0.000010980 in Epoch 587
Epoch 602
Epoch 602, Loss: 0.000019599, Improvement: -0.000007535, Best Loss: 0.000010980 in Epoch 587
Epoch 603
Epoch 603, Loss: 0.000015904, Improvement: -0.000003695, Best Loss: 0.000010980 in Epoch 587
Epoch 604
A best model at epoch 604 has been saved with training error 0.000010439.
Epoch 604, Loss: 0.000013833, Improvement: -0.000002071, Best Loss: 0.000010439 in Epoch 604
Epoch 605
A best model at epoch 605 has been saved with training error 0.000009207.
Epoch 605, Loss: 0.000015008, Improvement: 0.000001175, Best Loss: 0.000009207 in Epoch 605
Epoch 606
Epoch 606, Loss: 0.000016783, Improvement: 0.000001775, Best Loss: 0.000009207 in Epoch 605
Epoch 607
Epoch 607, Loss: 0.000017153, Improvement: 0.000000370, Best Loss: 0.000009207 in Epoch 605
Epoch 608
Epoch 608, Loss: 0.000018143, Improvement: 0.000000990, Best Loss: 0.000009207 in Epoch 605
Epoch 609
Epoch 609, Loss: 0.000017399, Improvement: -0.000000744, Best Loss: 0.000009207 in Epoch 605
Epoch 610
Epoch 610, Loss: 0.000022296, Improvement: 0.000004897, Best Loss: 0.000009207 in Epoch 605
Epoch 611
Epoch 611, Loss: 0.000036002, Improvement: 0.000013706, Best Loss: 0.000009207 in Epoch 605
Epoch 612
Epoch 612, Loss: 0.000087073, Improvement: 0.000051072, Best Loss: 0.000009207 in Epoch 605
Epoch 613
Epoch 613, Loss: 0.000108797, Improvement: 0.000021723, Best Loss: 0.000009207 in Epoch 605
Epoch 614
Epoch 614, Loss: 0.000099231, Improvement: -0.000009566, Best Loss: 0.000009207 in Epoch 605
Epoch 615
Epoch 615, Loss: 0.000076649, Improvement: -0.000022582, Best Loss: 0.000009207 in Epoch 605
Epoch 616
Epoch 616, Loss: 0.000041054, Improvement: -0.000035595, Best Loss: 0.000009207 in Epoch 605
Epoch 617
Epoch 617, Loss: 0.000034231, Improvement: -0.000006823, Best Loss: 0.000009207 in Epoch 605
Epoch 618
Epoch 618, Loss: 0.000027704, Improvement: -0.000006527, Best Loss: 0.000009207 in Epoch 605
Epoch 619
Epoch 619, Loss: 0.000029243, Improvement: 0.000001539, Best Loss: 0.000009207 in Epoch 605
Epoch 620
Epoch 620, Loss: 0.000039804, Improvement: 0.000010561, Best Loss: 0.000009207 in Epoch 605
Epoch 621
Epoch 621, Loss: 0.000029280, Improvement: -0.000010524, Best Loss: 0.000009207 in Epoch 605
Epoch 622
Epoch 622, Loss: 0.000022215, Improvement: -0.000007065, Best Loss: 0.000009207 in Epoch 605
Epoch 623
Epoch 623, Loss: 0.000035478, Improvement: 0.000013263, Best Loss: 0.000009207 in Epoch 605
Epoch 624
Epoch 624, Loss: 0.000053488, Improvement: 0.000018011, Best Loss: 0.000009207 in Epoch 605
Epoch 625
Epoch 625, Loss: 0.000036903, Improvement: -0.000016586, Best Loss: 0.000009207 in Epoch 605
Epoch 626
Epoch 626, Loss: 0.000068755, Improvement: 0.000031852, Best Loss: 0.000009207 in Epoch 605
Epoch 627
Epoch 627, Loss: 0.000110635, Improvement: 0.000041880, Best Loss: 0.000009207 in Epoch 605
Epoch 628
Epoch 628, Loss: 0.000137688, Improvement: 0.000027053, Best Loss: 0.000009207 in Epoch 605
Epoch 629
Epoch 629, Loss: 0.000074069, Improvement: -0.000063618, Best Loss: 0.000009207 in Epoch 605
Epoch 630
Epoch 630, Loss: 0.000042123, Improvement: -0.000031947, Best Loss: 0.000009207 in Epoch 605
Epoch 631
Epoch 631, Loss: 0.000029463, Improvement: -0.000012660, Best Loss: 0.000009207 in Epoch 605
Epoch 632
Epoch 632, Loss: 0.000020415, Improvement: -0.000009048, Best Loss: 0.000009207 in Epoch 605
Epoch 633
Epoch 633, Loss: 0.000014295, Improvement: -0.000006120, Best Loss: 0.000009207 in Epoch 605
Epoch 634
Epoch 634, Loss: 0.000012527, Improvement: -0.000001768, Best Loss: 0.000009207 in Epoch 605
Epoch 635
Epoch 635, Loss: 0.000012589, Improvement: 0.000000062, Best Loss: 0.000009207 in Epoch 605
Epoch 636
Epoch 636, Loss: 0.000016190, Improvement: 0.000003601, Best Loss: 0.000009207 in Epoch 605
Epoch 637
Epoch 637, Loss: 0.000029424, Improvement: 0.000013234, Best Loss: 0.000009207 in Epoch 605
Epoch 638
Epoch 638, Loss: 0.000019120, Improvement: -0.000010304, Best Loss: 0.000009207 in Epoch 605
Epoch 639
Epoch 639, Loss: 0.000021917, Improvement: 0.000002797, Best Loss: 0.000009207 in Epoch 605
Epoch 640
Epoch 640, Loss: 0.000030308, Improvement: 0.000008391, Best Loss: 0.000009207 in Epoch 605
Epoch 641
Epoch 641, Loss: 0.000025788, Improvement: -0.000004520, Best Loss: 0.000009207 in Epoch 605
Epoch 642
Epoch 642, Loss: 0.000019738, Improvement: -0.000006050, Best Loss: 0.000009207 in Epoch 605
Epoch 643
Epoch 643, Loss: 0.000018758, Improvement: -0.000000980, Best Loss: 0.000009207 in Epoch 605
Epoch 644
Epoch 644, Loss: 0.000017321, Improvement: -0.000001437, Best Loss: 0.000009207 in Epoch 605
Epoch 645
A best model at epoch 645 has been saved with training error 0.000008841.
A best model at epoch 645 has been saved with training error 0.000008789.
Epoch 645, Loss: 0.000011967, Improvement: -0.000005355, Best Loss: 0.000008789 in Epoch 645
Epoch 646
Epoch 646, Loss: 0.000011504, Improvement: -0.000000463, Best Loss: 0.000008789 in Epoch 645
Epoch 647
A best model at epoch 647 has been saved with training error 0.000007573.
Epoch 647, Loss: 0.000018492, Improvement: 0.000006988, Best Loss: 0.000007573 in Epoch 647
Epoch 648
Epoch 648, Loss: 0.000080286, Improvement: 0.000061794, Best Loss: 0.000007573 in Epoch 647
Epoch 649
Epoch 649, Loss: 0.000125321, Improvement: 0.000045035, Best Loss: 0.000007573 in Epoch 647
Epoch 650
Model saving checkpoint: the model trained after epoch 650 has been saved with the training errors.
Epoch 650, Loss: 0.000073265, Improvement: -0.000052056, Best Loss: 0.000007573 in Epoch 647
Epoch 651
Epoch 651, Loss: 0.000040581, Improvement: -0.000032684, Best Loss: 0.000007573 in Epoch 647
Epoch 652
Epoch 652, Loss: 0.000025822, Improvement: -0.000014758, Best Loss: 0.000007573 in Epoch 647
Epoch 653
Epoch 653, Loss: 0.000022633, Improvement: -0.000003189, Best Loss: 0.000007573 in Epoch 647
Epoch 654
Epoch 654, Loss: 0.000028570, Improvement: 0.000005937, Best Loss: 0.000007573 in Epoch 647
Epoch 655
Epoch 655, Loss: 0.000034184, Improvement: 0.000005614, Best Loss: 0.000007573 in Epoch 647
Epoch 656
Epoch 656, Loss: 0.000038674, Improvement: 0.000004490, Best Loss: 0.000007573 in Epoch 647
Epoch 657
Epoch 657, Loss: 0.000037037, Improvement: -0.000001638, Best Loss: 0.000007573 in Epoch 647
Epoch 658
Epoch 658, Loss: 0.000040200, Improvement: 0.000003163, Best Loss: 0.000007573 in Epoch 647
Epoch 659
Epoch 659, Loss: 0.000049391, Improvement: 0.000009191, Best Loss: 0.000007573 in Epoch 647
Epoch 660
Epoch 660, Loss: 0.000039206, Improvement: -0.000010185, Best Loss: 0.000007573 in Epoch 647
Epoch 661
Epoch 661, Loss: 0.000029632, Improvement: -0.000009574, Best Loss: 0.000007573 in Epoch 647
Epoch 662
Epoch 662, Loss: 0.000024700, Improvement: -0.000004932, Best Loss: 0.000007573 in Epoch 647
Epoch 663
Epoch 663, Loss: 0.000020521, Improvement: -0.000004179, Best Loss: 0.000007573 in Epoch 647
Epoch 664
Epoch 664, Loss: 0.000018128, Improvement: -0.000002393, Best Loss: 0.000007573 in Epoch 647
Epoch 665
Epoch 665, Loss: 0.000024653, Improvement: 0.000006524, Best Loss: 0.000007573 in Epoch 647
Epoch 666
Epoch 666, Loss: 0.000037182, Improvement: 0.000012529, Best Loss: 0.000007573 in Epoch 647
Epoch 667
Epoch 667, Loss: 0.000089992, Improvement: 0.000052810, Best Loss: 0.000007573 in Epoch 647
Epoch 668
Epoch 668, Loss: 0.000081131, Improvement: -0.000008861, Best Loss: 0.000007573 in Epoch 647
Epoch 669
Epoch 669, Loss: 0.000036885, Improvement: -0.000044246, Best Loss: 0.000007573 in Epoch 647
Epoch 670
Epoch 670, Loss: 0.000024740, Improvement: -0.000012146, Best Loss: 0.000007573 in Epoch 647
Epoch 671
Epoch 671, Loss: 0.000014937, Improvement: -0.000009803, Best Loss: 0.000007573 in Epoch 647
Epoch 672
Epoch 672, Loss: 0.000012353, Improvement: -0.000002584, Best Loss: 0.000007573 in Epoch 647
Epoch 673
A best model at epoch 673 has been saved with training error 0.000007450.
Epoch 673, Loss: 0.000015924, Improvement: 0.000003570, Best Loss: 0.000007450 in Epoch 673
Epoch 674
Epoch 674, Loss: 0.000025178, Improvement: 0.000009255, Best Loss: 0.000007450 in Epoch 673
Epoch 675
Epoch 675, Loss: 0.000020890, Improvement: -0.000004289, Best Loss: 0.000007450 in Epoch 673
Epoch 676
Epoch 676, Loss: 0.000025311, Improvement: 0.000004422, Best Loss: 0.000007450 in Epoch 673
Epoch 677
Epoch 677, Loss: 0.000029088, Improvement: 0.000003777, Best Loss: 0.000007450 in Epoch 673
Epoch 678
Epoch 678, Loss: 0.000034206, Improvement: 0.000005118, Best Loss: 0.000007450 in Epoch 673
Epoch 679
Epoch 679, Loss: 0.000025060, Improvement: -0.000009146, Best Loss: 0.000007450 in Epoch 673
Epoch 680
