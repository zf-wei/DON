The dimension of y_tensor is torch.Size([10201, 2]).
The dimension of y_expanded is torch.Size([500, 10201, 2]) after expanding.
The dimensions of the initial conditions are: (500, 101)
The dimensions of the solutions are: (500, 101, 101)
The dimension of u_tensor is torch.Size([500, 101]).
The dimension of u_expanded is torch.Size([500, 10201, 101]) after expanding.
The loaded solution dataset has dimension (500, 101, 101),
	 while the arranged linearized dataset has dimension (500, 10201).
The dimension of s_tensor is torch.Size([500, 10201]).
The dimension of s_expanded is torch.Size([500, 10201, 1]) after expanding.
Epoch 1
A best model at epoch 1 has been saved with training error 0.000098361.
A best model at epoch 1 has been saved with training error 0.000096477.
A best model at epoch 1 has been saved with training error 0.000052318.
A best model at epoch 1 has been saved with training error 0.000041873.
Epoch 1, Loss: 0.000228533, Improvement: 0.000228533, Best Loss: 0.000041873 in Epoch 1
Epoch 2
A best model at epoch 2 has been saved with training error 0.000031563.
Epoch 2, Loss: 0.000062546, Improvement: -0.000165987, Best Loss: 0.000031563 in Epoch 2
Epoch 3
Epoch 3, Loss: 0.000048933, Improvement: -0.000013613, Best Loss: 0.000031563 in Epoch 2
Epoch 4
A best model at epoch 4 has been saved with training error 0.000030874.
Epoch 4, Loss: 0.000046022, Improvement: -0.000002912, Best Loss: 0.000030874 in Epoch 4
Epoch 5
A best model at epoch 5 has been saved with training error 0.000027856.
Epoch 5, Loss: 0.000043920, Improvement: -0.000002102, Best Loss: 0.000027856 in Epoch 5
Epoch 6
Epoch 6, Loss: 0.000042010, Improvement: -0.000001909, Best Loss: 0.000027856 in Epoch 5
Epoch 7
Epoch 7, Loss: 0.000040249, Improvement: -0.000001761, Best Loss: 0.000027856 in Epoch 5
Epoch 8
A best model at epoch 8 has been saved with training error 0.000024538.
Epoch 8, Loss: 0.000038743, Improvement: -0.000001506, Best Loss: 0.000024538 in Epoch 8
Epoch 9
Epoch 9, Loss: 0.000037656, Improvement: -0.000001087, Best Loss: 0.000024538 in Epoch 8
Epoch 10
A best model at epoch 10 has been saved with training error 0.000018561.
Epoch 10, Loss: 0.000036917, Improvement: -0.000000739, Best Loss: 0.000018561 in Epoch 10
Epoch 11
Epoch 11, Loss: 0.000036472, Improvement: -0.000000445, Best Loss: 0.000018561 in Epoch 10
Epoch 12
Epoch 12, Loss: 0.000036167, Improvement: -0.000000304, Best Loss: 0.000018561 in Epoch 10
Epoch 13
Epoch 13, Loss: 0.000035879, Improvement: -0.000000288, Best Loss: 0.000018561 in Epoch 10
Epoch 14
Epoch 14, Loss: 0.000035581, Improvement: -0.000000299, Best Loss: 0.000018561 in Epoch 10
Epoch 15
Epoch 15, Loss: 0.000035242, Improvement: -0.000000339, Best Loss: 0.000018561 in Epoch 10
Epoch 16
Epoch 16, Loss: 0.000034833, Improvement: -0.000000409, Best Loss: 0.000018561 in Epoch 10
Epoch 17
Epoch 17, Loss: 0.000034344, Improvement: -0.000000489, Best Loss: 0.000018561 in Epoch 10
Epoch 18
Epoch 18, Loss: 0.000033744, Improvement: -0.000000601, Best Loss: 0.000018561 in Epoch 10
Epoch 19
Epoch 19, Loss: 0.000033015, Improvement: -0.000000729, Best Loss: 0.000018561 in Epoch 10
Epoch 20
Epoch 20, Loss: 0.000032137, Improvement: -0.000000878, Best Loss: 0.000018561 in Epoch 10
Epoch 21
Epoch 21, Loss: 0.000031083, Improvement: -0.000001054, Best Loss: 0.000018561 in Epoch 10
Epoch 22
Epoch 22, Loss: 0.000029780, Improvement: -0.000001303, Best Loss: 0.000018561 in Epoch 10
Epoch 23
A best model at epoch 23 has been saved with training error 0.000017822.
Epoch 23, Loss: 0.000028144, Improvement: -0.000001636, Best Loss: 0.000017822 in Epoch 23
Epoch 24
A best model at epoch 24 has been saved with training error 0.000017739.
Epoch 24, Loss: 0.000026263, Improvement: -0.000001882, Best Loss: 0.000017739 in Epoch 24
Epoch 25
A best model at epoch 25 has been saved with training error 0.000017514.
A best model at epoch 25 has been saved with training error 0.000015443.
Epoch 25, Loss: 0.000024035, Improvement: -0.000002228, Best Loss: 0.000015443 in Epoch 25
Epoch 26
A best model at epoch 26 has been saved with training error 0.000014172.
Epoch 26, Loss: 0.000021557, Improvement: -0.000002478, Best Loss: 0.000014172 in Epoch 26
Epoch 27
A best model at epoch 27 has been saved with training error 0.000013008.
A best model at epoch 27 has been saved with training error 0.000012840.
A best model at epoch 27 has been saved with training error 0.000012504.
Epoch 27, Loss: 0.000019043, Improvement: -0.000002514, Best Loss: 0.000012504 in Epoch 27
Epoch 28
A best model at epoch 28 has been saved with training error 0.000010442.
Epoch 28, Loss: 0.000016780, Improvement: -0.000002264, Best Loss: 0.000010442 in Epoch 28
Epoch 29
A best model at epoch 29 has been saved with training error 0.000009902.
Epoch 29, Loss: 0.000015051, Improvement: -0.000001729, Best Loss: 0.000009902 in Epoch 29
Epoch 30
A best model at epoch 30 has been saved with training error 0.000009369.
A best model at epoch 30 has been saved with training error 0.000008142.
Epoch 30, Loss: 0.000014063, Improvement: -0.000000988, Best Loss: 0.000008142 in Epoch 30
Epoch 31
A best model at epoch 31 has been saved with training error 0.000007705.
Epoch 31, Loss: 0.000013588, Improvement: -0.000000475, Best Loss: 0.000007705 in Epoch 31
Epoch 32
Epoch 32, Loss: 0.000013319, Improvement: -0.000000269, Best Loss: 0.000007705 in Epoch 31
Epoch 33
A best model at epoch 33 has been saved with training error 0.000007215.
Epoch 33, Loss: 0.000013124, Improvement: -0.000000195, Best Loss: 0.000007215 in Epoch 33
Epoch 34
A best model at epoch 34 has been saved with training error 0.000006479.
Epoch 34, Loss: 0.000012935, Improvement: -0.000000189, Best Loss: 0.000006479 in Epoch 34
Epoch 35
A best model at epoch 35 has been saved with training error 0.000006054.
Epoch 35, Loss: 0.000012765, Improvement: -0.000000170, Best Loss: 0.000006054 in Epoch 35
Epoch 36
Epoch 36, Loss: 0.000012586, Improvement: -0.000000178, Best Loss: 0.000006054 in Epoch 35
Epoch 37
A best model at epoch 37 has been saved with training error 0.000005014.
Epoch 37, Loss: 0.000012411, Improvement: -0.000000175, Best Loss: 0.000005014 in Epoch 37
Epoch 38
Epoch 38, Loss: 0.000012214, Improvement: -0.000000197, Best Loss: 0.000005014 in Epoch 37
Epoch 39
Epoch 39, Loss: 0.000012023, Improvement: -0.000000191, Best Loss: 0.000005014 in Epoch 37
Epoch 40
Epoch 40, Loss: 0.000011832, Improvement: -0.000000191, Best Loss: 0.000005014 in Epoch 37
Epoch 41
Epoch 41, Loss: 0.000011638, Improvement: -0.000000194, Best Loss: 0.000005014 in Epoch 37
Epoch 42
Epoch 42, Loss: 0.000011420, Improvement: -0.000000217, Best Loss: 0.000005014 in Epoch 37
Epoch 43
Epoch 43, Loss: 0.000011194, Improvement: -0.000000226, Best Loss: 0.000005014 in Epoch 37
Epoch 44
Epoch 44, Loss: 0.000010943, Improvement: -0.000000251, Best Loss: 0.000005014 in Epoch 37
Epoch 45
Epoch 45, Loss: 0.000010684, Improvement: -0.000000259, Best Loss: 0.000005014 in Epoch 37
Epoch 46
A best model at epoch 46 has been saved with training error 0.000003999.
Epoch 46, Loss: 0.000010391, Improvement: -0.000000293, Best Loss: 0.000003999 in Epoch 46
Epoch 47
Epoch 47, Loss: 0.000010065, Improvement: -0.000000326, Best Loss: 0.000003999 in Epoch 46
Epoch 48
Epoch 48, Loss: 0.000009716, Improvement: -0.000000348, Best Loss: 0.000003999 in Epoch 46
Epoch 49
Epoch 49, Loss: 0.000009334, Improvement: -0.000000382, Best Loss: 0.000003999 in Epoch 46
Epoch 50
Model saving checkpoint: the model trained after epoch 50 has been saved with the training errors.
Epoch 50, Loss: 0.000008906, Improvement: -0.000000428, Best Loss: 0.000003999 in Epoch 46
Epoch 51
Epoch 51, Loss: 0.000008435, Improvement: -0.000000472, Best Loss: 0.000003999 in Epoch 46
Epoch 52
Epoch 52, Loss: 0.000007883, Improvement: -0.000000552, Best Loss: 0.000003999 in Epoch 46
Epoch 53
Epoch 53, Loss: 0.000007281, Improvement: -0.000000602, Best Loss: 0.000003999 in Epoch 46
Epoch 54
Epoch 54, Loss: 0.000006621, Improvement: -0.000000660, Best Loss: 0.000003999 in Epoch 46
Epoch 55
A best model at epoch 55 has been saved with training error 0.000003585.
Epoch 55, Loss: 0.000005905, Improvement: -0.000000716, Best Loss: 0.000003585 in Epoch 55
Epoch 56
Epoch 56, Loss: 0.000005186, Improvement: -0.000000718, Best Loss: 0.000003585 in Epoch 55
Epoch 57
A best model at epoch 57 has been saved with training error 0.000003129.
A best model at epoch 57 has been saved with training error 0.000002648.
A best model at epoch 57 has been saved with training error 0.000002584.
Epoch 57, Loss: 0.000004442, Improvement: -0.000000744, Best Loss: 0.000002584 in Epoch 57
Epoch 58
A best model at epoch 58 has been saved with training error 0.000002083.
Epoch 58, Loss: 0.000003742, Improvement: -0.000000699, Best Loss: 0.000002083 in Epoch 58
Epoch 59
A best model at epoch 59 has been saved with training error 0.000002042.
A best model at epoch 59 has been saved with training error 0.000001912.
Epoch 59, Loss: 0.000003095, Improvement: -0.000000647, Best Loss: 0.000001912 in Epoch 59
Epoch 60
A best model at epoch 60 has been saved with training error 0.000001901.
A best model at epoch 60 has been saved with training error 0.000001875.
Epoch 60, Loss: 0.000002594, Improvement: -0.000000501, Best Loss: 0.000001875 in Epoch 60
Epoch 61
A best model at epoch 61 has been saved with training error 0.000001723.
A best model at epoch 61 has been saved with training error 0.000001527.
A best model at epoch 61 has been saved with training error 0.000001471.
A best model at epoch 61 has been saved with training error 0.000001444.
Epoch 61, Loss: 0.000002225, Improvement: -0.000000369, Best Loss: 0.000001444 in Epoch 61
Epoch 62
A best model at epoch 62 has been saved with training error 0.000001075.
Epoch 62, Loss: 0.000001990, Improvement: -0.000000236, Best Loss: 0.000001075 in Epoch 62
Epoch 63
Epoch 63, Loss: 0.000001851, Improvement: -0.000000138, Best Loss: 0.000001075 in Epoch 62
Epoch 64
Epoch 64, Loss: 0.000001760, Improvement: -0.000000091, Best Loss: 0.000001075 in Epoch 62
Epoch 65
A best model at epoch 65 has been saved with training error 0.000000980.
Epoch 65, Loss: 0.000001675, Improvement: -0.000000085, Best Loss: 0.000000980 in Epoch 65
Epoch 66
Epoch 66, Loss: 0.000001598, Improvement: -0.000000077, Best Loss: 0.000000980 in Epoch 65
Epoch 67
A best model at epoch 67 has been saved with training error 0.000000958.
Epoch 67, Loss: 0.000001539, Improvement: -0.000000059, Best Loss: 0.000000958 in Epoch 67
Epoch 68
Epoch 68, Loss: 0.000001484, Improvement: -0.000000055, Best Loss: 0.000000958 in Epoch 67
Epoch 69
A best model at epoch 69 has been saved with training error 0.000000942.
A best model at epoch 69 has been saved with training error 0.000000772.
Epoch 69, Loss: 0.000001415, Improvement: -0.000000070, Best Loss: 0.000000772 in Epoch 69
Epoch 70
Epoch 70, Loss: 0.000001415, Improvement: -0.000000000, Best Loss: 0.000000772 in Epoch 69
Epoch 71
Epoch 71, Loss: 0.000001326, Improvement: -0.000000088, Best Loss: 0.000000772 in Epoch 69
Epoch 72
Epoch 72, Loss: 0.000001255, Improvement: -0.000000071, Best Loss: 0.000000772 in Epoch 69
Epoch 73
A best model at epoch 73 has been saved with training error 0.000000686.
Epoch 73, Loss: 0.000001204, Improvement: -0.000000051, Best Loss: 0.000000686 in Epoch 73
Epoch 74
Epoch 74, Loss: 0.000001154, Improvement: -0.000000050, Best Loss: 0.000000686 in Epoch 73
Epoch 75
A best model at epoch 75 has been saved with training error 0.000000680.
Epoch 75, Loss: 0.000001119, Improvement: -0.000000036, Best Loss: 0.000000680 in Epoch 75
Epoch 76
Epoch 76, Loss: 0.000001091, Improvement: -0.000000027, Best Loss: 0.000000680 in Epoch 75
Epoch 77
Epoch 77, Loss: 0.000001040, Improvement: -0.000000051, Best Loss: 0.000000680 in Epoch 75
Epoch 78
Epoch 78, Loss: 0.000000976, Improvement: -0.000000064, Best Loss: 0.000000680 in Epoch 75
Epoch 79
A best model at epoch 79 has been saved with training error 0.000000587.
Epoch 79, Loss: 0.000000957, Improvement: -0.000000019, Best Loss: 0.000000587 in Epoch 79
Epoch 80
Epoch 80, Loss: 0.000000936, Improvement: -0.000000021, Best Loss: 0.000000587 in Epoch 79
Epoch 81
Epoch 81, Loss: 0.000000907, Improvement: -0.000000029, Best Loss: 0.000000587 in Epoch 79
Epoch 82
Epoch 82, Loss: 0.000000861, Improvement: -0.000000046, Best Loss: 0.000000587 in Epoch 79
Epoch 83
A best model at epoch 83 has been saved with training error 0.000000571.
Epoch 83, Loss: 0.000000849, Improvement: -0.000000012, Best Loss: 0.000000571 in Epoch 83
Epoch 84
Epoch 84, Loss: 0.000000818, Improvement: -0.000000031, Best Loss: 0.000000571 in Epoch 83
Epoch 85
Epoch 85, Loss: 0.000000814, Improvement: -0.000000004, Best Loss: 0.000000571 in Epoch 83
Epoch 86
A best model at epoch 86 has been saved with training error 0.000000518.
Epoch 86, Loss: 0.000000785, Improvement: -0.000000029, Best Loss: 0.000000518 in Epoch 86
Epoch 87
Epoch 87, Loss: 0.000000772, Improvement: -0.000000013, Best Loss: 0.000000518 in Epoch 86
Epoch 88
A best model at epoch 88 has been saved with training error 0.000000458.
Epoch 88, Loss: 0.000000756, Improvement: -0.000000016, Best Loss: 0.000000458 in Epoch 88
Epoch 89
Epoch 89, Loss: 0.000000769, Improvement: 0.000000014, Best Loss: 0.000000458 in Epoch 88
Epoch 90
Epoch 90, Loss: 0.000000756, Improvement: -0.000000013, Best Loss: 0.000000458 in Epoch 88
Epoch 91
Epoch 91, Loss: 0.000000733, Improvement: -0.000000023, Best Loss: 0.000000458 in Epoch 88
Epoch 92
Epoch 92, Loss: 0.000000744, Improvement: 0.000000011, Best Loss: 0.000000458 in Epoch 88
Epoch 93
Epoch 93, Loss: 0.000000718, Improvement: -0.000000025, Best Loss: 0.000000458 in Epoch 88
Epoch 94
A best model at epoch 94 has been saved with training error 0.000000442.
Epoch 94, Loss: 0.000000706, Improvement: -0.000000013, Best Loss: 0.000000442 in Epoch 94
Epoch 95
A best model at epoch 95 has been saved with training error 0.000000434.
Epoch 95, Loss: 0.000000701, Improvement: -0.000000005, Best Loss: 0.000000434 in Epoch 95
Epoch 96
Epoch 96, Loss: 0.000000689, Improvement: -0.000000012, Best Loss: 0.000000434 in Epoch 95
Epoch 97
Epoch 97, Loss: 0.000000693, Improvement: 0.000000004, Best Loss: 0.000000434 in Epoch 95
Epoch 98
Epoch 98, Loss: 0.000000693, Improvement: 0.000000001, Best Loss: 0.000000434 in Epoch 95
Epoch 99
A best model at epoch 99 has been saved with training error 0.000000416.
Epoch 99, Loss: 0.000000680, Improvement: -0.000000013, Best Loss: 0.000000416 in Epoch 99
Epoch 100
Model saving checkpoint: the model trained after epoch 100 has been saved with the training errors.
Epoch 100, Loss: 0.000000728, Improvement: 0.000000047, Best Loss: 0.000000416 in Epoch 99
Epoch 101
Epoch 101, Loss: 0.000000676, Improvement: -0.000000051, Best Loss: 0.000000416 in Epoch 99
Epoch 102
Epoch 102, Loss: 0.000000678, Improvement: 0.000000002, Best Loss: 0.000000416 in Epoch 99
Epoch 103
Epoch 103, Loss: 0.000000667, Improvement: -0.000000011, Best Loss: 0.000000416 in Epoch 99
Epoch 104
A best model at epoch 104 has been saved with training error 0.000000415.
Epoch 104, Loss: 0.000000663, Improvement: -0.000000004, Best Loss: 0.000000415 in Epoch 104
Epoch 105
Epoch 105, Loss: 0.000000662, Improvement: -0.000000001, Best Loss: 0.000000415 in Epoch 104
Epoch 106
Epoch 106, Loss: 0.000000658, Improvement: -0.000000004, Best Loss: 0.000000415 in Epoch 104
Epoch 107
A best model at epoch 107 has been saved with training error 0.000000396.
A best model at epoch 107 has been saved with training error 0.000000381.
Epoch 107, Loss: 0.000000652, Improvement: -0.000000006, Best Loss: 0.000000381 in Epoch 107
Epoch 108
Epoch 108, Loss: 0.000000657, Improvement: 0.000000005, Best Loss: 0.000000381 in Epoch 107
Epoch 109
Epoch 109, Loss: 0.000000668, Improvement: 0.000000011, Best Loss: 0.000000381 in Epoch 107
Epoch 110
Epoch 110, Loss: 0.000000645, Improvement: -0.000000023, Best Loss: 0.000000381 in Epoch 107
Epoch 111
Epoch 111, Loss: 0.000000639, Improvement: -0.000000006, Best Loss: 0.000000381 in Epoch 107
Epoch 112
Epoch 112, Loss: 0.000000641, Improvement: 0.000000001, Best Loss: 0.000000381 in Epoch 107
Epoch 113
Epoch 113, Loss: 0.000000633, Improvement: -0.000000007, Best Loss: 0.000000381 in Epoch 107
Epoch 114
A best model at epoch 114 has been saved with training error 0.000000374.
Epoch 114, Loss: 0.000000642, Improvement: 0.000000009, Best Loss: 0.000000374 in Epoch 114
Epoch 115
Epoch 115, Loss: 0.000000639, Improvement: -0.000000003, Best Loss: 0.000000374 in Epoch 114
Epoch 116
Epoch 116, Loss: 0.000000633, Improvement: -0.000000005, Best Loss: 0.000000374 in Epoch 114
Epoch 117
Epoch 117, Loss: 0.000000624, Improvement: -0.000000010, Best Loss: 0.000000374 in Epoch 114
Epoch 118
A best model at epoch 118 has been saved with training error 0.000000356.
Epoch 118, Loss: 0.000000619, Improvement: -0.000000004, Best Loss: 0.000000356 in Epoch 118
Epoch 119
Epoch 119, Loss: 0.000000620, Improvement: 0.000000001, Best Loss: 0.000000356 in Epoch 118
Epoch 120
Epoch 120, Loss: 0.000000613, Improvement: -0.000000007, Best Loss: 0.000000356 in Epoch 118
Epoch 121
Epoch 121, Loss: 0.000000602, Improvement: -0.000000011, Best Loss: 0.000000356 in Epoch 118
Epoch 122
Epoch 122, Loss: 0.000000604, Improvement: 0.000000002, Best Loss: 0.000000356 in Epoch 118
Epoch 123
Epoch 123, Loss: 0.000000603, Improvement: -0.000000001, Best Loss: 0.000000356 in Epoch 118
Epoch 124
Epoch 124, Loss: 0.000000595, Improvement: -0.000000008, Best Loss: 0.000000356 in Epoch 118
Epoch 125
Epoch 125, Loss: 0.000000611, Improvement: 0.000000016, Best Loss: 0.000000356 in Epoch 118
Epoch 126
Epoch 126, Loss: 0.000000624, Improvement: 0.000000013, Best Loss: 0.000000356 in Epoch 118
Epoch 127
Epoch 127, Loss: 0.000000643, Improvement: 0.000000019, Best Loss: 0.000000356 in Epoch 118
Epoch 128
Epoch 128, Loss: 0.000000606, Improvement: -0.000000038, Best Loss: 0.000000356 in Epoch 118
Epoch 129
Epoch 129, Loss: 0.000000584, Improvement: -0.000000022, Best Loss: 0.000000356 in Epoch 118
Epoch 130
A best model at epoch 130 has been saved with training error 0.000000342.
Epoch 130, Loss: 0.000000584, Improvement: 0.000000000, Best Loss: 0.000000342 in Epoch 130
Epoch 131
Epoch 131, Loss: 0.000000579, Improvement: -0.000000005, Best Loss: 0.000000342 in Epoch 130
Epoch 132
Epoch 132, Loss: 0.000000580, Improvement: 0.000000001, Best Loss: 0.000000342 in Epoch 130
Epoch 133
Epoch 133, Loss: 0.000000574, Improvement: -0.000000006, Best Loss: 0.000000342 in Epoch 130
Epoch 134
Epoch 134, Loss: 0.000000566, Improvement: -0.000000008, Best Loss: 0.000000342 in Epoch 130
Epoch 135
Epoch 135, Loss: 0.000000563, Improvement: -0.000000003, Best Loss: 0.000000342 in Epoch 130
Epoch 136
Epoch 136, Loss: 0.000000560, Improvement: -0.000000003, Best Loss: 0.000000342 in Epoch 130
Epoch 137
Epoch 137, Loss: 0.000000561, Improvement: 0.000000001, Best Loss: 0.000000342 in Epoch 130
Epoch 138
Epoch 138, Loss: 0.000000572, Improvement: 0.000000011, Best Loss: 0.000000342 in Epoch 130
Epoch 139
Epoch 139, Loss: 0.000000559, Improvement: -0.000000014, Best Loss: 0.000000342 in Epoch 130
Epoch 140
Epoch 140, Loss: 0.000000560, Improvement: 0.000000001, Best Loss: 0.000000342 in Epoch 130
Epoch 141
Epoch 141, Loss: 0.000000561, Improvement: 0.000000001, Best Loss: 0.000000342 in Epoch 130
Epoch 142
Epoch 142, Loss: 0.000000556, Improvement: -0.000000005, Best Loss: 0.000000342 in Epoch 130
Epoch 143
Epoch 143, Loss: 0.000000554, Improvement: -0.000000002, Best Loss: 0.000000342 in Epoch 130
Epoch 144
Epoch 144, Loss: 0.000000621, Improvement: 0.000000066, Best Loss: 0.000000342 in Epoch 130
Epoch 145
Epoch 145, Loss: 0.000000598, Improvement: -0.000000022, Best Loss: 0.000000342 in Epoch 130
Epoch 146
Epoch 146, Loss: 0.000000533, Improvement: -0.000000066, Best Loss: 0.000000342 in Epoch 130
Epoch 147
Epoch 147, Loss: 0.000000525, Improvement: -0.000000008, Best Loss: 0.000000342 in Epoch 130
Epoch 148
Epoch 148, Loss: 0.000000563, Improvement: 0.000000038, Best Loss: 0.000000342 in Epoch 130
Epoch 149
Epoch 149, Loss: 0.000000565, Improvement: 0.000000002, Best Loss: 0.000000342 in Epoch 130
Epoch 150
Model saving checkpoint: the model trained after epoch 150 has been saved with the training errors.
Epoch 150, Loss: 0.000000531, Improvement: -0.000000034, Best Loss: 0.000000342 in Epoch 130
Epoch 151
Epoch 151, Loss: 0.000000533, Improvement: 0.000000002, Best Loss: 0.000000342 in Epoch 130
Epoch 152
Epoch 152, Loss: 0.000000742, Improvement: 0.000000209, Best Loss: 0.000000342 in Epoch 130
Epoch 153
Epoch 153, Loss: 0.000001082, Improvement: 0.000000340, Best Loss: 0.000000342 in Epoch 130
Epoch 154
Epoch 154, Loss: 0.000000854, Improvement: -0.000000228, Best Loss: 0.000000342 in Epoch 130
Epoch 155
Epoch 155, Loss: 0.000001038, Improvement: 0.000000184, Best Loss: 0.000000342 in Epoch 130
Epoch 156
Epoch 156, Loss: 0.000000720, Improvement: -0.000000318, Best Loss: 0.000000342 in Epoch 130
Epoch 157
Epoch 157, Loss: 0.000000660, Improvement: -0.000000060, Best Loss: 0.000000342 in Epoch 130
Epoch 158
Epoch 158, Loss: 0.000000518, Improvement: -0.000000143, Best Loss: 0.000000342 in Epoch 130
Epoch 159
Epoch 159, Loss: 0.000000523, Improvement: 0.000000005, Best Loss: 0.000000342 in Epoch 130
Epoch 160
Epoch 160, Loss: 0.000000502, Improvement: -0.000000020, Best Loss: 0.000000342 in Epoch 130
Epoch 161
A best model at epoch 161 has been saved with training error 0.000000302.
Epoch 161, Loss: 0.000000495, Improvement: -0.000000007, Best Loss: 0.000000302 in Epoch 161
Epoch 162
Epoch 162, Loss: 0.000000502, Improvement: 0.000000006, Best Loss: 0.000000302 in Epoch 161
Epoch 163
Epoch 163, Loss: 0.000000517, Improvement: 0.000000015, Best Loss: 0.000000302 in Epoch 161
Epoch 164
Epoch 164, Loss: 0.000000576, Improvement: 0.000000060, Best Loss: 0.000000302 in Epoch 161
Epoch 165
Epoch 165, Loss: 0.000000827, Improvement: 0.000000251, Best Loss: 0.000000302 in Epoch 161
Epoch 166
Epoch 166, Loss: 0.000000734, Improvement: -0.000000093, Best Loss: 0.000000302 in Epoch 161
Epoch 167
Epoch 167, Loss: 0.000000503, Improvement: -0.000000231, Best Loss: 0.000000302 in Epoch 161
Epoch 168
Epoch 168, Loss: 0.000000490, Improvement: -0.000000013, Best Loss: 0.000000302 in Epoch 161
Epoch 169
Epoch 169, Loss: 0.000000508, Improvement: 0.000000017, Best Loss: 0.000000302 in Epoch 161
Epoch 170
Epoch 170, Loss: 0.000000588, Improvement: 0.000000080, Best Loss: 0.000000302 in Epoch 161
Epoch 171
Epoch 171, Loss: 0.000000934, Improvement: 0.000000346, Best Loss: 0.000000302 in Epoch 161
Epoch 172
Epoch 172, Loss: 0.000000969, Improvement: 0.000000035, Best Loss: 0.000000302 in Epoch 161
Epoch 173
Epoch 173, Loss: 0.000000737, Improvement: -0.000000233, Best Loss: 0.000000302 in Epoch 161
Epoch 174
Epoch 174, Loss: 0.000000560, Improvement: -0.000000177, Best Loss: 0.000000302 in Epoch 161
Epoch 175
Epoch 175, Loss: 0.000000525, Improvement: -0.000000035, Best Loss: 0.000000302 in Epoch 161
Epoch 176
Epoch 176, Loss: 0.000000555, Improvement: 0.000000030, Best Loss: 0.000000302 in Epoch 161
Epoch 177
Epoch 177, Loss: 0.000000623, Improvement: 0.000000068, Best Loss: 0.000000302 in Epoch 161
Epoch 178
Epoch 178, Loss: 0.000000833, Improvement: 0.000000210, Best Loss: 0.000000302 in Epoch 161
Epoch 179
Epoch 179, Loss: 0.000000733, Improvement: -0.000000101, Best Loss: 0.000000302 in Epoch 161
Epoch 180
Epoch 180, Loss: 0.000000535, Improvement: -0.000000197, Best Loss: 0.000000302 in Epoch 161
Epoch 181
Epoch 181, Loss: 0.000000630, Improvement: 0.000000095, Best Loss: 0.000000302 in Epoch 161
Epoch 182
Epoch 182, Loss: 0.000000668, Improvement: 0.000000038, Best Loss: 0.000000302 in Epoch 161
Epoch 183
Epoch 183, Loss: 0.000000623, Improvement: -0.000000046, Best Loss: 0.000000302 in Epoch 161
Epoch 184
Epoch 184, Loss: 0.000000866, Improvement: 0.000000243, Best Loss: 0.000000302 in Epoch 161
Epoch 185
Epoch 185, Loss: 0.000001050, Improvement: 0.000000184, Best Loss: 0.000000302 in Epoch 161
Epoch 186
Epoch 186, Loss: 0.000000618, Improvement: -0.000000432, Best Loss: 0.000000302 in Epoch 161
Epoch 187
Epoch 187, Loss: 0.000001031, Improvement: 0.000000414, Best Loss: 0.000000302 in Epoch 161
Epoch 188
Epoch 188, Loss: 0.000000802, Improvement: -0.000000229, Best Loss: 0.000000302 in Epoch 161
Epoch 189
Epoch 189, Loss: 0.000000984, Improvement: 0.000000182, Best Loss: 0.000000302 in Epoch 161
Epoch 190
Epoch 190, Loss: 0.000000750, Improvement: -0.000000234, Best Loss: 0.000000302 in Epoch 161
Epoch 191
Epoch 191, Loss: 0.000000940, Improvement: 0.000000190, Best Loss: 0.000000302 in Epoch 161
Epoch 192
Epoch 192, Loss: 0.000001027, Improvement: 0.000000088, Best Loss: 0.000000302 in Epoch 161
Epoch 193
Epoch 193, Loss: 0.000000846, Improvement: -0.000000181, Best Loss: 0.000000302 in Epoch 161
Epoch 194
Epoch 194, Loss: 0.000000537, Improvement: -0.000000309, Best Loss: 0.000000302 in Epoch 161
Epoch 195
Epoch 195, Loss: 0.000000493, Improvement: -0.000000044, Best Loss: 0.000000302 in Epoch 161
Epoch 196
Epoch 196, Loss: 0.000000465, Improvement: -0.000000027, Best Loss: 0.000000302 in Epoch 161
Epoch 197
A best model at epoch 197 has been saved with training error 0.000000269.
Epoch 197, Loss: 0.000000496, Improvement: 0.000000031, Best Loss: 0.000000269 in Epoch 197
Epoch 198
Epoch 198, Loss: 0.000000441, Improvement: -0.000000055, Best Loss: 0.000000269 in Epoch 197
Epoch 199
A best model at epoch 199 has been saved with training error 0.000000261.
Epoch 199, Loss: 0.000000429, Improvement: -0.000000012, Best Loss: 0.000000261 in Epoch 199
Epoch 200
Model saving checkpoint: the model trained after epoch 200 has been saved with the training errors.
Epoch 200, Loss: 0.000000419, Improvement: -0.000000010, Best Loss: 0.000000261 in Epoch 199
Epoch 201
Epoch 201, Loss: 0.000000455, Improvement: 0.000000037, Best Loss: 0.000000261 in Epoch 199
Epoch 202
Epoch 202, Loss: 0.000000772, Improvement: 0.000000317, Best Loss: 0.000000261 in Epoch 199
Epoch 203
Epoch 203, Loss: 0.000001207, Improvement: 0.000000435, Best Loss: 0.000000261 in Epoch 199
Epoch 204
Epoch 204, Loss: 0.000000801, Improvement: -0.000000406, Best Loss: 0.000000261 in Epoch 199
Epoch 205
Epoch 205, Loss: 0.000000829, Improvement: 0.000000027, Best Loss: 0.000000261 in Epoch 199
Epoch 206
Epoch 206, Loss: 0.000000545, Improvement: -0.000000283, Best Loss: 0.000000261 in Epoch 199
Epoch 207
Epoch 207, Loss: 0.000000430, Improvement: -0.000000115, Best Loss: 0.000000261 in Epoch 199
Epoch 208
Epoch 208, Loss: 0.000000422, Improvement: -0.000000008, Best Loss: 0.000000261 in Epoch 199
Epoch 209
A best model at epoch 209 has been saved with training error 0.000000229.
Epoch 209, Loss: 0.000000420, Improvement: -0.000000002, Best Loss: 0.000000229 in Epoch 209
Epoch 210
Epoch 210, Loss: 0.000000414, Improvement: -0.000000006, Best Loss: 0.000000229 in Epoch 209
Epoch 211
Epoch 211, Loss: 0.000000404, Improvement: -0.000000010, Best Loss: 0.000000229 in Epoch 209
Epoch 212
Epoch 212, Loss: 0.000000403, Improvement: -0.000000001, Best Loss: 0.000000229 in Epoch 209
Epoch 213
Epoch 213, Loss: 0.000000410, Improvement: 0.000000007, Best Loss: 0.000000229 in Epoch 209
Epoch 214
Epoch 214, Loss: 0.000000398, Improvement: -0.000000013, Best Loss: 0.000000229 in Epoch 209
Epoch 215
Epoch 215, Loss: 0.000000397, Improvement: -0.000000001, Best Loss: 0.000000229 in Epoch 209
Epoch 216
Epoch 216, Loss: 0.000000396, Improvement: -0.000000001, Best Loss: 0.000000229 in Epoch 209
Epoch 217
Epoch 217, Loss: 0.000000464, Improvement: 0.000000068, Best Loss: 0.000000229 in Epoch 209
Epoch 218
Epoch 218, Loss: 0.000000396, Improvement: -0.000000068, Best Loss: 0.000000229 in Epoch 209
Epoch 219
Epoch 219, Loss: 0.000000396, Improvement: 0.000000001, Best Loss: 0.000000229 in Epoch 209
Epoch 220
Epoch 220, Loss: 0.000000436, Improvement: 0.000000040, Best Loss: 0.000000229 in Epoch 209
Epoch 221
Epoch 221, Loss: 0.000000580, Improvement: 0.000000144, Best Loss: 0.000000229 in Epoch 209
Epoch 222
Epoch 222, Loss: 0.000000513, Improvement: -0.000000067, Best Loss: 0.000000229 in Epoch 209
Epoch 223
Epoch 223, Loss: 0.000000676, Improvement: 0.000000163, Best Loss: 0.000000229 in Epoch 209
Epoch 224
Epoch 224, Loss: 0.000000519, Improvement: -0.000000157, Best Loss: 0.000000229 in Epoch 209
Epoch 225
Epoch 225, Loss: 0.000000572, Improvement: 0.000000053, Best Loss: 0.000000229 in Epoch 209
Epoch 226
Epoch 226, Loss: 0.000000812, Improvement: 0.000000240, Best Loss: 0.000000229 in Epoch 209
Epoch 227
Epoch 227, Loss: 0.000000752, Improvement: -0.000000060, Best Loss: 0.000000229 in Epoch 209
Epoch 228
Epoch 228, Loss: 0.000000749, Improvement: -0.000000003, Best Loss: 0.000000229 in Epoch 209
Epoch 229
Epoch 229, Loss: 0.000000854, Improvement: 0.000000105, Best Loss: 0.000000229 in Epoch 209
Epoch 230
Epoch 230, Loss: 0.000000782, Improvement: -0.000000072, Best Loss: 0.000000229 in Epoch 209
Epoch 231
Epoch 231, Loss: 0.000000614, Improvement: -0.000000168, Best Loss: 0.000000229 in Epoch 209
Epoch 232
Epoch 232, Loss: 0.000000459, Improvement: -0.000000155, Best Loss: 0.000000229 in Epoch 209
Epoch 233
Epoch 233, Loss: 0.000000429, Improvement: -0.000000030, Best Loss: 0.000000229 in Epoch 209
Epoch 234
Epoch 234, Loss: 0.000000380, Improvement: -0.000000048, Best Loss: 0.000000229 in Epoch 209
Epoch 235
A best model at epoch 235 has been saved with training error 0.000000210.
Epoch 235, Loss: 0.000000388, Improvement: 0.000000008, Best Loss: 0.000000210 in Epoch 235
Epoch 236
Epoch 236, Loss: 0.000000366, Improvement: -0.000000022, Best Loss: 0.000000210 in Epoch 235
Epoch 237
Epoch 237, Loss: 0.000000364, Improvement: -0.000000002, Best Loss: 0.000000210 in Epoch 235
Epoch 238
Epoch 238, Loss: 0.000000362, Improvement: -0.000000002, Best Loss: 0.000000210 in Epoch 235
Epoch 239
Epoch 239, Loss: 0.000000382, Improvement: 0.000000019, Best Loss: 0.000000210 in Epoch 235
Epoch 240
Epoch 240, Loss: 0.000000468, Improvement: 0.000000087, Best Loss: 0.000000210 in Epoch 235
Epoch 241
Epoch 241, Loss: 0.000000405, Improvement: -0.000000063, Best Loss: 0.000000210 in Epoch 235
Epoch 242
Epoch 242, Loss: 0.000000384, Improvement: -0.000000021, Best Loss: 0.000000210 in Epoch 235
Epoch 243
Epoch 243, Loss: 0.000000388, Improvement: 0.000000004, Best Loss: 0.000000210 in Epoch 235
Epoch 244
Epoch 244, Loss: 0.000000556, Improvement: 0.000000168, Best Loss: 0.000000210 in Epoch 235
Epoch 245
Epoch 245, Loss: 0.000000602, Improvement: 0.000000046, Best Loss: 0.000000210 in Epoch 235
Epoch 246
Epoch 246, Loss: 0.000000530, Improvement: -0.000000072, Best Loss: 0.000000210 in Epoch 235
Epoch 247
Epoch 247, Loss: 0.000000416, Improvement: -0.000000114, Best Loss: 0.000000210 in Epoch 235
Epoch 248
Epoch 248, Loss: 0.000000875, Improvement: 0.000000459, Best Loss: 0.000000210 in Epoch 235
Epoch 249
Epoch 249, Loss: 0.000000620, Improvement: -0.000000255, Best Loss: 0.000000210 in Epoch 235
Epoch 250
Model saving checkpoint: the model trained after epoch 250 has been saved with the training errors.
Epoch 250, Loss: 0.000000409, Improvement: -0.000000212, Best Loss: 0.000000210 in Epoch 235
Epoch 251
Epoch 251, Loss: 0.000000380, Improvement: -0.000000029, Best Loss: 0.000000210 in Epoch 235
Epoch 252
Epoch 252, Loss: 0.000000353, Improvement: -0.000000027, Best Loss: 0.000000210 in Epoch 235
Epoch 253
Epoch 253, Loss: 0.000000364, Improvement: 0.000000011, Best Loss: 0.000000210 in Epoch 235
Epoch 254
A best model at epoch 254 has been saved with training error 0.000000198.
Epoch 254, Loss: 0.000000352, Improvement: -0.000000011, Best Loss: 0.000000198 in Epoch 254
Epoch 255
Epoch 255, Loss: 0.000000354, Improvement: 0.000000001, Best Loss: 0.000000198 in Epoch 254
Epoch 256
Epoch 256, Loss: 0.000000355, Improvement: 0.000000002, Best Loss: 0.000000198 in Epoch 254
Epoch 257
Epoch 257, Loss: 0.000000359, Improvement: 0.000000003, Best Loss: 0.000000198 in Epoch 254
Epoch 258
Epoch 258, Loss: 0.000000365, Improvement: 0.000000007, Best Loss: 0.000000198 in Epoch 254
Epoch 259
Epoch 259, Loss: 0.000000464, Improvement: 0.000000099, Best Loss: 0.000000198 in Epoch 254
Epoch 260
Epoch 260, Loss: 0.000000484, Improvement: 0.000000020, Best Loss: 0.000000198 in Epoch 254
Epoch 261
Epoch 261, Loss: 0.000000392, Improvement: -0.000000092, Best Loss: 0.000000198 in Epoch 254
Epoch 262
Epoch 262, Loss: 0.000000784, Improvement: 0.000000392, Best Loss: 0.000000198 in Epoch 254
Epoch 263
Epoch 263, Loss: 0.000000576, Improvement: -0.000000208, Best Loss: 0.000000198 in Epoch 254
Epoch 264
Epoch 264, Loss: 0.000000480, Improvement: -0.000000096, Best Loss: 0.000000198 in Epoch 254
Epoch 265
Epoch 265, Loss: 0.000000391, Improvement: -0.000000088, Best Loss: 0.000000198 in Epoch 254
Epoch 266
Epoch 266, Loss: 0.000000348, Improvement: -0.000000043, Best Loss: 0.000000198 in Epoch 254
Epoch 267
Epoch 267, Loss: 0.000000340, Improvement: -0.000000008, Best Loss: 0.000000198 in Epoch 254
Epoch 268
Epoch 268, Loss: 0.000000341, Improvement: 0.000000001, Best Loss: 0.000000198 in Epoch 254
Epoch 269
Epoch 269, Loss: 0.000000346, Improvement: 0.000000005, Best Loss: 0.000000198 in Epoch 254
Epoch 270
Epoch 270, Loss: 0.000000360, Improvement: 0.000000014, Best Loss: 0.000000198 in Epoch 254
Epoch 271
Epoch 271, Loss: 0.000000373, Improvement: 0.000000013, Best Loss: 0.000000198 in Epoch 254
Epoch 272
Epoch 272, Loss: 0.000000352, Improvement: -0.000000021, Best Loss: 0.000000198 in Epoch 254
Epoch 273
Epoch 273, Loss: 0.000000387, Improvement: 0.000000035, Best Loss: 0.000000198 in Epoch 254
Epoch 274
Epoch 274, Loss: 0.000000434, Improvement: 0.000000047, Best Loss: 0.000000198 in Epoch 254
Epoch 275
Epoch 275, Loss: 0.000000500, Improvement: 0.000000066, Best Loss: 0.000000198 in Epoch 254
Epoch 276
Epoch 276, Loss: 0.000000659, Improvement: 0.000000158, Best Loss: 0.000000198 in Epoch 254
Epoch 277
Epoch 277, Loss: 0.000000427, Improvement: -0.000000232, Best Loss: 0.000000198 in Epoch 254
Epoch 278
Epoch 278, Loss: 0.000000368, Improvement: -0.000000059, Best Loss: 0.000000198 in Epoch 254
Epoch 279
Epoch 279, Loss: 0.000000345, Improvement: -0.000000023, Best Loss: 0.000000198 in Epoch 254
Epoch 280
Epoch 280, Loss: 0.000000337, Improvement: -0.000000008, Best Loss: 0.000000198 in Epoch 254
Epoch 281
Epoch 281, Loss: 0.000000333, Improvement: -0.000000003, Best Loss: 0.000000198 in Epoch 254
Epoch 282
Epoch 282, Loss: 0.000000334, Improvement: 0.000000001, Best Loss: 0.000000198 in Epoch 254
Epoch 283
Epoch 283, Loss: 0.000000333, Improvement: -0.000000001, Best Loss: 0.000000198 in Epoch 254
Epoch 284
Epoch 284, Loss: 0.000000332, Improvement: -0.000000001, Best Loss: 0.000000198 in Epoch 254
Epoch 285
Epoch 285, Loss: 0.000000514, Improvement: 0.000000182, Best Loss: 0.000000198 in Epoch 254
Epoch 286
Epoch 286, Loss: 0.000000564, Improvement: 0.000000051, Best Loss: 0.000000198 in Epoch 254
Epoch 287
Epoch 287, Loss: 0.000000439, Improvement: -0.000000125, Best Loss: 0.000000198 in Epoch 254
Epoch 288
Epoch 288, Loss: 0.000000381, Improvement: -0.000000058, Best Loss: 0.000000198 in Epoch 254
Epoch 289
Epoch 289, Loss: 0.000000427, Improvement: 0.000000046, Best Loss: 0.000000198 in Epoch 254
Epoch 290
Epoch 290, Loss: 0.000000489, Improvement: 0.000000062, Best Loss: 0.000000198 in Epoch 254
Epoch 291
Epoch 291, Loss: 0.000000355, Improvement: -0.000000134, Best Loss: 0.000000198 in Epoch 254
Epoch 292
Epoch 292, Loss: 0.000000409, Improvement: 0.000000054, Best Loss: 0.000000198 in Epoch 254
Epoch 293
Epoch 293, Loss: 0.000000586, Improvement: 0.000000177, Best Loss: 0.000000198 in Epoch 254
Epoch 294
Epoch 294, Loss: 0.000001206, Improvement: 0.000000620, Best Loss: 0.000000198 in Epoch 254
Epoch 295
Epoch 295, Loss: 0.000000695, Improvement: -0.000000511, Best Loss: 0.000000198 in Epoch 254
Epoch 296
Epoch 296, Loss: 0.000000403, Improvement: -0.000000292, Best Loss: 0.000000198 in Epoch 254
Epoch 297
Epoch 297, Loss: 0.000000366, Improvement: -0.000000037, Best Loss: 0.000000198 in Epoch 254
Epoch 298
Epoch 298, Loss: 0.000000330, Improvement: -0.000000036, Best Loss: 0.000000198 in Epoch 254
Epoch 299
Epoch 299, Loss: 0.000000324, Improvement: -0.000000007, Best Loss: 0.000000198 in Epoch 254
Epoch 300
Model saving checkpoint: the model trained after epoch 300 has been saved with the training errors.
Epoch 300, Loss: 0.000000321, Improvement: -0.000000003, Best Loss: 0.000000198 in Epoch 254
Epoch 301
Epoch 301, Loss: 0.000000322, Improvement: 0.000000001, Best Loss: 0.000000198 in Epoch 254
Epoch 302
Epoch 302, Loss: 0.000000320, Improvement: -0.000000001, Best Loss: 0.000000198 in Epoch 254
Epoch 303
Epoch 303, Loss: 0.000000319, Improvement: -0.000000001, Best Loss: 0.000000198 in Epoch 254
Epoch 304
Epoch 304, Loss: 0.000000320, Improvement: 0.000000000, Best Loss: 0.000000198 in Epoch 254
Epoch 305
Epoch 305, Loss: 0.000000320, Improvement: -0.000000000, Best Loss: 0.000000198 in Epoch 254
Epoch 306
Epoch 306, Loss: 0.000000319, Improvement: -0.000000001, Best Loss: 0.000000198 in Epoch 254
Epoch 307
Epoch 307, Loss: 0.000000318, Improvement: -0.000000001, Best Loss: 0.000000198 in Epoch 254
Epoch 308
Epoch 308, Loss: 0.000000318, Improvement: 0.000000000, Best Loss: 0.000000198 in Epoch 254
Epoch 309
Epoch 309, Loss: 0.000000318, Improvement: 0.000000000, Best Loss: 0.000000198 in Epoch 254
Epoch 310
Epoch 310, Loss: 0.000000318, Improvement: 0.000000000, Best Loss: 0.000000198 in Epoch 254
Epoch 311
Epoch 311, Loss: 0.000000319, Improvement: 0.000000001, Best Loss: 0.000000198 in Epoch 254
Epoch 312
Epoch 312, Loss: 0.000000318, Improvement: -0.000000001, Best Loss: 0.000000198 in Epoch 254
Epoch 313
Epoch 313, Loss: 0.000000317, Improvement: -0.000000000, Best Loss: 0.000000198 in Epoch 254
Epoch 314
Epoch 314, Loss: 0.000000319, Improvement: 0.000000002, Best Loss: 0.000000198 in Epoch 254
Epoch 315
Epoch 315, Loss: 0.000000318, Improvement: -0.000000001, Best Loss: 0.000000198 in Epoch 254
Epoch 316
Epoch 316, Loss: 0.000000318, Improvement: -0.000000000, Best Loss: 0.000000198 in Epoch 254
Epoch 317
Epoch 317, Loss: 0.000000318, Improvement: 0.000000000, Best Loss: 0.000000198 in Epoch 254
Epoch 318
A best model at epoch 318 has been saved with training error 0.000000180.
Epoch 318, Loss: 0.000000319, Improvement: 0.000000001, Best Loss: 0.000000180 in Epoch 318
Epoch 319
Epoch 319, Loss: 0.000000317, Improvement: -0.000000002, Best Loss: 0.000000180 in Epoch 318
Epoch 320
Epoch 320, Loss: 0.000000317, Improvement: -0.000000000, Best Loss: 0.000000180 in Epoch 318
Epoch 321
Epoch 321, Loss: 0.000000338, Improvement: 0.000000021, Best Loss: 0.000000180 in Epoch 318
Epoch 322
Epoch 322, Loss: 0.000000317, Improvement: -0.000000021, Best Loss: 0.000000180 in Epoch 318
Epoch 323
slurmstepd: error: *** JOB 8035767 ON a100-03 CANCELLED AT 2024-11-19T19:06:54 ***
