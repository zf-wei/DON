A best model at iteration 1 has been saved with training loss 0.04144600778818.
A best model at iteration 2 has been saved with training loss 0.03687179461122.
A best model at iteration 5 has been saved with training loss 0.03670930862427.
A best model at iteration 7 has been saved with training loss 0.03372225165367.
A best model at iteration 10 has been saved with training loss 0.03294011950493.
A best model at iteration 12 has been saved with training loss 0.03286875784397.
A best model at iteration 14 has been saved with training loss 0.03246127814054.
A best model at iteration 16 has been saved with training loss 0.03132289275527.
A best model at iteration 18 has been saved with training loss 0.03003841079772.
A best model at iteration 23 has been saved with training loss 0.02953929081559.
A best model at iteration 25 has been saved with training loss 0.02880518883467.
A best model at iteration 30 has been saved with training loss 0.02796857804060.
A best model at iteration 37 has been saved with training loss 0.02724777348340.
A best model at iteration 41 has been saved with training loss 0.02690350078046.
A best model at iteration 42 has been saved with training loss 0.02588123083115.
A best model at iteration 46 has been saved with training loss 0.02505552023649.
A best model at iteration 48 has been saved with training loss 0.02444896660745.
A best model at iteration 52 has been saved with training loss 0.02444713935256.
A best model at iteration 53 has been saved with training loss 0.02429556287825.
A best model at iteration 54 has been saved with training loss 0.02417798340321.
A best model at iteration 55 has been saved with training loss 0.02315974421799.
A best model at iteration 57 has been saved with training loss 0.02250618860126.
A best model at iteration 59 has been saved with training loss 0.02228362299502.
A best model at iteration 60 has been saved with training loss 0.02154622413218.
A best model at iteration 61 has been saved with training loss 0.02116682566702.
A best model at iteration 62 has been saved with training loss 0.02101026102901.
A best model at iteration 67 has been saved with training loss 0.02011543512344.
A best model at iteration 70 has been saved with training loss 0.01851134188473.
A best model at iteration 74 has been saved with training loss 0.01834652014077.
A best model at iteration 75 has been saved with training loss 0.01815522834659.
A best model at iteration 76 has been saved with training loss 0.01758116669953.
A best model at iteration 77 has been saved with training loss 0.01633334532380.
A best model at iteration 80 has been saved with training loss 0.01621882058680.
A best model at iteration 82 has been saved with training loss 0.01584319956601.
A best model at iteration 84 has been saved with training loss 0.01513055060059.
A best model at iteration 85 has been saved with training loss 0.01468794234097.
A best model at iteration 86 has been saved with training loss 0.01445119176060.
A best model at iteration 88 has been saved with training loss 0.01423480920494.
A best model at iteration 90 has been saved with training loss 0.01361907459795.
A best model at iteration 93 has been saved with training loss 0.01348040997982.
A best model at iteration 94 has been saved with training loss 0.01304215472192.
A best model at iteration 95 has been saved with training loss 0.01289716549218.
A best model at iteration 98 has been saved with training loss 0.01215468253940.
A best model at iteration 99 has been saved with training loss 0.01168555859476.
A best model at iteration 102 has been saved with training loss 0.01166053209454.
A best model at iteration 103 has been saved with training loss 0.01142179127783.
A best model at iteration 104 has been saved with training loss 0.01098506245762.
A best model at iteration 113 has been saved with training loss 0.01023941580206.
A best model at iteration 119 has been saved with training loss 0.00990220345557.
A best model at iteration 121 has been saved with training loss 0.00981194619089.
A best model at iteration 122 has been saved with training loss 0.00935797579587.
A best model at iteration 124 has been saved with training loss 0.00904220063239.
A best model at iteration 132 has been saved with training loss 0.00797638483346.
A best model at iteration 138 has been saved with training loss 0.00712973251939.
A best model at iteration 147 has been saved with training loss 0.00618677632883.
A best model at iteration 150 has been saved with training loss 0.00592591008171.
A best model at iteration 154 has been saved with training loss 0.00538636790588.
A best model at iteration 159 has been saved with training loss 0.00533511862159.
A best model at iteration 160 has been saved with training loss 0.00489787198603.
A best model at iteration 163 has been saved with training loss 0.00489437486976.
A best model at iteration 165 has been saved with training loss 0.00472957547754.
A best model at iteration 169 has been saved with training loss 0.00454603135586.
A best model at iteration 195 has been saved with training loss 0.00400886638090.
A best model at iteration 257 has been saved with training loss 0.00395641522482.
A best model at iteration 300 has been saved with training loss 0.00369567843154.
A best model at iteration 321 has been saved with training loss 0.00325836869888.
A best model at iteration 722 has been saved with training loss 0.00323792663403.
A best model at iteration 767 has been saved with training loss 0.00318108848296.
A best model at iteration 771 has been saved with training loss 0.00279558426701.
A best model at iteration 874 has been saved with training loss 0.00271651730873.
A best model at iteration 953 has been saved with training loss 0.00258273608051.
A best model at iteration 976 has been saved with training loss 0.00256545143202.
A best model at iteration 981 has been saved with training loss 0.00254598725587.
A best model at iteration 1011 has been saved with training loss 0.00253583351150.
A best model at iteration 1012 has been saved with training loss 0.00238087028265.
A best model at iteration 1038 has been saved with training loss 0.00179530214518.
A best model at iteration 1144 has been saved with training loss 0.00173693499528.
A best model at iteration 1289 has been saved with training loss 0.00171682494693.
A best model at iteration 1301 has been saved with training loss 0.00149562465958.
A best model at iteration 1328 has been saved with training loss 0.00142904405948.
A best model at iteration 1329 has been saved with training loss 0.00141858961433.
A best model at iteration 1330 has been saved with training loss 0.00135171925649.
A best model at iteration 1332 has been saved with training loss 0.00131949258503.
A best model at iteration 1338 has been saved with training loss 0.00131384073757.
A best model at iteration 1344 has been saved with training loss 0.00117902003694.
A best model at iteration 1347 has been saved with training loss 0.00115232262760.
A best model at iteration 1649 has been saved with training loss 0.00113724835683.
A best model at iteration 1672 has been saved with training loss 0.00111060182098.
A best model at iteration 1727 has been saved with training loss 0.00103211600799.
A best model at iteration 1728 has been saved with training loss 0.00097037869273.
A best model at iteration 1798 has been saved with training loss 0.00089026713977.
A best model at iteration 2124 has been saved with training loss 0.00086025934434.
A best model at iteration 2127 has been saved with training loss 0.00080265494762.
A best model at iteration 2144 has been saved with training loss 0.00077683187556.
A best model at iteration 2147 has been saved with training loss 0.00077250041068.
A best model at iteration 2269 has been saved with training loss 0.00076982093742.
A best model at iteration 2396 has been saved with training loss 0.00071414984995.
A best model at iteration 2558 has been saved with training loss 0.00070637190947.
A best model at iteration 2682 has been saved with training loss 0.00066715094727.
A best model at iteration 2736 has been saved with training loss 0.00056076538749.
A best model at iteration 3168 has been saved with training loss 0.00050556147471.
A best model at iteration 3435 has been saved with training loss 0.00050160882529.
A best model at iteration 3732 has been saved with training loss 0.00048970693024.
A best model at iteration 3920 has been saved with training loss 0.00043578835903.
A best model at iteration 4090 has been saved with training loss 0.00043523265049.
A best model at iteration 4283 has been saved with training loss 0.00040943411295.
A best model at iteration 4292 has been saved with training loss 0.00034515417065.
A best model at iteration 6599 has been saved with training loss 0.00034116566530.
A best model at iteration 6967 has been saved with training loss 0.00033198104938.
A best model at iteration 7461 has been saved with training loss 0.00032264660695.
A best model at iteration 8894 has been saved with training loss 0.00030695059104.
A best model at iteration 9130 has been saved with training loss 0.00029436638579.
A best model at iteration 9414 has been saved with training loss 0.00026784994407.
A best model at iteration 10112 has been saved with training loss 0.00025504294899.
A best model at iteration 10521 has been saved with training loss 0.00025206635473.
A best model at iteration 13298 has been saved with training loss 0.00023996167874.
A best model at iteration 13358 has been saved with training loss 0.00022021093173.
A best model at iteration 17259 has been saved with training loss 0.00019809603691.
A best model at iteration 22835 has been saved with training loss 0.00018397319946.
A best model at iteration 30814 has been saved with training loss 0.00016052230785.
A best model at iteration 63218 has been saved with training loss 0.00013329899230.
A best model at iteration 75100 has been saved with training loss 0.00012771422917.
A best model at iteration 88735 has been saved with training loss 0.00012225397222.
A best model at iteration 125147 has been saved with training loss 0.00011889930465.
A best model at iteration 134297 has been saved with training loss 0.00011403268581.
