The dimension of y_tensor is torch.Size([5000, 2]).
The dimension of y_expanded is torch.Size([500, 5000, 2]) after expanding.
The dimensions of the initial conditions are: (500, 50)
The dimensions of the solutions are: (500, 100, 50)
The dimension of u_tensor is torch.Size([500, 50]).
The dimension of u_expanded is torch.Size([500, 5000, 50]) after expanding.
The loaded solution dataset has dimension (500, 100, 50),
	 while the arranged linearized dataset has dimension (500, 5000).
The dimension of s_tensor is torch.Size([500, 5000]).
The dimension of s_expanded is torch.Size([500, 5000, 1]) after expanding.
Epoch 1
A best model at epoch 1 has been saved with training error 0.060961723.
A best model at epoch 1 has been saved with training error 0.036594443.
Epoch 1, Loss: 0.260718262, Improvement: 0.260718262, Best Loss: 0.036594443 in Epoch 1
Epoch 2
A best model at epoch 2 has been saved with training error 0.029512985.
A best model at epoch 2 has been saved with training error 0.022966027.
Epoch 2, Loss: 0.084224300, Improvement: -0.176493962, Best Loss: 0.022966027 in Epoch 2
Epoch 3
A best model at epoch 3 has been saved with training error 0.017262381.
A best model at epoch 3 has been saved with training error 0.015132034.
A best model at epoch 3 has been saved with training error 0.013202629.
A best model at epoch 3 has been saved with training error 0.011924230.
Epoch 3, Loss: 0.026022903, Improvement: -0.058201397, Best Loss: 0.011924230 in Epoch 3
Epoch 4
A best model at epoch 4 has been saved with training error 0.011799620.
A best model at epoch 4 has been saved with training error 0.010139774.
A best model at epoch 4 has been saved with training error 0.008244103.
Epoch 4, Loss: 0.016040648, Improvement: -0.009982255, Best Loss: 0.008244103 in Epoch 4
Epoch 5
Epoch 5, Loss: 0.013672038, Improvement: -0.002368610, Best Loss: 0.008244103 in Epoch 4
Epoch 6
A best model at epoch 6 has been saved with training error 0.007593758.
A best model at epoch 6 has been saved with training error 0.007045695.
Epoch 6, Loss: 0.012703300, Improvement: -0.000968738, Best Loss: 0.007045695 in Epoch 6
Epoch 7
Epoch 7, Loss: 0.012240664, Improvement: -0.000462636, Best Loss: 0.007045695 in Epoch 6
Epoch 8
Epoch 8, Loss: 0.011890399, Improvement: -0.000350265, Best Loss: 0.007045695 in Epoch 6
Epoch 9
Epoch 9, Loss: 0.011662555, Improvement: -0.000227844, Best Loss: 0.007045695 in Epoch 6
Epoch 10
Epoch 10, Loss: 0.011507070, Improvement: -0.000155485, Best Loss: 0.007045695 in Epoch 6
Epoch 11
Epoch 11, Loss: 0.011367056, Improvement: -0.000140014, Best Loss: 0.007045695 in Epoch 6
Epoch 12
A best model at epoch 12 has been saved with training error 0.006712854.
A best model at epoch 12 has been saved with training error 0.005474281.
Epoch 12, Loss: 0.011239976, Improvement: -0.000127080, Best Loss: 0.005474281 in Epoch 12
Epoch 13
Epoch 13, Loss: 0.011145636, Improvement: -0.000094340, Best Loss: 0.005474281 in Epoch 12
Epoch 14
Epoch 14, Loss: 0.011057252, Improvement: -0.000088384, Best Loss: 0.005474281 in Epoch 12
Epoch 15
Epoch 15, Loss: 0.010973509, Improvement: -0.000083743, Best Loss: 0.005474281 in Epoch 12
Epoch 16
Epoch 16, Loss: 0.010903425, Improvement: -0.000070084, Best Loss: 0.005474281 in Epoch 12
Epoch 17
Epoch 17, Loss: 0.010812795, Improvement: -0.000090630, Best Loss: 0.005474281 in Epoch 12
Epoch 18
Epoch 18, Loss: 0.010745658, Improvement: -0.000067137, Best Loss: 0.005474281 in Epoch 12
Epoch 19
Epoch 19, Loss: 0.010674289, Improvement: -0.000071369, Best Loss: 0.005474281 in Epoch 12
Epoch 20
Epoch 20, Loss: 0.010602534, Improvement: -0.000071755, Best Loss: 0.005474281 in Epoch 12
Epoch 21
A best model at epoch 21 has been saved with training error 0.005309480.
Epoch 21, Loss: 0.010540853, Improvement: -0.000061681, Best Loss: 0.005309480 in Epoch 21
Epoch 22
Epoch 22, Loss: 0.010466330, Improvement: -0.000074524, Best Loss: 0.005309480 in Epoch 21
Epoch 23
A best model at epoch 23 has been saved with training error 0.004094624.
Epoch 23, Loss: 0.010400518, Improvement: -0.000065811, Best Loss: 0.004094624 in Epoch 23
Epoch 24
Epoch 24, Loss: 0.010335338, Improvement: -0.000065180, Best Loss: 0.004094624 in Epoch 23
Epoch 25
Epoch 25, Loss: 0.010261686, Improvement: -0.000073653, Best Loss: 0.004094624 in Epoch 23
Epoch 26
Epoch 26, Loss: 0.010194860, Improvement: -0.000066826, Best Loss: 0.004094624 in Epoch 23
Epoch 27
Epoch 27, Loss: 0.010128985, Improvement: -0.000065875, Best Loss: 0.004094624 in Epoch 23
Epoch 28
Epoch 28, Loss: 0.010060013, Improvement: -0.000068972, Best Loss: 0.004094624 in Epoch 23
Epoch 29
Epoch 29, Loss: 0.009986726, Improvement: -0.000073286, Best Loss: 0.004094624 in Epoch 23
Epoch 30
Epoch 30, Loss: 0.009906498, Improvement: -0.000080229, Best Loss: 0.004094624 in Epoch 23
Epoch 31
Epoch 31, Loss: 0.009838061, Improvement: -0.000068436, Best Loss: 0.004094624 in Epoch 23
Epoch 32
Epoch 32, Loss: 0.009777438, Improvement: -0.000060624, Best Loss: 0.004094624 in Epoch 23
Epoch 33
A best model at epoch 33 has been saved with training error 0.003980352.
Epoch 33, Loss: 0.009684797, Improvement: -0.000092641, Best Loss: 0.003980352 in Epoch 33
Epoch 34
Epoch 34, Loss: 0.009606398, Improvement: -0.000078399, Best Loss: 0.003980352 in Epoch 33
Epoch 35
Epoch 35, Loss: 0.009530431, Improvement: -0.000075967, Best Loss: 0.003980352 in Epoch 33
Epoch 36
Epoch 36, Loss: 0.009455301, Improvement: -0.000075130, Best Loss: 0.003980352 in Epoch 33
Epoch 37
Epoch 37, Loss: 0.009372712, Improvement: -0.000082589, Best Loss: 0.003980352 in Epoch 33
Epoch 38
Epoch 38, Loss: 0.009313173, Improvement: -0.000059539, Best Loss: 0.003980352 in Epoch 33
Epoch 39
Epoch 39, Loss: 0.009218239, Improvement: -0.000094935, Best Loss: 0.003980352 in Epoch 33
Epoch 40
Epoch 40, Loss: 0.009127679, Improvement: -0.000090560, Best Loss: 0.003980352 in Epoch 33
Epoch 41
Epoch 41, Loss: 0.009033520, Improvement: -0.000094159, Best Loss: 0.003980352 in Epoch 33
Epoch 42
Epoch 42, Loss: 0.008946161, Improvement: -0.000087359, Best Loss: 0.003980352 in Epoch 33
Epoch 43
Epoch 43, Loss: 0.008856821, Improvement: -0.000089340, Best Loss: 0.003980352 in Epoch 33
Epoch 44
Epoch 44, Loss: 0.008764650, Improvement: -0.000092172, Best Loss: 0.003980352 in Epoch 33
Epoch 45
Epoch 45, Loss: 0.008667262, Improvement: -0.000097388, Best Loss: 0.003980352 in Epoch 33
Epoch 46
Epoch 46, Loss: 0.008603538, Improvement: -0.000063724, Best Loss: 0.003980352 in Epoch 33
Epoch 47
Epoch 47, Loss: 0.008486072, Improvement: -0.000117466, Best Loss: 0.003980352 in Epoch 33
Epoch 48
Epoch 48, Loss: 0.008388671, Improvement: -0.000097400, Best Loss: 0.003980352 in Epoch 33
Epoch 49
Epoch 49, Loss: 0.008292082, Improvement: -0.000096589, Best Loss: 0.003980352 in Epoch 33
Epoch 50
Model saving checkpoint: the model trained after epoch 50 has been saved with the training errors.
Epoch 50, Loss: 0.008183539, Improvement: -0.000108543, Best Loss: 0.003980352 in Epoch 33
Epoch 51
Epoch 51, Loss: 0.008083113, Improvement: -0.000100426, Best Loss: 0.003980352 in Epoch 33
Epoch 52
Epoch 52, Loss: 0.007987167, Improvement: -0.000095946, Best Loss: 0.003980352 in Epoch 33
Epoch 53
Epoch 53, Loss: 0.007887310, Improvement: -0.000099857, Best Loss: 0.003980352 in Epoch 33
Epoch 54
Epoch 54, Loss: 0.007791540, Improvement: -0.000095770, Best Loss: 0.003980352 in Epoch 33
Epoch 55
Epoch 55, Loss: 0.007708517, Improvement: -0.000083023, Best Loss: 0.003980352 in Epoch 33
Epoch 56
Epoch 56, Loss: 0.007617309, Improvement: -0.000091208, Best Loss: 0.003980352 in Epoch 33
Epoch 57
Epoch 57, Loss: 0.007540724, Improvement: -0.000076585, Best Loss: 0.003980352 in Epoch 33
Epoch 58
A best model at epoch 58 has been saved with training error 0.003830474.
Epoch 58, Loss: 0.007492501, Improvement: -0.000048223, Best Loss: 0.003830474 in Epoch 58
Epoch 59
Epoch 59, Loss: 0.007507080, Improvement: 0.000014579, Best Loss: 0.003830474 in Epoch 58
Epoch 60
Epoch 60, Loss: 0.007379914, Improvement: -0.000127166, Best Loss: 0.003830474 in Epoch 58
Epoch 61
Epoch 61, Loss: 0.007336964, Improvement: -0.000042950, Best Loss: 0.003830474 in Epoch 58
Epoch 62
Epoch 62, Loss: 0.007421004, Improvement: 0.000084040, Best Loss: 0.003830474 in Epoch 58
Epoch 63
Epoch 63, Loss: 0.007414748, Improvement: -0.000006256, Best Loss: 0.003830474 in Epoch 58
Epoch 64
Epoch 64, Loss: 0.007487583, Improvement: 0.000072835, Best Loss: 0.003830474 in Epoch 58
Epoch 65
Epoch 65, Loss: 0.007829734, Improvement: 0.000342152, Best Loss: 0.003830474 in Epoch 58
Epoch 66
Epoch 66, Loss: 0.009122784, Improvement: 0.001293050, Best Loss: 0.003830474 in Epoch 58
Epoch 67
Epoch 67, Loss: 0.009869920, Improvement: 0.000747135, Best Loss: 0.003830474 in Epoch 58
Epoch 68
Epoch 68, Loss: 0.011592901, Improvement: 0.001722981, Best Loss: 0.003830474 in Epoch 58
Epoch 69
A best model at epoch 69 has been saved with training error 0.003642547.
Epoch 69, Loss: 0.008839987, Improvement: -0.002752914, Best Loss: 0.003642547 in Epoch 69
Epoch 70
Epoch 70, Loss: 0.007580919, Improvement: -0.001259068, Best Loss: 0.003642547 in Epoch 69
Epoch 71
Epoch 71, Loss: 0.007077029, Improvement: -0.000503890, Best Loss: 0.003642547 in Epoch 69
Epoch 72
Epoch 72, Loss: 0.006892363, Improvement: -0.000184666, Best Loss: 0.003642547 in Epoch 69
Epoch 73
Epoch 73, Loss: 0.006773679, Improvement: -0.000118684, Best Loss: 0.003642547 in Epoch 69
Epoch 74
Epoch 74, Loss: 0.006639685, Improvement: -0.000133995, Best Loss: 0.003642547 in Epoch 69
Epoch 75
Epoch 75, Loss: 0.006535929, Improvement: -0.000103755, Best Loss: 0.003642547 in Epoch 69
Epoch 76
A best model at epoch 76 has been saved with training error 0.003129643.
Epoch 76, Loss: 0.006477546, Improvement: -0.000058383, Best Loss: 0.003129643 in Epoch 76
Epoch 77
Epoch 77, Loss: 0.006421983, Improvement: -0.000055563, Best Loss: 0.003129643 in Epoch 76
Epoch 78
Epoch 78, Loss: 0.006355771, Improvement: -0.000066213, Best Loss: 0.003129643 in Epoch 76
Epoch 79
Epoch 79, Loss: 0.006314940, Improvement: -0.000040831, Best Loss: 0.003129643 in Epoch 76
Epoch 80
Epoch 80, Loss: 0.006259291, Improvement: -0.000055649, Best Loss: 0.003129643 in Epoch 76
Epoch 81
Epoch 81, Loss: 0.006218584, Improvement: -0.000040707, Best Loss: 0.003129643 in Epoch 76
Epoch 82
Epoch 82, Loss: 0.006159360, Improvement: -0.000059223, Best Loss: 0.003129643 in Epoch 76
Epoch 83
Epoch 83, Loss: 0.006115271, Improvement: -0.000044090, Best Loss: 0.003129643 in Epoch 76
Epoch 84
Epoch 84, Loss: 0.006089106, Improvement: -0.000026165, Best Loss: 0.003129643 in Epoch 76
Epoch 85
Epoch 85, Loss: 0.006067020, Improvement: -0.000022087, Best Loss: 0.003129643 in Epoch 76
Epoch 86
Epoch 86, Loss: 0.006058490, Improvement: -0.000008529, Best Loss: 0.003129643 in Epoch 76
Epoch 87
Epoch 87, Loss: 0.006063198, Improvement: 0.000004708, Best Loss: 0.003129643 in Epoch 76
Epoch 88
Epoch 88, Loss: 0.006147691, Improvement: 0.000084493, Best Loss: 0.003129643 in Epoch 76
Epoch 89
Epoch 89, Loss: 0.006233904, Improvement: 0.000086213, Best Loss: 0.003129643 in Epoch 76
Epoch 90
Epoch 90, Loss: 0.006427362, Improvement: 0.000193457, Best Loss: 0.003129643 in Epoch 76
Epoch 91
Epoch 91, Loss: 0.006753857, Improvement: 0.000326495, Best Loss: 0.003129643 in Epoch 76
Epoch 92
Epoch 92, Loss: 0.006607775, Improvement: -0.000146082, Best Loss: 0.003129643 in Epoch 76
Epoch 93
Epoch 93, Loss: 0.006821263, Improvement: 0.000213488, Best Loss: 0.003129643 in Epoch 76
Epoch 94
Epoch 94, Loss: 0.006795686, Improvement: -0.000025577, Best Loss: 0.003129643 in Epoch 76
Epoch 95
Epoch 95, Loss: 0.006983204, Improvement: 0.000187519, Best Loss: 0.003129643 in Epoch 76
Epoch 96
Epoch 96, Loss: 0.007761946, Improvement: 0.000778742, Best Loss: 0.003129643 in Epoch 76
Epoch 97
Epoch 97, Loss: 0.006610902, Improvement: -0.001151044, Best Loss: 0.003129643 in Epoch 76
Epoch 98
Epoch 98, Loss: 0.006068370, Improvement: -0.000542532, Best Loss: 0.003129643 in Epoch 76
Epoch 99
A best model at epoch 99 has been saved with training error 0.003086734.
Epoch 99, Loss: 0.005614891, Improvement: -0.000453479, Best Loss: 0.003086734 in Epoch 99
Epoch 100
Model saving checkpoint: the model trained after epoch 100 has been saved with the training errors.
Epoch 100, Loss: 0.005389541, Improvement: -0.000225350, Best Loss: 0.003086734 in Epoch 99
Epoch 101
Epoch 101, Loss: 0.005247420, Improvement: -0.000142121, Best Loss: 0.003086734 in Epoch 99
Epoch 102
Epoch 102, Loss: 0.005178321, Improvement: -0.000069099, Best Loss: 0.003086734 in Epoch 99
Epoch 103
Epoch 103, Loss: 0.005102995, Improvement: -0.000075326, Best Loss: 0.003086734 in Epoch 99
Epoch 104
Epoch 104, Loss: 0.005024813, Improvement: -0.000078182, Best Loss: 0.003086734 in Epoch 99
Epoch 105
Epoch 105, Loss: 0.005000950, Improvement: -0.000023864, Best Loss: 0.003086734 in Epoch 99
Epoch 106
Epoch 106, Loss: 0.004982289, Improvement: -0.000018661, Best Loss: 0.003086734 in Epoch 99
Epoch 107
Epoch 107, Loss: 0.005067494, Improvement: 0.000085205, Best Loss: 0.003086734 in Epoch 99
Epoch 108
Epoch 108, Loss: 0.005388616, Improvement: 0.000321121, Best Loss: 0.003086734 in Epoch 99
Epoch 109
Epoch 109, Loss: 0.005341806, Improvement: -0.000046810, Best Loss: 0.003086734 in Epoch 99
Epoch 110
Epoch 110, Loss: 0.005250795, Improvement: -0.000091010, Best Loss: 0.003086734 in Epoch 99
Epoch 111
Epoch 111, Loss: 0.005028772, Improvement: -0.000222023, Best Loss: 0.003086734 in Epoch 99
Epoch 112
Epoch 112, Loss: 0.004823454, Improvement: -0.000205317, Best Loss: 0.003086734 in Epoch 99
Epoch 113
A best model at epoch 113 has been saved with training error 0.003021556.
A best model at epoch 113 has been saved with training error 0.002857047.
Epoch 113, Loss: 0.004670107, Improvement: -0.000153348, Best Loss: 0.002857047 in Epoch 113
Epoch 114
Epoch 114, Loss: 0.004611421, Improvement: -0.000058686, Best Loss: 0.002857047 in Epoch 113
Epoch 115
Epoch 115, Loss: 0.004295858, Improvement: -0.000315563, Best Loss: 0.002857047 in Epoch 113
Epoch 116
Epoch 116, Loss: 0.004139930, Improvement: -0.000155928, Best Loss: 0.002857047 in Epoch 113
Epoch 117
A best model at epoch 117 has been saved with training error 0.002710388.
Epoch 117, Loss: 0.004025455, Improvement: -0.000114476, Best Loss: 0.002710388 in Epoch 117
Epoch 118
Epoch 118, Loss: 0.004005652, Improvement: -0.000019803, Best Loss: 0.002710388 in Epoch 117
Epoch 119
A best model at epoch 119 has been saved with training error 0.002530172.
Epoch 119, Loss: 0.003961360, Improvement: -0.000044292, Best Loss: 0.002530172 in Epoch 119
Epoch 120
A best model at epoch 120 has been saved with training error 0.002410148.
A best model at epoch 120 has been saved with training error 0.002285537.
A best model at epoch 120 has been saved with training error 0.002235325.
Epoch 120, Loss: 0.003877987, Improvement: -0.000083373, Best Loss: 0.002235325 in Epoch 120
Epoch 121
Epoch 121, Loss: 0.003940134, Improvement: 0.000062147, Best Loss: 0.002235325 in Epoch 120
Epoch 122
Epoch 122, Loss: 0.003930438, Improvement: -0.000009696, Best Loss: 0.002235325 in Epoch 120
Epoch 123
Epoch 123, Loss: 0.003762716, Improvement: -0.000167722, Best Loss: 0.002235325 in Epoch 120
Epoch 124
Epoch 124, Loss: 0.003892895, Improvement: 0.000130179, Best Loss: 0.002235325 in Epoch 120
Epoch 125
Epoch 125, Loss: 0.004200426, Improvement: 0.000307530, Best Loss: 0.002235325 in Epoch 120
Epoch 126
Epoch 126, Loss: 0.004304959, Improvement: 0.000104534, Best Loss: 0.002235325 in Epoch 120
Epoch 127
Epoch 127, Loss: 0.004118333, Improvement: -0.000186626, Best Loss: 0.002235325 in Epoch 120
Epoch 128
Epoch 128, Loss: 0.004144020, Improvement: 0.000025687, Best Loss: 0.002235325 in Epoch 120
Epoch 129
A best model at epoch 129 has been saved with training error 0.002143860.
Epoch 129, Loss: 0.003841164, Improvement: -0.000302856, Best Loss: 0.002143860 in Epoch 129
Epoch 130
Epoch 130, Loss: 0.003679519, Improvement: -0.000161645, Best Loss: 0.002143860 in Epoch 129
Epoch 131
Epoch 131, Loss: 0.003502331, Improvement: -0.000177188, Best Loss: 0.002143860 in Epoch 129
Epoch 132
Epoch 132, Loss: 0.003418329, Improvement: -0.000084001, Best Loss: 0.002143860 in Epoch 129
Epoch 133
Epoch 133, Loss: 0.003488829, Improvement: 0.000070499, Best Loss: 0.002143860 in Epoch 129
Epoch 134
A best model at epoch 134 has been saved with training error 0.001857177.
Epoch 134, Loss: 0.003332889, Improvement: -0.000155940, Best Loss: 0.001857177 in Epoch 134
Epoch 135
Epoch 135, Loss: 0.003236040, Improvement: -0.000096849, Best Loss: 0.001857177 in Epoch 134
Epoch 136
Epoch 136, Loss: 0.003056345, Improvement: -0.000179694, Best Loss: 0.001857177 in Epoch 134
Epoch 137
Epoch 137, Loss: 0.003023881, Improvement: -0.000032465, Best Loss: 0.001857177 in Epoch 134
Epoch 138
Epoch 138, Loss: 0.002970310, Improvement: -0.000053571, Best Loss: 0.001857177 in Epoch 134
Epoch 139
Epoch 139, Loss: 0.002912969, Improvement: -0.000057341, Best Loss: 0.001857177 in Epoch 134
Epoch 140
Epoch 140, Loss: 0.002866379, Improvement: -0.000046590, Best Loss: 0.001857177 in Epoch 134
Epoch 141
Epoch 141, Loss: 0.002835297, Improvement: -0.000031081, Best Loss: 0.001857177 in Epoch 134
Epoch 142
A best model at epoch 142 has been saved with training error 0.001769878.
Epoch 142, Loss: 0.002772892, Improvement: -0.000062405, Best Loss: 0.001769878 in Epoch 142
Epoch 143
Epoch 143, Loss: 0.002845666, Improvement: 0.000072774, Best Loss: 0.001769878 in Epoch 142
Epoch 144
A best model at epoch 144 has been saved with training error 0.001707603.
Epoch 144, Loss: 0.002934744, Improvement: 0.000089078, Best Loss: 0.001707603 in Epoch 144
Epoch 145
A best model at epoch 145 has been saved with training error 0.001525390.
Epoch 145, Loss: 0.002828275, Improvement: -0.000106469, Best Loss: 0.001525390 in Epoch 145
Epoch 146
Epoch 146, Loss: 0.002672068, Improvement: -0.000156207, Best Loss: 0.001525390 in Epoch 145
Epoch 147
Epoch 147, Loss: 0.002826863, Improvement: 0.000154796, Best Loss: 0.001525390 in Epoch 145
Epoch 148
Epoch 148, Loss: 0.003405343, Improvement: 0.000578480, Best Loss: 0.001525390 in Epoch 145
Epoch 149
Epoch 149, Loss: 0.003424225, Improvement: 0.000018881, Best Loss: 0.001525390 in Epoch 145
Epoch 150
Model saving checkpoint: the model trained after epoch 150 has been saved with the training errors.
Epoch 150, Loss: 0.003104718, Improvement: -0.000319506, Best Loss: 0.001525390 in Epoch 145
Epoch 151
Epoch 151, Loss: 0.003553774, Improvement: 0.000449056, Best Loss: 0.001525390 in Epoch 145
Epoch 152
Epoch 152, Loss: 0.003883214, Improvement: 0.000329439, Best Loss: 0.001525390 in Epoch 145
Epoch 153
Epoch 153, Loss: 0.003811358, Improvement: -0.000071856, Best Loss: 0.001525390 in Epoch 145
Epoch 154
Epoch 154, Loss: 0.003298192, Improvement: -0.000513166, Best Loss: 0.001525390 in Epoch 145
Epoch 155
A best model at epoch 155 has been saved with training error 0.001411897.
Epoch 155, Loss: 0.002957699, Improvement: -0.000340493, Best Loss: 0.001411897 in Epoch 155
Epoch 156
Epoch 156, Loss: 0.002746177, Improvement: -0.000211522, Best Loss: 0.001411897 in Epoch 155
Epoch 157
A best model at epoch 157 has been saved with training error 0.001261423.
Epoch 157, Loss: 0.002569094, Improvement: -0.000177083, Best Loss: 0.001261423 in Epoch 157
Epoch 158
Epoch 158, Loss: 0.002393402, Improvement: -0.000175692, Best Loss: 0.001261423 in Epoch 157
Epoch 159
Epoch 159, Loss: 0.002282270, Improvement: -0.000111132, Best Loss: 0.001261423 in Epoch 157
Epoch 160
Epoch 160, Loss: 0.002196048, Improvement: -0.000086222, Best Loss: 0.001261423 in Epoch 157
Epoch 161
Epoch 161, Loss: 0.002142182, Improvement: -0.000053866, Best Loss: 0.001261423 in Epoch 157
Epoch 162
Epoch 162, Loss: 0.002063043, Improvement: -0.000079139, Best Loss: 0.001261423 in Epoch 157
Epoch 163
Epoch 163, Loss: 0.002086132, Improvement: 0.000023090, Best Loss: 0.001261423 in Epoch 157
Epoch 164
A best model at epoch 164 has been saved with training error 0.001141576.
Epoch 164, Loss: 0.001999967, Improvement: -0.000086166, Best Loss: 0.001141576 in Epoch 164
Epoch 165
A best model at epoch 165 has been saved with training error 0.001059416.
Epoch 165, Loss: 0.001969384, Improvement: -0.000030582, Best Loss: 0.001059416 in Epoch 165
Epoch 166
Epoch 166, Loss: 0.001961010, Improvement: -0.000008374, Best Loss: 0.001059416 in Epoch 165
Epoch 167
Epoch 167, Loss: 0.001955022, Improvement: -0.000005989, Best Loss: 0.001059416 in Epoch 165
Epoch 168
Epoch 168, Loss: 0.001934998, Improvement: -0.000020024, Best Loss: 0.001059416 in Epoch 165
Epoch 169
Epoch 169, Loss: 0.001915046, Improvement: -0.000019952, Best Loss: 0.001059416 in Epoch 165
Epoch 170
A best model at epoch 170 has been saved with training error 0.001047314.
A best model at epoch 170 has been saved with training error 0.001036219.
Epoch 170, Loss: 0.001893039, Improvement: -0.000022007, Best Loss: 0.001036219 in Epoch 170
Epoch 171
Epoch 171, Loss: 0.001839508, Improvement: -0.000053531, Best Loss: 0.001036219 in Epoch 170
Epoch 172
Epoch 172, Loss: 0.001836925, Improvement: -0.000002582, Best Loss: 0.001036219 in Epoch 170
Epoch 173
Epoch 173, Loss: 0.001800957, Improvement: -0.000035968, Best Loss: 0.001036219 in Epoch 170
Epoch 174
Epoch 174, Loss: 0.001861630, Improvement: 0.000060673, Best Loss: 0.001036219 in Epoch 170
Epoch 175
Epoch 175, Loss: 0.001860157, Improvement: -0.000001473, Best Loss: 0.001036219 in Epoch 170
Epoch 176
Epoch 176, Loss: 0.001852335, Improvement: -0.000007823, Best Loss: 0.001036219 in Epoch 170
Epoch 177
Epoch 177, Loss: 0.001995209, Improvement: 0.000142874, Best Loss: 0.001036219 in Epoch 170
Epoch 178
Epoch 178, Loss: 0.001939729, Improvement: -0.000055479, Best Loss: 0.001036219 in Epoch 170
Epoch 179
Epoch 179, Loss: 0.002057624, Improvement: 0.000117895, Best Loss: 0.001036219 in Epoch 170
Epoch 180
Epoch 180, Loss: 0.002069868, Improvement: 0.000012244, Best Loss: 0.001036219 in Epoch 170
Epoch 181
Epoch 181, Loss: 0.002252789, Improvement: 0.000182920, Best Loss: 0.001036219 in Epoch 170
Epoch 182
Epoch 182, Loss: 0.002296789, Improvement: 0.000044000, Best Loss: 0.001036219 in Epoch 170
Epoch 183
Epoch 183, Loss: 0.002349460, Improvement: 0.000052671, Best Loss: 0.001036219 in Epoch 170
Epoch 184
Epoch 184, Loss: 0.002210353, Improvement: -0.000139106, Best Loss: 0.001036219 in Epoch 170
Epoch 185
Epoch 185, Loss: 0.001897607, Improvement: -0.000312746, Best Loss: 0.001036219 in Epoch 170
Epoch 186
Epoch 186, Loss: 0.002415290, Improvement: 0.000517682, Best Loss: 0.001036219 in Epoch 170
Epoch 187
Epoch 187, Loss: 0.003095176, Improvement: 0.000679887, Best Loss: 0.001036219 in Epoch 170
Epoch 188
Epoch 188, Loss: 0.002219592, Improvement: -0.000875584, Best Loss: 0.001036219 in Epoch 170
Epoch 189
A best model at epoch 189 has been saved with training error 0.001004324.
Epoch 189, Loss: 0.002032296, Improvement: -0.000187296, Best Loss: 0.001004324 in Epoch 189
Epoch 190
Epoch 190, Loss: 0.001928826, Improvement: -0.000103470, Best Loss: 0.001004324 in Epoch 189
Epoch 191
Epoch 191, Loss: 0.001760966, Improvement: -0.000167860, Best Loss: 0.001004324 in Epoch 189
Epoch 192
Epoch 192, Loss: 0.001859714, Improvement: 0.000098748, Best Loss: 0.001004324 in Epoch 189
Epoch 193
A best model at epoch 193 has been saved with training error 0.001002977.
A best model at epoch 193 has been saved with training error 0.000896794.
Epoch 193, Loss: 0.001753211, Improvement: -0.000106503, Best Loss: 0.000896794 in Epoch 193
Epoch 194
A best model at epoch 194 has been saved with training error 0.000869249.
Epoch 194, Loss: 0.001631418, Improvement: -0.000121793, Best Loss: 0.000869249 in Epoch 194
Epoch 195
Epoch 195, Loss: 0.001549498, Improvement: -0.000081920, Best Loss: 0.000869249 in Epoch 194
Epoch 196
Epoch 196, Loss: 0.001498212, Improvement: -0.000051286, Best Loss: 0.000869249 in Epoch 194
Epoch 197
Epoch 197, Loss: 0.001470486, Improvement: -0.000027726, Best Loss: 0.000869249 in Epoch 194
Epoch 198
Epoch 198, Loss: 0.001445837, Improvement: -0.000024648, Best Loss: 0.000869249 in Epoch 194
Epoch 199
Epoch 199, Loss: 0.001440099, Improvement: -0.000005738, Best Loss: 0.000869249 in Epoch 194
Epoch 200
Model saving checkpoint: the model trained after epoch 200 has been saved with the training errors.
Epoch 200, Loss: 0.001425706, Improvement: -0.000014394, Best Loss: 0.000869249 in Epoch 194
Epoch 201
A best model at epoch 201 has been saved with training error 0.000666218.
Epoch 201, Loss: 0.001410713, Improvement: -0.000014993, Best Loss: 0.000666218 in Epoch 201
Epoch 202
Epoch 202, Loss: 0.001397658, Improvement: -0.000013054, Best Loss: 0.000666218 in Epoch 201
Epoch 203
Epoch 203, Loss: 0.001380152, Improvement: -0.000017506, Best Loss: 0.000666218 in Epoch 201
Epoch 204
Epoch 204, Loss: 0.001393730, Improvement: 0.000013578, Best Loss: 0.000666218 in Epoch 201
Epoch 205
Epoch 205, Loss: 0.001384098, Improvement: -0.000009633, Best Loss: 0.000666218 in Epoch 201
Epoch 206
Epoch 206, Loss: 0.001366573, Improvement: -0.000017525, Best Loss: 0.000666218 in Epoch 201
Epoch 207
Epoch 207, Loss: 0.001355812, Improvement: -0.000010761, Best Loss: 0.000666218 in Epoch 201
Epoch 208
Epoch 208, Loss: 0.001406873, Improvement: 0.000051060, Best Loss: 0.000666218 in Epoch 201
Epoch 209
Epoch 209, Loss: 0.001418765, Improvement: 0.000011892, Best Loss: 0.000666218 in Epoch 201
Epoch 210
Epoch 210, Loss: 0.001385097, Improvement: -0.000033668, Best Loss: 0.000666218 in Epoch 201
Epoch 211
Epoch 211, Loss: 0.001343492, Improvement: -0.000041605, Best Loss: 0.000666218 in Epoch 201
Epoch 212
Epoch 212, Loss: 0.001341532, Improvement: -0.000001960, Best Loss: 0.000666218 in Epoch 201
Epoch 213
Epoch 213, Loss: 0.001340736, Improvement: -0.000000796, Best Loss: 0.000666218 in Epoch 201
Epoch 214
Epoch 214, Loss: 0.001360925, Improvement: 0.000020188, Best Loss: 0.000666218 in Epoch 201
Epoch 215
Epoch 215, Loss: 0.001375842, Improvement: 0.000014917, Best Loss: 0.000666218 in Epoch 201
Epoch 216
Epoch 216, Loss: 0.001569768, Improvement: 0.000193927, Best Loss: 0.000666218 in Epoch 201
Epoch 217
Epoch 217, Loss: 0.001452127, Improvement: -0.000117642, Best Loss: 0.000666218 in Epoch 201
Epoch 218
Epoch 218, Loss: 0.001470059, Improvement: 0.000017933, Best Loss: 0.000666218 in Epoch 201
Epoch 219
Epoch 219, Loss: 0.001425909, Improvement: -0.000044151, Best Loss: 0.000666218 in Epoch 201
Epoch 220
Epoch 220, Loss: 0.001448409, Improvement: 0.000022501, Best Loss: 0.000666218 in Epoch 201
Epoch 221
Epoch 221, Loss: 0.001503107, Improvement: 0.000054698, Best Loss: 0.000666218 in Epoch 201
Epoch 222
Epoch 222, Loss: 0.001372229, Improvement: -0.000130878, Best Loss: 0.000666218 in Epoch 201
Epoch 223
Epoch 223, Loss: 0.001301523, Improvement: -0.000070706, Best Loss: 0.000666218 in Epoch 201
Epoch 224
Epoch 224, Loss: 0.001359637, Improvement: 0.000058113, Best Loss: 0.000666218 in Epoch 201
Epoch 225
Epoch 225, Loss: 0.001364706, Improvement: 0.000005070, Best Loss: 0.000666218 in Epoch 201
Epoch 226
Epoch 226, Loss: 0.001340329, Improvement: -0.000024377, Best Loss: 0.000666218 in Epoch 201
Epoch 227
Epoch 227, Loss: 0.001266281, Improvement: -0.000074048, Best Loss: 0.000666218 in Epoch 201
Epoch 228
Epoch 228, Loss: 0.001219600, Improvement: -0.000046681, Best Loss: 0.000666218 in Epoch 201
Epoch 229
Epoch 229, Loss: 0.001195293, Improvement: -0.000024308, Best Loss: 0.000666218 in Epoch 201
Epoch 230
A best model at epoch 230 has been saved with training error 0.000579072.
Epoch 230, Loss: 0.001203074, Improvement: 0.000007782, Best Loss: 0.000579072 in Epoch 230
Epoch 231
Epoch 231, Loss: 0.001160421, Improvement: -0.000042653, Best Loss: 0.000579072 in Epoch 230
Epoch 232
Epoch 232, Loss: 0.001114579, Improvement: -0.000045842, Best Loss: 0.000579072 in Epoch 230
Epoch 233
Epoch 233, Loss: 0.001096315, Improvement: -0.000018264, Best Loss: 0.000579072 in Epoch 230
Epoch 234
A best model at epoch 234 has been saved with training error 0.000557648.
Epoch 234, Loss: 0.001105248, Improvement: 0.000008933, Best Loss: 0.000557648 in Epoch 234
Epoch 235
Epoch 235, Loss: 0.001200077, Improvement: 0.000094829, Best Loss: 0.000557648 in Epoch 234
Epoch 236
Epoch 236, Loss: 0.001300658, Improvement: 0.000100582, Best Loss: 0.000557648 in Epoch 234
Epoch 237
Epoch 237, Loss: 0.001403246, Improvement: 0.000102587, Best Loss: 0.000557648 in Epoch 234
Epoch 238
Epoch 238, Loss: 0.001398644, Improvement: -0.000004602, Best Loss: 0.000557648 in Epoch 234
Epoch 239
Epoch 239, Loss: 0.001228889, Improvement: -0.000169754, Best Loss: 0.000557648 in Epoch 234
Epoch 240
Epoch 240, Loss: 0.001135514, Improvement: -0.000093375, Best Loss: 0.000557648 in Epoch 234
Epoch 241
Epoch 241, Loss: 0.001108555, Improvement: -0.000026959, Best Loss: 0.000557648 in Epoch 234
Epoch 242
A best model at epoch 242 has been saved with training error 0.000475587.
Epoch 242, Loss: 0.001344015, Improvement: 0.000235460, Best Loss: 0.000475587 in Epoch 242
Epoch 243
Epoch 243, Loss: 0.001856992, Improvement: 0.000512977, Best Loss: 0.000475587 in Epoch 242
Epoch 244
Epoch 244, Loss: 0.001663709, Improvement: -0.000193284, Best Loss: 0.000475587 in Epoch 242
Epoch 245
Epoch 245, Loss: 0.001274215, Improvement: -0.000389494, Best Loss: 0.000475587 in Epoch 242
Epoch 246
Epoch 246, Loss: 0.001327537, Improvement: 0.000053322, Best Loss: 0.000475587 in Epoch 242
Epoch 247
Epoch 247, Loss: 0.001443811, Improvement: 0.000116274, Best Loss: 0.000475587 in Epoch 242
Epoch 248
Epoch 248, Loss: 0.001130803, Improvement: -0.000313007, Best Loss: 0.000475587 in Epoch 242
Epoch 249
Epoch 249, Loss: 0.001043948, Improvement: -0.000086855, Best Loss: 0.000475587 in Epoch 242
Epoch 250
Model saving checkpoint: the model trained after epoch 250 has been saved with the training errors.
Epoch 250, Loss: 0.000982270, Improvement: -0.000061678, Best Loss: 0.000475587 in Epoch 242
Epoch 251
Epoch 251, Loss: 0.000964292, Improvement: -0.000017978, Best Loss: 0.000475587 in Epoch 242
Epoch 252
Epoch 252, Loss: 0.000927724, Improvement: -0.000036568, Best Loss: 0.000475587 in Epoch 242
Epoch 253
Epoch 253, Loss: 0.000905974, Improvement: -0.000021749, Best Loss: 0.000475587 in Epoch 242
Epoch 254
Epoch 254, Loss: 0.000898493, Improvement: -0.000007481, Best Loss: 0.000475587 in Epoch 242
Epoch 255
Epoch 255, Loss: 0.000892943, Improvement: -0.000005550, Best Loss: 0.000475587 in Epoch 242
Epoch 256
Epoch 256, Loss: 0.000887558, Improvement: -0.000005385, Best Loss: 0.000475587 in Epoch 242
Epoch 257
A best model at epoch 257 has been saved with training error 0.000428872.
Epoch 257, Loss: 0.000871323, Improvement: -0.000016235, Best Loss: 0.000428872 in Epoch 257
Epoch 258
Epoch 258, Loss: 0.000877066, Improvement: 0.000005742, Best Loss: 0.000428872 in Epoch 257
Epoch 259
Epoch 259, Loss: 0.000860117, Improvement: -0.000016949, Best Loss: 0.000428872 in Epoch 257
Epoch 260
Epoch 260, Loss: 0.000848820, Improvement: -0.000011297, Best Loss: 0.000428872 in Epoch 257
Epoch 261
Epoch 261, Loss: 0.000832767, Improvement: -0.000016053, Best Loss: 0.000428872 in Epoch 257
Epoch 262
Epoch 262, Loss: 0.000844489, Improvement: 0.000011722, Best Loss: 0.000428872 in Epoch 257
Epoch 263
Epoch 263, Loss: 0.000837824, Improvement: -0.000006665, Best Loss: 0.000428872 in Epoch 257
Epoch 264
Epoch 264, Loss: 0.000895441, Improvement: 0.000057617, Best Loss: 0.000428872 in Epoch 257
Epoch 265
Epoch 265, Loss: 0.001034490, Improvement: 0.000139049, Best Loss: 0.000428872 in Epoch 257
Epoch 266
Epoch 266, Loss: 0.001118699, Improvement: 0.000084209, Best Loss: 0.000428872 in Epoch 257
Epoch 267
Epoch 267, Loss: 0.001381322, Improvement: 0.000262624, Best Loss: 0.000428872 in Epoch 257
Epoch 268
Epoch 268, Loss: 0.001589719, Improvement: 0.000208397, Best Loss: 0.000428872 in Epoch 257
Epoch 269
Epoch 269, Loss: 0.001355451, Improvement: -0.000234269, Best Loss: 0.000428872 in Epoch 257
Epoch 270
Epoch 270, Loss: 0.001091712, Improvement: -0.000263739, Best Loss: 0.000428872 in Epoch 257
Epoch 271
Epoch 271, Loss: 0.000915986, Improvement: -0.000175726, Best Loss: 0.000428872 in Epoch 257
Epoch 272
Epoch 272, Loss: 0.000867798, Improvement: -0.000048189, Best Loss: 0.000428872 in Epoch 257
Epoch 273
Epoch 273, Loss: 0.001011364, Improvement: 0.000143567, Best Loss: 0.000428872 in Epoch 257
Epoch 274
Epoch 274, Loss: 0.000979917, Improvement: -0.000031447, Best Loss: 0.000428872 in Epoch 257
Epoch 275
Epoch 275, Loss: 0.000925770, Improvement: -0.000054147, Best Loss: 0.000428872 in Epoch 257
Epoch 276
Epoch 276, Loss: 0.001097025, Improvement: 0.000171256, Best Loss: 0.000428872 in Epoch 257
Epoch 277
Epoch 277, Loss: 0.001012133, Improvement: -0.000084893, Best Loss: 0.000428872 in Epoch 257
Epoch 278
A best model at epoch 278 has been saved with training error 0.000372869.
Epoch 278, Loss: 0.000966299, Improvement: -0.000045834, Best Loss: 0.000372869 in Epoch 278
Epoch 279
Epoch 279, Loss: 0.000865457, Improvement: -0.000100841, Best Loss: 0.000372869 in Epoch 278
Epoch 280
Epoch 280, Loss: 0.000777333, Improvement: -0.000088124, Best Loss: 0.000372869 in Epoch 278
Epoch 281
Epoch 281, Loss: 0.000761817, Improvement: -0.000015517, Best Loss: 0.000372869 in Epoch 278
Epoch 282
Epoch 282, Loss: 0.000783161, Improvement: 0.000021344, Best Loss: 0.000372869 in Epoch 278
Epoch 283
Epoch 283, Loss: 0.000769076, Improvement: -0.000014085, Best Loss: 0.000372869 in Epoch 278
Epoch 284
Epoch 284, Loss: 0.000725402, Improvement: -0.000043674, Best Loss: 0.000372869 in Epoch 278
Epoch 285
Epoch 285, Loss: 0.000705351, Improvement: -0.000020051, Best Loss: 0.000372869 in Epoch 278
Epoch 286
A best model at epoch 286 has been saved with training error 0.000370878.
Epoch 286, Loss: 0.000688272, Improvement: -0.000017079, Best Loss: 0.000370878 in Epoch 286
Epoch 287
Epoch 287, Loss: 0.000684440, Improvement: -0.000003831, Best Loss: 0.000370878 in Epoch 286
Epoch 288
Epoch 288, Loss: 0.000679005, Improvement: -0.000005436, Best Loss: 0.000370878 in Epoch 286
Epoch 289
Epoch 289, Loss: 0.000713657, Improvement: 0.000034653, Best Loss: 0.000370878 in Epoch 286
Epoch 290
Epoch 290, Loss: 0.000728512, Improvement: 0.000014855, Best Loss: 0.000370878 in Epoch 286
Epoch 291
Epoch 291, Loss: 0.000855142, Improvement: 0.000126630, Best Loss: 0.000370878 in Epoch 286
Epoch 292
Epoch 292, Loss: 0.000801056, Improvement: -0.000054086, Best Loss: 0.000370878 in Epoch 286
Epoch 293
Epoch 293, Loss: 0.000789279, Improvement: -0.000011777, Best Loss: 0.000370878 in Epoch 286
Epoch 294
Epoch 294, Loss: 0.000820716, Improvement: 0.000031437, Best Loss: 0.000370878 in Epoch 286
Epoch 295
Epoch 295, Loss: 0.000839619, Improvement: 0.000018903, Best Loss: 0.000370878 in Epoch 286
Epoch 296
Epoch 296, Loss: 0.000784435, Improvement: -0.000055184, Best Loss: 0.000370878 in Epoch 286
Epoch 297
Epoch 297, Loss: 0.000682088, Improvement: -0.000102347, Best Loss: 0.000370878 in Epoch 286
Epoch 298
Epoch 298, Loss: 0.000658476, Improvement: -0.000023612, Best Loss: 0.000370878 in Epoch 286
Epoch 299
Epoch 299, Loss: 0.000621648, Improvement: -0.000036828, Best Loss: 0.000370878 in Epoch 286
Epoch 300
Model saving checkpoint: the model trained after epoch 300 has been saved with the training errors.
Epoch 300, Loss: 0.000609350, Improvement: -0.000012297, Best Loss: 0.000370878 in Epoch 286
Epoch 301
Epoch 301, Loss: 0.000755904, Improvement: 0.000146554, Best Loss: 0.000370878 in Epoch 286
Epoch 302
Epoch 302, Loss: 0.000696166, Improvement: -0.000059738, Best Loss: 0.000370878 in Epoch 286
Epoch 303
Epoch 303, Loss: 0.000689037, Improvement: -0.000007129, Best Loss: 0.000370878 in Epoch 286
Epoch 304
Epoch 304, Loss: 0.000650585, Improvement: -0.000038452, Best Loss: 0.000370878 in Epoch 286
Epoch 305
Epoch 305, Loss: 0.000622347, Improvement: -0.000028238, Best Loss: 0.000370878 in Epoch 286
Epoch 306
Epoch 306, Loss: 0.000623048, Improvement: 0.000000701, Best Loss: 0.000370878 in Epoch 286
Epoch 307
Epoch 307, Loss: 0.000607241, Improvement: -0.000015807, Best Loss: 0.000370878 in Epoch 286
Epoch 308
Epoch 308, Loss: 0.000574133, Improvement: -0.000033109, Best Loss: 0.000370878 in Epoch 286
Epoch 309
Epoch 309, Loss: 0.000613362, Improvement: 0.000039229, Best Loss: 0.000370878 in Epoch 286
Epoch 310
Epoch 310, Loss: 0.000841446, Improvement: 0.000228084, Best Loss: 0.000370878 in Epoch 286
Epoch 311
Epoch 311, Loss: 0.000847592, Improvement: 0.000006146, Best Loss: 0.000370878 in Epoch 286
Epoch 312
Epoch 312, Loss: 0.000751691, Improvement: -0.000095901, Best Loss: 0.000370878 in Epoch 286
Epoch 313
Epoch 313, Loss: 0.000720345, Improvement: -0.000031345, Best Loss: 0.000370878 in Epoch 286
Epoch 314
Epoch 314, Loss: 0.000799844, Improvement: 0.000079499, Best Loss: 0.000370878 in Epoch 286
Epoch 315
Epoch 315, Loss: 0.000697918, Improvement: -0.000101926, Best Loss: 0.000370878 in Epoch 286
Epoch 316
Epoch 316, Loss: 0.000732984, Improvement: 0.000035066, Best Loss: 0.000370878 in Epoch 286
Epoch 317
Epoch 317, Loss: 0.000769259, Improvement: 0.000036276, Best Loss: 0.000370878 in Epoch 286
Epoch 318
Epoch 318, Loss: 0.000743066, Improvement: -0.000026193, Best Loss: 0.000370878 in Epoch 286
Epoch 319
Epoch 319, Loss: 0.000649842, Improvement: -0.000093225, Best Loss: 0.000370878 in Epoch 286
Epoch 320
Epoch 320, Loss: 0.000677008, Improvement: 0.000027166, Best Loss: 0.000370878 in Epoch 286
Epoch 321
A best model at epoch 321 has been saved with training error 0.000320737.
Epoch 321, Loss: 0.000683438, Improvement: 0.000006430, Best Loss: 0.000320737 in Epoch 321
Epoch 322
Epoch 322, Loss: 0.000536004, Improvement: -0.000147434, Best Loss: 0.000320737 in Epoch 321
Epoch 323
Epoch 323, Loss: 0.000493520, Improvement: -0.000042484, Best Loss: 0.000320737 in Epoch 321
Epoch 324
A best model at epoch 324 has been saved with training error 0.000307680.
Epoch 324, Loss: 0.000481366, Improvement: -0.000012154, Best Loss: 0.000307680 in Epoch 324
Epoch 325
Epoch 325, Loss: 0.000481163, Improvement: -0.000000204, Best Loss: 0.000307680 in Epoch 324
Epoch 326
Epoch 326, Loss: 0.000478577, Improvement: -0.000002586, Best Loss: 0.000307680 in Epoch 324
Epoch 327
Epoch 327, Loss: 0.000487419, Improvement: 0.000008842, Best Loss: 0.000307680 in Epoch 324
Epoch 328
A best model at epoch 328 has been saved with training error 0.000273217.
Epoch 328, Loss: 0.000467493, Improvement: -0.000019926, Best Loss: 0.000273217 in Epoch 328
Epoch 329
Epoch 329, Loss: 0.000458178, Improvement: -0.000009315, Best Loss: 0.000273217 in Epoch 328
Epoch 330
Epoch 330, Loss: 0.000504079, Improvement: 0.000045901, Best Loss: 0.000273217 in Epoch 328
Epoch 331
Epoch 331, Loss: 0.000476446, Improvement: -0.000027633, Best Loss: 0.000273217 in Epoch 328
Epoch 332
Epoch 332, Loss: 0.000613857, Improvement: 0.000137411, Best Loss: 0.000273217 in Epoch 328
Epoch 333
Epoch 333, Loss: 0.000631417, Improvement: 0.000017560, Best Loss: 0.000273217 in Epoch 328
Epoch 334
Epoch 334, Loss: 0.000500930, Improvement: -0.000130487, Best Loss: 0.000273217 in Epoch 328
Epoch 335
Epoch 335, Loss: 0.000480760, Improvement: -0.000020170, Best Loss: 0.000273217 in Epoch 328
Epoch 336
A best model at epoch 336 has been saved with training error 0.000266599.
Epoch 336, Loss: 0.000477403, Improvement: -0.000003358, Best Loss: 0.000266599 in Epoch 336
Epoch 337
A best model at epoch 337 has been saved with training error 0.000253683.
Epoch 337, Loss: 0.000564606, Improvement: 0.000087203, Best Loss: 0.000253683 in Epoch 337
Epoch 338
Epoch 338, Loss: 0.000508062, Improvement: -0.000056544, Best Loss: 0.000253683 in Epoch 337
Epoch 339
Epoch 339, Loss: 0.000636838, Improvement: 0.000128776, Best Loss: 0.000253683 in Epoch 337
Epoch 340
Epoch 340, Loss: 0.000537155, Improvement: -0.000099682, Best Loss: 0.000253683 in Epoch 337
Epoch 341
Epoch 341, Loss: 0.000462152, Improvement: -0.000075004, Best Loss: 0.000253683 in Epoch 337
Epoch 342
Epoch 342, Loss: 0.000454068, Improvement: -0.000008084, Best Loss: 0.000253683 in Epoch 337
Epoch 343
Epoch 343, Loss: 0.000435887, Improvement: -0.000018181, Best Loss: 0.000253683 in Epoch 337
Epoch 344
Epoch 344, Loss: 0.000406877, Improvement: -0.000029009, Best Loss: 0.000253683 in Epoch 337
Epoch 345
Epoch 345, Loss: 0.000397959, Improvement: -0.000008918, Best Loss: 0.000253683 in Epoch 337
Epoch 346
A best model at epoch 346 has been saved with training error 0.000225291.
Epoch 346, Loss: 0.000389449, Improvement: -0.000008511, Best Loss: 0.000225291 in Epoch 346
Epoch 347
Epoch 347, Loss: 0.000368979, Improvement: -0.000020469, Best Loss: 0.000225291 in Epoch 346
Epoch 348
Epoch 348, Loss: 0.000409198, Improvement: 0.000040218, Best Loss: 0.000225291 in Epoch 346
Epoch 349
Epoch 349, Loss: 0.000414350, Improvement: 0.000005152, Best Loss: 0.000225291 in Epoch 346
Epoch 350
Model saving checkpoint: the model trained after epoch 350 has been saved with the training errors.
Epoch 350, Loss: 0.000451090, Improvement: 0.000036741, Best Loss: 0.000225291 in Epoch 346
Epoch 351
Epoch 351, Loss: 0.000568313, Improvement: 0.000117222, Best Loss: 0.000225291 in Epoch 346
Epoch 352
Epoch 352, Loss: 0.000646306, Improvement: 0.000077994, Best Loss: 0.000225291 in Epoch 346
Epoch 353
Epoch 353, Loss: 0.000654519, Improvement: 0.000008212, Best Loss: 0.000225291 in Epoch 346
Epoch 354
Epoch 354, Loss: 0.000728923, Improvement: 0.000074404, Best Loss: 0.000225291 in Epoch 346
Epoch 355
Epoch 355, Loss: 0.000612987, Improvement: -0.000115936, Best Loss: 0.000225291 in Epoch 346
Epoch 356
Epoch 356, Loss: 0.000477000, Improvement: -0.000135987, Best Loss: 0.000225291 in Epoch 346
Epoch 357
Epoch 357, Loss: 0.000395309, Improvement: -0.000081691, Best Loss: 0.000225291 in Epoch 346
Epoch 358
Epoch 358, Loss: 0.000475410, Improvement: 0.000080100, Best Loss: 0.000225291 in Epoch 346
Epoch 359
Epoch 359, Loss: 0.000419241, Improvement: -0.000056169, Best Loss: 0.000225291 in Epoch 346
Epoch 360
Epoch 360, Loss: 0.000364954, Improvement: -0.000054287, Best Loss: 0.000225291 in Epoch 346
Epoch 361
A best model at epoch 361 has been saved with training error 0.000219962.
A best model at epoch 361 has been saved with training error 0.000215599.
A best model at epoch 361 has been saved with training error 0.000209059.
Epoch 361, Loss: 0.000324492, Improvement: -0.000040462, Best Loss: 0.000209059 in Epoch 361
Epoch 362
Epoch 362, Loss: 0.000315022, Improvement: -0.000009470, Best Loss: 0.000209059 in Epoch 361
Epoch 363
Epoch 363, Loss: 0.000303893, Improvement: -0.000011129, Best Loss: 0.000209059 in Epoch 361
Epoch 364
Epoch 364, Loss: 0.000295852, Improvement: -0.000008042, Best Loss: 0.000209059 in Epoch 361
Epoch 365
A best model at epoch 365 has been saved with training error 0.000202899.
A best model at epoch 365 has been saved with training error 0.000188456.
Epoch 365, Loss: 0.000289597, Improvement: -0.000006255, Best Loss: 0.000188456 in Epoch 365
Epoch 366
Epoch 366, Loss: 0.000288732, Improvement: -0.000000865, Best Loss: 0.000188456 in Epoch 365
Epoch 367
Epoch 367, Loss: 0.000286697, Improvement: -0.000002034, Best Loss: 0.000188456 in Epoch 365
Epoch 368
Epoch 368, Loss: 0.000292643, Improvement: 0.000005945, Best Loss: 0.000188456 in Epoch 365
Epoch 369
Epoch 369, Loss: 0.000329125, Improvement: 0.000036482, Best Loss: 0.000188456 in Epoch 365
Epoch 370
Epoch 370, Loss: 0.000420354, Improvement: 0.000091229, Best Loss: 0.000188456 in Epoch 365
Epoch 371
Epoch 371, Loss: 0.000396557, Improvement: -0.000023797, Best Loss: 0.000188456 in Epoch 365
Epoch 372
Epoch 372, Loss: 0.000404110, Improvement: 0.000007553, Best Loss: 0.000188456 in Epoch 365
Epoch 373
Epoch 373, Loss: 0.000397787, Improvement: -0.000006323, Best Loss: 0.000188456 in Epoch 365
Epoch 374
Epoch 374, Loss: 0.000359366, Improvement: -0.000038421, Best Loss: 0.000188456 in Epoch 365
Epoch 375
Epoch 375, Loss: 0.000368184, Improvement: 0.000008818, Best Loss: 0.000188456 in Epoch 365
Epoch 376
Epoch 376, Loss: 0.000377473, Improvement: 0.000009289, Best Loss: 0.000188456 in Epoch 365
Epoch 377
Epoch 377, Loss: 0.000401997, Improvement: 0.000024524, Best Loss: 0.000188456 in Epoch 365
Epoch 378
Epoch 378, Loss: 0.000713723, Improvement: 0.000311725, Best Loss: 0.000188456 in Epoch 365
Epoch 379
Epoch 379, Loss: 0.000870241, Improvement: 0.000156518, Best Loss: 0.000188456 in Epoch 365
Epoch 380
Epoch 380, Loss: 0.000683482, Improvement: -0.000186758, Best Loss: 0.000188456 in Epoch 365
Epoch 381
Epoch 381, Loss: 0.000452166, Improvement: -0.000231317, Best Loss: 0.000188456 in Epoch 365
Epoch 382
Epoch 382, Loss: 0.000340406, Improvement: -0.000111760, Best Loss: 0.000188456 in Epoch 365
Epoch 383
Epoch 383, Loss: 0.000299838, Improvement: -0.000040568, Best Loss: 0.000188456 in Epoch 365
Epoch 384
A best model at epoch 384 has been saved with training error 0.000186567.
Epoch 384, Loss: 0.000271829, Improvement: -0.000028009, Best Loss: 0.000186567 in Epoch 384
Epoch 385
A best model at epoch 385 has been saved with training error 0.000159850.
Epoch 385, Loss: 0.000263176, Improvement: -0.000008653, Best Loss: 0.000159850 in Epoch 385
Epoch 386
Epoch 386, Loss: 0.000241528, Improvement: -0.000021647, Best Loss: 0.000159850 in Epoch 385
Epoch 387
Epoch 387, Loss: 0.000234242, Improvement: -0.000007286, Best Loss: 0.000159850 in Epoch 385
Epoch 388
Epoch 388, Loss: 0.000229458, Improvement: -0.000004784, Best Loss: 0.000159850 in Epoch 385
Epoch 389
Epoch 389, Loss: 0.000226241, Improvement: -0.000003217, Best Loss: 0.000159850 in Epoch 385
Epoch 390
A best model at epoch 390 has been saved with training error 0.000135884.
Epoch 390, Loss: 0.000222718, Improvement: -0.000003523, Best Loss: 0.000135884 in Epoch 390
Epoch 391
Epoch 391, Loss: 0.000220545, Improvement: -0.000002173, Best Loss: 0.000135884 in Epoch 390
Epoch 392
Epoch 392, Loss: 0.000218467, Improvement: -0.000002078, Best Loss: 0.000135884 in Epoch 390
Epoch 393
A best model at epoch 393 has been saved with training error 0.000134025.
Epoch 393, Loss: 0.000214761, Improvement: -0.000003706, Best Loss: 0.000134025 in Epoch 393
Epoch 394
A best model at epoch 394 has been saved with training error 0.000129335.
Epoch 394, Loss: 0.000213000, Improvement: -0.000001761, Best Loss: 0.000129335 in Epoch 394
Epoch 395
Epoch 395, Loss: 0.000209240, Improvement: -0.000003760, Best Loss: 0.000129335 in Epoch 394
Epoch 396
A best model at epoch 396 has been saved with training error 0.000116106.
Epoch 396, Loss: 0.000207961, Improvement: -0.000001279, Best Loss: 0.000116106 in Epoch 396
Epoch 397
Epoch 397, Loss: 0.000210225, Improvement: 0.000002265, Best Loss: 0.000116106 in Epoch 396
Epoch 398
Epoch 398, Loss: 0.000205227, Improvement: -0.000004998, Best Loss: 0.000116106 in Epoch 396
Epoch 399
Epoch 399, Loss: 0.000207702, Improvement: 0.000002475, Best Loss: 0.000116106 in Epoch 396
Epoch 400
Model saving checkpoint: the model trained after epoch 400 has been saved with the training errors.
Epoch 400, Loss: 0.000207553, Improvement: -0.000000150, Best Loss: 0.000116106 in Epoch 396
Epoch 401
Epoch 401, Loss: 0.000222041, Improvement: 0.000014488, Best Loss: 0.000116106 in Epoch 396
Epoch 402
Epoch 402, Loss: 0.000212261, Improvement: -0.000009780, Best Loss: 0.000116106 in Epoch 396
Epoch 403
Epoch 403, Loss: 0.000223442, Improvement: 0.000011181, Best Loss: 0.000116106 in Epoch 396
Epoch 404
Epoch 404, Loss: 0.000272911, Improvement: 0.000049470, Best Loss: 0.000116106 in Epoch 396
Epoch 405
Epoch 405, Loss: 0.000263602, Improvement: -0.000009309, Best Loss: 0.000116106 in Epoch 396
Epoch 406
Epoch 406, Loss: 0.000249722, Improvement: -0.000013880, Best Loss: 0.000116106 in Epoch 396
Epoch 407
Epoch 407, Loss: 0.000211883, Improvement: -0.000037839, Best Loss: 0.000116106 in Epoch 396
Epoch 408
Epoch 408, Loss: 0.000227420, Improvement: 0.000015537, Best Loss: 0.000116106 in Epoch 396
Epoch 409
Epoch 409, Loss: 0.000226773, Improvement: -0.000000648, Best Loss: 0.000116106 in Epoch 396
Epoch 410
Epoch 410, Loss: 0.000210094, Improvement: -0.000016679, Best Loss: 0.000116106 in Epoch 396
Epoch 411
Epoch 411, Loss: 0.000203257, Improvement: -0.000006837, Best Loss: 0.000116106 in Epoch 396
Epoch 412
A best model at epoch 412 has been saved with training error 0.000114996.
Epoch 412, Loss: 0.000213975, Improvement: 0.000010718, Best Loss: 0.000114996 in Epoch 412
Epoch 413
Epoch 413, Loss: 0.000333526, Improvement: 0.000119551, Best Loss: 0.000114996 in Epoch 412
Epoch 414
Epoch 414, Loss: 0.000260933, Improvement: -0.000072593, Best Loss: 0.000114996 in Epoch 412
Epoch 415
Epoch 415, Loss: 0.000296446, Improvement: 0.000035513, Best Loss: 0.000114996 in Epoch 412
Epoch 416
Epoch 416, Loss: 0.000244604, Improvement: -0.000051842, Best Loss: 0.000114996 in Epoch 412
Epoch 417
Epoch 417, Loss: 0.000236602, Improvement: -0.000008002, Best Loss: 0.000114996 in Epoch 412
Epoch 418
Epoch 418, Loss: 0.000202077, Improvement: -0.000034525, Best Loss: 0.000114996 in Epoch 412
Epoch 419
Epoch 419, Loss: 0.000202024, Improvement: -0.000000053, Best Loss: 0.000114996 in Epoch 412
Epoch 420
Epoch 420, Loss: 0.000217243, Improvement: 0.000015220, Best Loss: 0.000114996 in Epoch 412
Epoch 421
Epoch 421, Loss: 0.000236881, Improvement: 0.000019637, Best Loss: 0.000114996 in Epoch 412
Epoch 422
Epoch 422, Loss: 0.000251872, Improvement: 0.000014992, Best Loss: 0.000114996 in Epoch 412
Epoch 423
Epoch 423, Loss: 0.000265114, Improvement: 0.000013242, Best Loss: 0.000114996 in Epoch 412
Epoch 424
Epoch 424, Loss: 0.000218835, Improvement: -0.000046280, Best Loss: 0.000114996 in Epoch 412
Epoch 425
Epoch 425, Loss: 0.000219377, Improvement: 0.000000542, Best Loss: 0.000114996 in Epoch 412
Epoch 426
Epoch 426, Loss: 0.000249674, Improvement: 0.000030297, Best Loss: 0.000114996 in Epoch 412
Epoch 427
Epoch 427, Loss: 0.000234733, Improvement: -0.000014941, Best Loss: 0.000114996 in Epoch 412
Epoch 428
Epoch 428, Loss: 0.000230905, Improvement: -0.000003828, Best Loss: 0.000114996 in Epoch 412
Epoch 429
Epoch 429, Loss: 0.000302716, Improvement: 0.000071810, Best Loss: 0.000114996 in Epoch 412
Epoch 430
Epoch 430, Loss: 0.000389068, Improvement: 0.000086352, Best Loss: 0.000114996 in Epoch 412
Epoch 431
Epoch 431, Loss: 0.000420032, Improvement: 0.000030963, Best Loss: 0.000114996 in Epoch 412
Epoch 432
Epoch 432, Loss: 0.000284455, Improvement: -0.000135576, Best Loss: 0.000114996 in Epoch 412
Epoch 433
Epoch 433, Loss: 0.000205730, Improvement: -0.000078726, Best Loss: 0.000114996 in Epoch 412
Epoch 434
Epoch 434, Loss: 0.000177992, Improvement: -0.000027738, Best Loss: 0.000114996 in Epoch 412
Epoch 435
Epoch 435, Loss: 0.000168032, Improvement: -0.000009960, Best Loss: 0.000114996 in Epoch 412
Epoch 436
Epoch 436, Loss: 0.000155927, Improvement: -0.000012104, Best Loss: 0.000114996 in Epoch 412
Epoch 437
A best model at epoch 437 has been saved with training error 0.000101803.
Epoch 437, Loss: 0.000154530, Improvement: -0.000001397, Best Loss: 0.000101803 in Epoch 437
Epoch 438
Epoch 438, Loss: 0.000148091, Improvement: -0.000006439, Best Loss: 0.000101803 in Epoch 437
Epoch 439
Epoch 439, Loss: 0.000145517, Improvement: -0.000002573, Best Loss: 0.000101803 in Epoch 437
Epoch 440
Epoch 440, Loss: 0.000143336, Improvement: -0.000002182, Best Loss: 0.000101803 in Epoch 437
Epoch 441
Epoch 441, Loss: 0.000150059, Improvement: 0.000006724, Best Loss: 0.000101803 in Epoch 437
Epoch 442
A best model at epoch 442 has been saved with training error 0.000083157.
Epoch 442, Loss: 0.000146652, Improvement: -0.000003408, Best Loss: 0.000083157 in Epoch 442
Epoch 443
Epoch 443, Loss: 0.000143600, Improvement: -0.000003052, Best Loss: 0.000083157 in Epoch 442
Epoch 444
Epoch 444, Loss: 0.000134483, Improvement: -0.000009117, Best Loss: 0.000083157 in Epoch 442
Epoch 445
Epoch 445, Loss: 0.000132484, Improvement: -0.000001999, Best Loss: 0.000083157 in Epoch 442
Epoch 446
Epoch 446, Loss: 0.000129354, Improvement: -0.000003130, Best Loss: 0.000083157 in Epoch 442
Epoch 447
Epoch 447, Loss: 0.000126773, Improvement: -0.000002581, Best Loss: 0.000083157 in Epoch 442
Epoch 448
Epoch 448, Loss: 0.000126419, Improvement: -0.000000354, Best Loss: 0.000083157 in Epoch 442
Epoch 449
Epoch 449, Loss: 0.000126627, Improvement: 0.000000208, Best Loss: 0.000083157 in Epoch 442
Epoch 450
Model saving checkpoint: the model trained after epoch 450 has been saved with the training errors.
Epoch 450, Loss: 0.000124863, Improvement: -0.000001764, Best Loss: 0.000083157 in Epoch 442
Epoch 451
A best model at epoch 451 has been saved with training error 0.000079755.
Epoch 451, Loss: 0.000121639, Improvement: -0.000003223, Best Loss: 0.000079755 in Epoch 451
Epoch 452
Epoch 452, Loss: 0.000121624, Improvement: -0.000000016, Best Loss: 0.000079755 in Epoch 451
Epoch 453
Epoch 453, Loss: 0.000119779, Improvement: -0.000001845, Best Loss: 0.000079755 in Epoch 451
Epoch 454
Epoch 454, Loss: 0.000119492, Improvement: -0.000000287, Best Loss: 0.000079755 in Epoch 451
Epoch 455
Epoch 455, Loss: 0.000123141, Improvement: 0.000003649, Best Loss: 0.000079755 in Epoch 451
Epoch 456
Epoch 456, Loss: 0.000129678, Improvement: 0.000006537, Best Loss: 0.000079755 in Epoch 451
Epoch 457
Epoch 457, Loss: 0.000174024, Improvement: 0.000044347, Best Loss: 0.000079755 in Epoch 451
Epoch 458
Epoch 458, Loss: 0.000216857, Improvement: 0.000042833, Best Loss: 0.000079755 in Epoch 451
Epoch 459
Epoch 459, Loss: 0.000252467, Improvement: 0.000035610, Best Loss: 0.000079755 in Epoch 451
Epoch 460
Epoch 460, Loss: 0.000215829, Improvement: -0.000036638, Best Loss: 0.000079755 in Epoch 451
Epoch 461
Epoch 461, Loss: 0.000283921, Improvement: 0.000068092, Best Loss: 0.000079755 in Epoch 451
Epoch 462
Epoch 462, Loss: 0.000319521, Improvement: 0.000035599, Best Loss: 0.000079755 in Epoch 451
Epoch 463
Epoch 463, Loss: 0.000220276, Improvement: -0.000099244, Best Loss: 0.000079755 in Epoch 451
Epoch 464
Epoch 464, Loss: 0.000253067, Improvement: 0.000032790, Best Loss: 0.000079755 in Epoch 451
Epoch 465
Epoch 465, Loss: 0.000230994, Improvement: -0.000022073, Best Loss: 0.000079755 in Epoch 451
Epoch 466
Epoch 466, Loss: 0.000186740, Improvement: -0.000044254, Best Loss: 0.000079755 in Epoch 451
Epoch 467
Epoch 467, Loss: 0.000166174, Improvement: -0.000020565, Best Loss: 0.000079755 in Epoch 451
Epoch 468
Epoch 468, Loss: 0.000133290, Improvement: -0.000032885, Best Loss: 0.000079755 in Epoch 451
Epoch 469
Epoch 469, Loss: 0.000139982, Improvement: 0.000006692, Best Loss: 0.000079755 in Epoch 451
Epoch 470
A best model at epoch 470 has been saved with training error 0.000075261.
Epoch 470, Loss: 0.000125252, Improvement: -0.000014730, Best Loss: 0.000075261 in Epoch 470
Epoch 471
A best model at epoch 471 has been saved with training error 0.000073723.
Epoch 471, Loss: 0.000110911, Improvement: -0.000014341, Best Loss: 0.000073723 in Epoch 471
Epoch 472
Epoch 472, Loss: 0.000111020, Improvement: 0.000000109, Best Loss: 0.000073723 in Epoch 471
Epoch 473
Epoch 473, Loss: 0.000113885, Improvement: 0.000002866, Best Loss: 0.000073723 in Epoch 471
Epoch 474
Epoch 474, Loss: 0.000111724, Improvement: -0.000002161, Best Loss: 0.000073723 in Epoch 471
Epoch 475
Epoch 475, Loss: 0.000108977, Improvement: -0.000002747, Best Loss: 0.000073723 in Epoch 471
Epoch 476
Epoch 476, Loss: 0.000121776, Improvement: 0.000012798, Best Loss: 0.000073723 in Epoch 471
Epoch 477
Epoch 477, Loss: 0.000122733, Improvement: 0.000000958, Best Loss: 0.000073723 in Epoch 471
Epoch 478
Epoch 478, Loss: 0.000135004, Improvement: 0.000012270, Best Loss: 0.000073723 in Epoch 471
Epoch 479
Epoch 479, Loss: 0.000119258, Improvement: -0.000015745, Best Loss: 0.000073723 in Epoch 471
Epoch 480
Epoch 480, Loss: 0.000122745, Improvement: 0.000003487, Best Loss: 0.000073723 in Epoch 471
Epoch 481
Epoch 481, Loss: 0.000150077, Improvement: 0.000027332, Best Loss: 0.000073723 in Epoch 471
Epoch 482
Epoch 482, Loss: 0.000151794, Improvement: 0.000001716, Best Loss: 0.000073723 in Epoch 471
Epoch 483
Epoch 483, Loss: 0.000189675, Improvement: 0.000037882, Best Loss: 0.000073723 in Epoch 471
Epoch 484
Epoch 484, Loss: 0.000263651, Improvement: 0.000073976, Best Loss: 0.000073723 in Epoch 471
Epoch 485
Epoch 485, Loss: 0.000191692, Improvement: -0.000071959, Best Loss: 0.000073723 in Epoch 471
Epoch 486
Epoch 486, Loss: 0.000154138, Improvement: -0.000037554, Best Loss: 0.000073723 in Epoch 471
Epoch 487
Epoch 487, Loss: 0.000149126, Improvement: -0.000005011, Best Loss: 0.000073723 in Epoch 471
Epoch 488
Epoch 488, Loss: 0.000149734, Improvement: 0.000000608, Best Loss: 0.000073723 in Epoch 471
Epoch 489
Epoch 489, Loss: 0.000135017, Improvement: -0.000014717, Best Loss: 0.000073723 in Epoch 471
Epoch 490
Epoch 490, Loss: 0.000137275, Improvement: 0.000002258, Best Loss: 0.000073723 in Epoch 471
Epoch 491
Epoch 491, Loss: 0.000150685, Improvement: 0.000013411, Best Loss: 0.000073723 in Epoch 471
Epoch 492
Epoch 492, Loss: 0.000309236, Improvement: 0.000158551, Best Loss: 0.000073723 in Epoch 471
Epoch 493
Epoch 493, Loss: 0.000233912, Improvement: -0.000075324, Best Loss: 0.000073723 in Epoch 471
Epoch 494
Epoch 494, Loss: 0.000176180, Improvement: -0.000057732, Best Loss: 0.000073723 in Epoch 471
Epoch 495
Epoch 495, Loss: 0.000125529, Improvement: -0.000050651, Best Loss: 0.000073723 in Epoch 471
Epoch 496
A best model at epoch 496 has been saved with training error 0.000069795.
Epoch 496, Loss: 0.000107863, Improvement: -0.000017666, Best Loss: 0.000069795 in Epoch 496
Epoch 497
A best model at epoch 497 has been saved with training error 0.000065633.
Epoch 497, Loss: 0.000120777, Improvement: 0.000012915, Best Loss: 0.000065633 in Epoch 497
Epoch 498
Epoch 498, Loss: 0.000139933, Improvement: 0.000019156, Best Loss: 0.000065633 in Epoch 497
Epoch 499
Epoch 499, Loss: 0.000144296, Improvement: 0.000004362, Best Loss: 0.000065633 in Epoch 497
Epoch 500
Model saving checkpoint: the model trained after epoch 500 has been saved with the training errors.
Epoch 500, Loss: 0.000115355, Improvement: -0.000028941, Best Loss: 0.000065633 in Epoch 497
Epoch 501
Epoch 501, Loss: 0.000103005, Improvement: -0.000012350, Best Loss: 0.000065633 in Epoch 497
Epoch 502
Epoch 502, Loss: 0.000100403, Improvement: -0.000002602, Best Loss: 0.000065633 in Epoch 497
Epoch 503
Epoch 503, Loss: 0.000110400, Improvement: 0.000009997, Best Loss: 0.000065633 in Epoch 497
Epoch 504
Epoch 504, Loss: 0.000107760, Improvement: -0.000002641, Best Loss: 0.000065633 in Epoch 497
Epoch 505
Epoch 505, Loss: 0.000113148, Improvement: 0.000005389, Best Loss: 0.000065633 in Epoch 497
Epoch 506
A best model at epoch 506 has been saved with training error 0.000057147.
Epoch 506, Loss: 0.000102198, Improvement: -0.000010950, Best Loss: 0.000057147 in Epoch 506
Epoch 507
Epoch 507, Loss: 0.000097159, Improvement: -0.000005039, Best Loss: 0.000057147 in Epoch 506
Epoch 508
Epoch 508, Loss: 0.000103059, Improvement: 0.000005900, Best Loss: 0.000057147 in Epoch 506
Epoch 509
Epoch 509, Loss: 0.000091817, Improvement: -0.000011242, Best Loss: 0.000057147 in Epoch 506
Epoch 510
A best model at epoch 510 has been saved with training error 0.000051216.
Epoch 510, Loss: 0.000087867, Improvement: -0.000003950, Best Loss: 0.000051216 in Epoch 510
Epoch 511
Epoch 511, Loss: 0.000083669, Improvement: -0.000004199, Best Loss: 0.000051216 in Epoch 510
Epoch 512
Epoch 512, Loss: 0.000096540, Improvement: 0.000012872, Best Loss: 0.000051216 in Epoch 510
Epoch 513
Epoch 513, Loss: 0.000087561, Improvement: -0.000008979, Best Loss: 0.000051216 in Epoch 510
Epoch 514
Epoch 514, Loss: 0.000105669, Improvement: 0.000018108, Best Loss: 0.000051216 in Epoch 510
Epoch 515
Epoch 515, Loss: 0.000118742, Improvement: 0.000013073, Best Loss: 0.000051216 in Epoch 510
Epoch 516
Epoch 516, Loss: 0.000106665, Improvement: -0.000012078, Best Loss: 0.000051216 in Epoch 510
Epoch 517
Epoch 517, Loss: 0.000142139, Improvement: 0.000035474, Best Loss: 0.000051216 in Epoch 510
Epoch 518
Epoch 518, Loss: 0.000157203, Improvement: 0.000015065, Best Loss: 0.000051216 in Epoch 510
Epoch 519
Epoch 519, Loss: 0.000134722, Improvement: -0.000022481, Best Loss: 0.000051216 in Epoch 510
Epoch 520
Epoch 520, Loss: 0.000210152, Improvement: 0.000075430, Best Loss: 0.000051216 in Epoch 510
Epoch 521
Epoch 521, Loss: 0.000274952, Improvement: 0.000064799, Best Loss: 0.000051216 in Epoch 510
Epoch 522
Epoch 522, Loss: 0.000195368, Improvement: -0.000079584, Best Loss: 0.000051216 in Epoch 510
Epoch 523
Epoch 523, Loss: 0.000159927, Improvement: -0.000035441, Best Loss: 0.000051216 in Epoch 510
Epoch 524
Epoch 524, Loss: 0.000146237, Improvement: -0.000013690, Best Loss: 0.000051216 in Epoch 510
Epoch 525
Epoch 525, Loss: 0.000113490, Improvement: -0.000032746, Best Loss: 0.000051216 in Epoch 510
Epoch 526
Epoch 526, Loss: 0.000088276, Improvement: -0.000025215, Best Loss: 0.000051216 in Epoch 510
Epoch 527
Epoch 527, Loss: 0.000085478, Improvement: -0.000002798, Best Loss: 0.000051216 in Epoch 510
Epoch 528
Epoch 528, Loss: 0.000075998, Improvement: -0.000009480, Best Loss: 0.000051216 in Epoch 510
Epoch 529
Epoch 529, Loss: 0.000076184, Improvement: 0.000000186, Best Loss: 0.000051216 in Epoch 510
Epoch 530
Epoch 530, Loss: 0.000088304, Improvement: 0.000012120, Best Loss: 0.000051216 in Epoch 510
Epoch 531
Epoch 531, Loss: 0.000089282, Improvement: 0.000000978, Best Loss: 0.000051216 in Epoch 510
Epoch 532
Epoch 532, Loss: 0.000081366, Improvement: -0.000007915, Best Loss: 0.000051216 in Epoch 510
Epoch 533
A best model at epoch 533 has been saved with training error 0.000050955.
Epoch 533, Loss: 0.000076617, Improvement: -0.000004749, Best Loss: 0.000050955 in Epoch 533
Epoch 534
A best model at epoch 534 has been saved with training error 0.000042787.
Epoch 534, Loss: 0.000090725, Improvement: 0.000014108, Best Loss: 0.000042787 in Epoch 534
Epoch 535
Epoch 535, Loss: 0.000071469, Improvement: -0.000019256, Best Loss: 0.000042787 in Epoch 534
Epoch 536
Epoch 536, Loss: 0.000073956, Improvement: 0.000002487, Best Loss: 0.000042787 in Epoch 534
Epoch 537
Epoch 537, Loss: 0.000088958, Improvement: 0.000015003, Best Loss: 0.000042787 in Epoch 534
Epoch 538
Epoch 538, Loss: 0.000082192, Improvement: -0.000006766, Best Loss: 0.000042787 in Epoch 534
Epoch 539
Epoch 539, Loss: 0.000108526, Improvement: 0.000026334, Best Loss: 0.000042787 in Epoch 534
Epoch 540
Epoch 540, Loss: 0.000116778, Improvement: 0.000008251, Best Loss: 0.000042787 in Epoch 534
Epoch 541
Epoch 541, Loss: 0.000097754, Improvement: -0.000019024, Best Loss: 0.000042787 in Epoch 534
Epoch 542
Epoch 542, Loss: 0.000094170, Improvement: -0.000003584, Best Loss: 0.000042787 in Epoch 534
Epoch 543
Epoch 543, Loss: 0.000124153, Improvement: 0.000029984, Best Loss: 0.000042787 in Epoch 534
Epoch 544
Epoch 544, Loss: 0.000142115, Improvement: 0.000017962, Best Loss: 0.000042787 in Epoch 534
Epoch 545
Epoch 545, Loss: 0.000121296, Improvement: -0.000020819, Best Loss: 0.000042787 in Epoch 534
Epoch 546
Epoch 546, Loss: 0.000122030, Improvement: 0.000000734, Best Loss: 0.000042787 in Epoch 534
Epoch 547
Epoch 547, Loss: 0.000119896, Improvement: -0.000002134, Best Loss: 0.000042787 in Epoch 534
Epoch 548
Epoch 548, Loss: 0.000100619, Improvement: -0.000019277, Best Loss: 0.000042787 in Epoch 534
Epoch 549
Epoch 549, Loss: 0.000085872, Improvement: -0.000014746, Best Loss: 0.000042787 in Epoch 534
Epoch 550
Model saving checkpoint: the model trained after epoch 550 has been saved with the training errors.
Epoch 550, Loss: 0.000072043, Improvement: -0.000013829, Best Loss: 0.000042787 in Epoch 534
Epoch 551
Epoch 551, Loss: 0.000084212, Improvement: 0.000012169, Best Loss: 0.000042787 in Epoch 534
Epoch 552
Epoch 552, Loss: 0.000102837, Improvement: 0.000018625, Best Loss: 0.000042787 in Epoch 534
Epoch 553
Epoch 553, Loss: 0.000097857, Improvement: -0.000004980, Best Loss: 0.000042787 in Epoch 534
Epoch 554
Epoch 554, Loss: 0.000074712, Improvement: -0.000023145, Best Loss: 0.000042787 in Epoch 534
Epoch 555
Epoch 555, Loss: 0.000068633, Improvement: -0.000006079, Best Loss: 0.000042787 in Epoch 534
Epoch 556
Epoch 556, Loss: 0.000073986, Improvement: 0.000005353, Best Loss: 0.000042787 in Epoch 534
Epoch 557
Epoch 557, Loss: 0.000124323, Improvement: 0.000050337, Best Loss: 0.000042787 in Epoch 534
Epoch 558
Epoch 558, Loss: 0.000169070, Improvement: 0.000044747, Best Loss: 0.000042787 in Epoch 534
Epoch 559
Epoch 559, Loss: 0.000176282, Improvement: 0.000007212, Best Loss: 0.000042787 in Epoch 534
Epoch 560
Epoch 560, Loss: 0.000227382, Improvement: 0.000051099, Best Loss: 0.000042787 in Epoch 534
Epoch 561
Epoch 561, Loss: 0.000192450, Improvement: -0.000034932, Best Loss: 0.000042787 in Epoch 534
Epoch 562
Epoch 562, Loss: 0.000146311, Improvement: -0.000046139, Best Loss: 0.000042787 in Epoch 534
Epoch 563
Epoch 563, Loss: 0.000157997, Improvement: 0.000011686, Best Loss: 0.000042787 in Epoch 534
Epoch 564
Epoch 564, Loss: 0.000115757, Improvement: -0.000042240, Best Loss: 0.000042787 in Epoch 534
Epoch 565
Epoch 565, Loss: 0.000092464, Improvement: -0.000023293, Best Loss: 0.000042787 in Epoch 534
Epoch 566
Epoch 566, Loss: 0.000074835, Improvement: -0.000017629, Best Loss: 0.000042787 in Epoch 534
Epoch 567
Epoch 567, Loss: 0.000078949, Improvement: 0.000004114, Best Loss: 0.000042787 in Epoch 534
Epoch 568
Epoch 568, Loss: 0.000086972, Improvement: 0.000008024, Best Loss: 0.000042787 in Epoch 534
Epoch 569
Epoch 569, Loss: 0.000074773, Improvement: -0.000012199, Best Loss: 0.000042787 in Epoch 534
Epoch 570
A best model at epoch 570 has been saved with training error 0.000040378.
A best model at epoch 570 has been saved with training error 0.000032206.
Epoch 570, Loss: 0.000055541, Improvement: -0.000019232, Best Loss: 0.000032206 in Epoch 570
Epoch 571
Epoch 571, Loss: 0.000050680, Improvement: -0.000004861, Best Loss: 0.000032206 in Epoch 570
Epoch 572
Epoch 572, Loss: 0.000048825, Improvement: -0.000001855, Best Loss: 0.000032206 in Epoch 570
Epoch 573
Epoch 573, Loss: 0.000048679, Improvement: -0.000000146, Best Loss: 0.000032206 in Epoch 570
Epoch 574
A best model at epoch 574 has been saved with training error 0.000031811.
A best model at epoch 574 has been saved with training error 0.000030489.
A best model at epoch 574 has been saved with training error 0.000023731.
Epoch 574, Loss: 0.000047580, Improvement: -0.000001099, Best Loss: 0.000023731 in Epoch 574
Epoch 575
Epoch 575, Loss: 0.000047212, Improvement: -0.000000367, Best Loss: 0.000023731 in Epoch 574
Epoch 576
Epoch 576, Loss: 0.000047085, Improvement: -0.000000127, Best Loss: 0.000023731 in Epoch 574
Epoch 577
Epoch 577, Loss: 0.000049611, Improvement: 0.000002526, Best Loss: 0.000023731 in Epoch 574
Epoch 578
Epoch 578, Loss: 0.000048234, Improvement: -0.000001377, Best Loss: 0.000023731 in Epoch 574
Epoch 579
Epoch 579, Loss: 0.000046666, Improvement: -0.000001568, Best Loss: 0.000023731 in Epoch 574
Epoch 580
Epoch 580, Loss: 0.000046734, Improvement: 0.000000068, Best Loss: 0.000023731 in Epoch 574
Epoch 581
Epoch 581, Loss: 0.000046852, Improvement: 0.000000118, Best Loss: 0.000023731 in Epoch 574
Epoch 582
Epoch 582, Loss: 0.000044551, Improvement: -0.000002301, Best Loss: 0.000023731 in Epoch 574
Epoch 583
Epoch 583, Loss: 0.000046137, Improvement: 0.000001586, Best Loss: 0.000023731 in Epoch 574
Epoch 584
Epoch 584, Loss: 0.000044745, Improvement: -0.000001393, Best Loss: 0.000023731 in Epoch 574
Epoch 585
Epoch 585, Loss: 0.000047448, Improvement: 0.000002703, Best Loss: 0.000023731 in Epoch 574
Epoch 586
Epoch 586, Loss: 0.000047877, Improvement: 0.000000429, Best Loss: 0.000023731 in Epoch 574
Epoch 587
Epoch 587, Loss: 0.000058949, Improvement: 0.000011072, Best Loss: 0.000023731 in Epoch 574
Epoch 588
Epoch 588, Loss: 0.000082002, Improvement: 0.000023053, Best Loss: 0.000023731 in Epoch 574
Epoch 589
Epoch 589, Loss: 0.000170418, Improvement: 0.000088415, Best Loss: 0.000023731 in Epoch 574
Epoch 590
Epoch 590, Loss: 0.000198549, Improvement: 0.000028131, Best Loss: 0.000023731 in Epoch 574
Epoch 591
Epoch 591, Loss: 0.000174669, Improvement: -0.000023880, Best Loss: 0.000023731 in Epoch 574
Epoch 592
Epoch 592, Loss: 0.000126333, Improvement: -0.000048335, Best Loss: 0.000023731 in Epoch 574
Epoch 593
Epoch 593, Loss: 0.000079523, Improvement: -0.000046811, Best Loss: 0.000023731 in Epoch 574
Epoch 594
Epoch 594, Loss: 0.000056897, Improvement: -0.000022625, Best Loss: 0.000023731 in Epoch 574
Epoch 595
Epoch 595, Loss: 0.000051324, Improvement: -0.000005573, Best Loss: 0.000023731 in Epoch 574
Epoch 596
Epoch 596, Loss: 0.000044368, Improvement: -0.000006956, Best Loss: 0.000023731 in Epoch 574
Epoch 597
Epoch 597, Loss: 0.000041444, Improvement: -0.000002924, Best Loss: 0.000023731 in Epoch 574
Epoch 598
Epoch 598, Loss: 0.000041199, Improvement: -0.000000245, Best Loss: 0.000023731 in Epoch 574
Epoch 599
Epoch 599, Loss: 0.000039048, Improvement: -0.000002151, Best Loss: 0.000023731 in Epoch 574
Epoch 600
Model saving checkpoint: the model trained after epoch 600 has been saved with the training errors.
Epoch 600, Loss: 0.000038453, Improvement: -0.000000595, Best Loss: 0.000023731 in Epoch 574
Epoch 601
Epoch 601, Loss: 0.000038478, Improvement: 0.000000025, Best Loss: 0.000023731 in Epoch 574
Epoch 602
Epoch 602, Loss: 0.000037619, Improvement: -0.000000859, Best Loss: 0.000023731 in Epoch 574
Epoch 603
Epoch 603, Loss: 0.000037461, Improvement: -0.000000158, Best Loss: 0.000023731 in Epoch 574
Epoch 604
Epoch 604, Loss: 0.000037344, Improvement: -0.000000116, Best Loss: 0.000023731 in Epoch 574
Epoch 605
Epoch 605, Loss: 0.000036847, Improvement: -0.000000498, Best Loss: 0.000023731 in Epoch 574
Epoch 606
A best model at epoch 606 has been saved with training error 0.000022770.
A best model at epoch 606 has been saved with training error 0.000022473.
Epoch 606, Loss: 0.000036655, Improvement: -0.000000192, Best Loss: 0.000022473 in Epoch 606
Epoch 607
Epoch 607, Loss: 0.000036181, Improvement: -0.000000473, Best Loss: 0.000022473 in Epoch 606
Epoch 608
A best model at epoch 608 has been saved with training error 0.000020552.
Epoch 608, Loss: 0.000035384, Improvement: -0.000000797, Best Loss: 0.000020552 in Epoch 608
Epoch 609
Epoch 609, Loss: 0.000034803, Improvement: -0.000000581, Best Loss: 0.000020552 in Epoch 608
Epoch 610
Epoch 610, Loss: 0.000034735, Improvement: -0.000000068, Best Loss: 0.000020552 in Epoch 608
Epoch 611
Epoch 611, Loss: 0.000034371, Improvement: -0.000000364, Best Loss: 0.000020552 in Epoch 608
Epoch 612
Epoch 612, Loss: 0.000034270, Improvement: -0.000000100, Best Loss: 0.000020552 in Epoch 608
Epoch 613
Epoch 613, Loss: 0.000034437, Improvement: 0.000000167, Best Loss: 0.000020552 in Epoch 608
Epoch 614
Epoch 614, Loss: 0.000034217, Improvement: -0.000000220, Best Loss: 0.000020552 in Epoch 608
Epoch 615
Epoch 615, Loss: 0.000034409, Improvement: 0.000000192, Best Loss: 0.000020552 in Epoch 608
Epoch 616
Epoch 616, Loss: 0.000033542, Improvement: -0.000000866, Best Loss: 0.000020552 in Epoch 608
Epoch 617
Epoch 617, Loss: 0.000036286, Improvement: 0.000002743, Best Loss: 0.000020552 in Epoch 608
Epoch 618
Epoch 618, Loss: 0.000064864, Improvement: 0.000028578, Best Loss: 0.000020552 in Epoch 608
Epoch 619
Epoch 619, Loss: 0.000083961, Improvement: 0.000019097, Best Loss: 0.000020552 in Epoch 608
Epoch 620
Epoch 620, Loss: 0.000072655, Improvement: -0.000011306, Best Loss: 0.000020552 in Epoch 608
Epoch 621
Epoch 621, Loss: 0.000068302, Improvement: -0.000004353, Best Loss: 0.000020552 in Epoch 608
Epoch 622
Epoch 622, Loss: 0.000071752, Improvement: 0.000003450, Best Loss: 0.000020552 in Epoch 608
Epoch 623
Epoch 623, Loss: 0.000094372, Improvement: 0.000022620, Best Loss: 0.000020552 in Epoch 608
Epoch 624
Epoch 624, Loss: 0.000078887, Improvement: -0.000015485, Best Loss: 0.000020552 in Epoch 608
Epoch 625
Epoch 625, Loss: 0.000102003, Improvement: 0.000023116, Best Loss: 0.000020552 in Epoch 608
Epoch 626
Epoch 626, Loss: 0.000091132, Improvement: -0.000010871, Best Loss: 0.000020552 in Epoch 608
Epoch 627
Epoch 627, Loss: 0.000079273, Improvement: -0.000011859, Best Loss: 0.000020552 in Epoch 608
Epoch 628
Epoch 628, Loss: 0.000072258, Improvement: -0.000007015, Best Loss: 0.000020552 in Epoch 608
Epoch 629
Epoch 629, Loss: 0.000060322, Improvement: -0.000011935, Best Loss: 0.000020552 in Epoch 608
Epoch 630
Epoch 630, Loss: 0.000053405, Improvement: -0.000006917, Best Loss: 0.000020552 in Epoch 608
Epoch 631
Epoch 631, Loss: 0.000050171, Improvement: -0.000003234, Best Loss: 0.000020552 in Epoch 608
Epoch 632
Epoch 632, Loss: 0.000065107, Improvement: 0.000014936, Best Loss: 0.000020552 in Epoch 608
Epoch 633
Epoch 633, Loss: 0.000156682, Improvement: 0.000091575, Best Loss: 0.000020552 in Epoch 608
Epoch 634
Epoch 634, Loss: 0.000188494, Improvement: 0.000031811, Best Loss: 0.000020552 in Epoch 608
Epoch 635
Epoch 635, Loss: 0.000091286, Improvement: -0.000097208, Best Loss: 0.000020552 in Epoch 608
Epoch 636
Epoch 636, Loss: 0.000064938, Improvement: -0.000026348, Best Loss: 0.000020552 in Epoch 608
Epoch 637
Epoch 637, Loss: 0.000052592, Improvement: -0.000012345, Best Loss: 0.000020552 in Epoch 608
Epoch 638
Epoch 638, Loss: 0.000041299, Improvement: -0.000011293, Best Loss: 0.000020552 in Epoch 608
Epoch 639
Epoch 639, Loss: 0.000034735, Improvement: -0.000006564, Best Loss: 0.000020552 in Epoch 608
Epoch 640
Epoch 640, Loss: 0.000033029, Improvement: -0.000001706, Best Loss: 0.000020552 in Epoch 608
Epoch 641
Epoch 641, Loss: 0.000031110, Improvement: -0.000001918, Best Loss: 0.000020552 in Epoch 608
Epoch 642
A best model at epoch 642 has been saved with training error 0.000017941.
Epoch 642, Loss: 0.000030958, Improvement: -0.000000152, Best Loss: 0.000017941 in Epoch 642
Epoch 643
Epoch 643, Loss: 0.000030586, Improvement: -0.000000372, Best Loss: 0.000017941 in Epoch 642
Epoch 644
Epoch 644, Loss: 0.000030035, Improvement: -0.000000551, Best Loss: 0.000017941 in Epoch 642
Epoch 645
Epoch 645, Loss: 0.000028718, Improvement: -0.000001316, Best Loss: 0.000017941 in Epoch 642
Epoch 646
Epoch 646, Loss: 0.000027786, Improvement: -0.000000932, Best Loss: 0.000017941 in Epoch 642
Epoch 647
Epoch 647, Loss: 0.000027831, Improvement: 0.000000045, Best Loss: 0.000017941 in Epoch 642
Epoch 648
A best model at epoch 648 has been saved with training error 0.000016927.
Epoch 648, Loss: 0.000027327, Improvement: -0.000000504, Best Loss: 0.000016927 in Epoch 648
Epoch 649
Epoch 649, Loss: 0.000028360, Improvement: 0.000001033, Best Loss: 0.000016927 in Epoch 648
Epoch 650
Model saving checkpoint: the model trained after epoch 650 has been saved with the training errors.
Epoch 650, Loss: 0.000027795, Improvement: -0.000000565, Best Loss: 0.000016927 in Epoch 648
Epoch 651
Epoch 651, Loss: 0.000027728, Improvement: -0.000000067, Best Loss: 0.000016927 in Epoch 648
Epoch 652
Epoch 652, Loss: 0.000027671, Improvement: -0.000000057, Best Loss: 0.000016927 in Epoch 648
Epoch 653
Epoch 653, Loss: 0.000028113, Improvement: 0.000000442, Best Loss: 0.000016927 in Epoch 648
Epoch 654
Epoch 654, Loss: 0.000029252, Improvement: 0.000001139, Best Loss: 0.000016927 in Epoch 648
Epoch 655
A best model at epoch 655 has been saved with training error 0.000015707.
Epoch 655, Loss: 0.000028341, Improvement: -0.000000910, Best Loss: 0.000015707 in Epoch 655
Epoch 656
Epoch 656, Loss: 0.000029984, Improvement: 0.000001643, Best Loss: 0.000015707 in Epoch 655
Epoch 657
Epoch 657, Loss: 0.000047552, Improvement: 0.000017568, Best Loss: 0.000015707 in Epoch 655
Epoch 658
Epoch 658, Loss: 0.000065022, Improvement: 0.000017470, Best Loss: 0.000015707 in Epoch 655
Epoch 659
Epoch 659, Loss: 0.000045594, Improvement: -0.000019428, Best Loss: 0.000015707 in Epoch 655
Epoch 660
Epoch 660, Loss: 0.000045389, Improvement: -0.000000205, Best Loss: 0.000015707 in Epoch 655
Epoch 661
Epoch 661, Loss: 0.000049402, Improvement: 0.000004013, Best Loss: 0.000015707 in Epoch 655
Epoch 662
Epoch 662, Loss: 0.000041229, Improvement: -0.000008173, Best Loss: 0.000015707 in Epoch 655
Epoch 663
Epoch 663, Loss: 0.000039218, Improvement: -0.000002011, Best Loss: 0.000015707 in Epoch 655
Epoch 664
Epoch 664, Loss: 0.000036337, Improvement: -0.000002881, Best Loss: 0.000015707 in Epoch 655
Epoch 665
Epoch 665, Loss: 0.000036378, Improvement: 0.000000041, Best Loss: 0.000015707 in Epoch 655
Epoch 666
Epoch 666, Loss: 0.000038165, Improvement: 0.000001787, Best Loss: 0.000015707 in Epoch 655
Epoch 667
Epoch 667, Loss: 0.000061666, Improvement: 0.000023501, Best Loss: 0.000015707 in Epoch 655
Epoch 668
Epoch 668, Loss: 0.000106302, Improvement: 0.000044636, Best Loss: 0.000015707 in Epoch 655
Epoch 669
Epoch 669, Loss: 0.000129930, Improvement: 0.000023629, Best Loss: 0.000015707 in Epoch 655
Epoch 670
Epoch 670, Loss: 0.000085613, Improvement: -0.000044317, Best Loss: 0.000015707 in Epoch 655
Epoch 671
Epoch 671, Loss: 0.000057593, Improvement: -0.000028020, Best Loss: 0.000015707 in Epoch 655
Epoch 672
Epoch 672, Loss: 0.000060188, Improvement: 0.000002595, Best Loss: 0.000015707 in Epoch 655
Epoch 673
Epoch 673, Loss: 0.000078433, Improvement: 0.000018245, Best Loss: 0.000015707 in Epoch 655
Epoch 674
Epoch 674, Loss: 0.000062846, Improvement: -0.000015587, Best Loss: 0.000015707 in Epoch 655
Epoch 675
Epoch 675, Loss: 0.000048623, Improvement: -0.000014224, Best Loss: 0.000015707 in Epoch 655
Epoch 676
Epoch 676, Loss: 0.000042212, Improvement: -0.000006410, Best Loss: 0.000015707 in Epoch 655
Epoch 677
Epoch 677, Loss: 0.000048461, Improvement: 0.000006249, Best Loss: 0.000015707 in Epoch 655
Epoch 678
Epoch 678, Loss: 0.000044110, Improvement: -0.000004351, Best Loss: 0.000015707 in Epoch 655
Epoch 679
Epoch 679, Loss: 0.000040280, Improvement: -0.000003830, Best Loss: 0.000015707 in Epoch 655
Epoch 680
Epoch 680, Loss: 0.000046876, Improvement: 0.000006596, Best Loss: 0.000015707 in Epoch 655
Epoch 681
Epoch 681, Loss: 0.000040479, Improvement: -0.000006397, Best Loss: 0.000015707 in Epoch 655
Epoch 682
Epoch 682, Loss: 0.000040059, Improvement: -0.000000420, Best Loss: 0.000015707 in Epoch 655
Epoch 683
Epoch 683, Loss: 0.000038925, Improvement: -0.000001134, Best Loss: 0.000015707 in Epoch 655
Epoch 684
Epoch 684, Loss: 0.000036565, Improvement: -0.000002360, Best Loss: 0.000015707 in Epoch 655
Epoch 685
Epoch 685, Loss: 0.000037581, Improvement: 0.000001016, Best Loss: 0.000015707 in Epoch 655
Epoch 686
Epoch 686, Loss: 0.000044901, Improvement: 0.000007320, Best Loss: 0.000015707 in Epoch 655
Epoch 687
Epoch 687, Loss: 0.000066111, Improvement: 0.000021210, Best Loss: 0.000015707 in Epoch 655
Epoch 688
Epoch 688, Loss: 0.000075702, Improvement: 0.000009591, Best Loss: 0.000015707 in Epoch 655
Epoch 689
Epoch 689, Loss: 0.000092658, Improvement: 0.000016956, Best Loss: 0.000015707 in Epoch 655
Epoch 690
Epoch 690, Loss: 0.000100083, Improvement: 0.000007425, Best Loss: 0.000015707 in Epoch 655
Epoch 691
Epoch 691, Loss: 0.000070443, Improvement: -0.000029640, Best Loss: 0.000015707 in Epoch 655
Epoch 692
Epoch 692, Loss: 0.000092652, Improvement: 0.000022209, Best Loss: 0.000015707 in Epoch 655
Epoch 693
Epoch 693, Loss: 0.000078714, Improvement: -0.000013938, Best Loss: 0.000015707 in Epoch 655
Epoch 694
Epoch 694, Loss: 0.000053132, Improvement: -0.000025582, Best Loss: 0.000015707 in Epoch 655
Epoch 695
Epoch 695, Loss: 0.000032889, Improvement: -0.000020243, Best Loss: 0.000015707 in Epoch 655
Epoch 696
Epoch 696, Loss: 0.000031755, Improvement: -0.000001134, Best Loss: 0.000015707 in Epoch 655
Epoch 697
Epoch 697, Loss: 0.000028649, Improvement: -0.000003106, Best Loss: 0.000015707 in Epoch 655
Epoch 698
Epoch 698, Loss: 0.000024162, Improvement: -0.000004487, Best Loss: 0.000015707 in Epoch 655
Epoch 699
Epoch 699, Loss: 0.000024328, Improvement: 0.000000166, Best Loss: 0.000015707 in Epoch 655
Epoch 700
A best model at epoch 700 has been saved with training error 0.000015443.
Model saving checkpoint: the model trained after epoch 700 has been saved with the training errors.
Epoch 700, Loss: 0.000022810, Improvement: -0.000001518, Best Loss: 0.000015443 in Epoch 700
Epoch 701
Epoch 701, Loss: 0.000023972, Improvement: 0.000001162, Best Loss: 0.000015443 in Epoch 700
Epoch 702
Epoch 702, Loss: 0.000023737, Improvement: -0.000000236, Best Loss: 0.000015443 in Epoch 700
Epoch 703
Epoch 703, Loss: 0.000023205, Improvement: -0.000000531, Best Loss: 0.000015443 in Epoch 700
Epoch 704
Epoch 704, Loss: 0.000030037, Improvement: 0.000006832, Best Loss: 0.000015443 in Epoch 700
Epoch 705
Epoch 705, Loss: 0.000029073, Improvement: -0.000000964, Best Loss: 0.000015443 in Epoch 700
Epoch 706
Epoch 706, Loss: 0.000040621, Improvement: 0.000011548, Best Loss: 0.000015443 in Epoch 700
Epoch 707
Epoch 707, Loss: 0.000041698, Improvement: 0.000001077, Best Loss: 0.000015443 in Epoch 700
Epoch 708
Epoch 708, Loss: 0.000039126, Improvement: -0.000002572, Best Loss: 0.000015443 in Epoch 700
Epoch 709
Epoch 709, Loss: 0.000049056, Improvement: 0.000009929, Best Loss: 0.000015443 in Epoch 700
Epoch 710
Epoch 710, Loss: 0.000040721, Improvement: -0.000008334, Best Loss: 0.000015443 in Epoch 700
Epoch 711
Epoch 711, Loss: 0.000047885, Improvement: 0.000007163, Best Loss: 0.000015443 in Epoch 700
Epoch 712
Epoch 712, Loss: 0.000059428, Improvement: 0.000011543, Best Loss: 0.000015443 in Epoch 700
Epoch 713
Epoch 713, Loss: 0.000066817, Improvement: 0.000007389, Best Loss: 0.000015443 in Epoch 700
Epoch 714
Epoch 714, Loss: 0.000051616, Improvement: -0.000015202, Best Loss: 0.000015443 in Epoch 700
Epoch 715
Epoch 715, Loss: 0.000082217, Improvement: 0.000030601, Best Loss: 0.000015443 in Epoch 700
Epoch 716
Epoch 716, Loss: 0.000072720, Improvement: -0.000009497, Best Loss: 0.000015443 in Epoch 700
Epoch 717
Epoch 717, Loss: 0.000048743, Improvement: -0.000023977, Best Loss: 0.000015443 in Epoch 700
Epoch 718
Epoch 718, Loss: 0.000055661, Improvement: 0.000006918, Best Loss: 0.000015443 in Epoch 700
Epoch 719
Epoch 719, Loss: 0.000057720, Improvement: 0.000002059, Best Loss: 0.000015443 in Epoch 700
Epoch 720
Epoch 720, Loss: 0.000079127, Improvement: 0.000021407, Best Loss: 0.000015443 in Epoch 700
Epoch 721
Epoch 721, Loss: 0.000075120, Improvement: -0.000004007, Best Loss: 0.000015443 in Epoch 700
Epoch 722
Epoch 722, Loss: 0.000066048, Improvement: -0.000009072, Best Loss: 0.000015443 in Epoch 700
Epoch 723
Epoch 723, Loss: 0.000043437, Improvement: -0.000022612, Best Loss: 0.000015443 in Epoch 700
Epoch 724
Epoch 724, Loss: 0.000047195, Improvement: 0.000003758, Best Loss: 0.000015443 in Epoch 700
Epoch 725
Epoch 725, Loss: 0.000052721, Improvement: 0.000005526, Best Loss: 0.000015443 in Epoch 700
Epoch 726
Epoch 726, Loss: 0.000048708, Improvement: -0.000004013, Best Loss: 0.000015443 in Epoch 700
Epoch 727
Epoch 727, Loss: 0.000058089, Improvement: 0.000009380, Best Loss: 0.000015443 in Epoch 700
Epoch 728
Epoch 728, Loss: 0.000078421, Improvement: 0.000020333, Best Loss: 0.000015443 in Epoch 700
Epoch 729
Epoch 729, Loss: 0.000073509, Improvement: -0.000004912, Best Loss: 0.000015443 in Epoch 700
Epoch 730
Epoch 730, Loss: 0.000038467, Improvement: -0.000035043, Best Loss: 0.000015443 in Epoch 700
Epoch 731
Epoch 731, Loss: 0.000027243, Improvement: -0.000011224, Best Loss: 0.000015443 in Epoch 700
Epoch 732
Epoch 732, Loss: 0.000026165, Improvement: -0.000001078, Best Loss: 0.000015443 in Epoch 700
Epoch 733
Epoch 733, Loss: 0.000031787, Improvement: 0.000005622, Best Loss: 0.000015443 in Epoch 700
Epoch 734
Epoch 734, Loss: 0.000027181, Improvement: -0.000004606, Best Loss: 0.000015443 in Epoch 700
Epoch 735
A best model at epoch 735 has been saved with training error 0.000015151.
Epoch 735, Loss: 0.000027383, Improvement: 0.000000201, Best Loss: 0.000015151 in Epoch 735
Epoch 736
Epoch 736, Loss: 0.000028975, Improvement: 0.000001592, Best Loss: 0.000015151 in Epoch 735
Epoch 737
Epoch 737, Loss: 0.000034519, Improvement: 0.000005544, Best Loss: 0.000015151 in Epoch 735
Epoch 738
Epoch 738, Loss: 0.000055937, Improvement: 0.000021419, Best Loss: 0.000015151 in Epoch 735
Epoch 739
Epoch 739, Loss: 0.000049462, Improvement: -0.000006475, Best Loss: 0.000015151 in Epoch 735
Epoch 740
Epoch 740, Loss: 0.000043655, Improvement: -0.000005807, Best Loss: 0.000015151 in Epoch 735
Epoch 741
Epoch 741, Loss: 0.000043630, Improvement: -0.000000025, Best Loss: 0.000015151 in Epoch 735
Epoch 742
Epoch 742, Loss: 0.000041275, Improvement: -0.000002354, Best Loss: 0.000015151 in Epoch 735
Epoch 743
Epoch 743, Loss: 0.000033404, Improvement: -0.000007871, Best Loss: 0.000015151 in Epoch 735
Epoch 744
Epoch 744, Loss: 0.000036150, Improvement: 0.000002746, Best Loss: 0.000015151 in Epoch 735
Epoch 745
Epoch 745, Loss: 0.000039039, Improvement: 0.000002890, Best Loss: 0.000015151 in Epoch 735
Epoch 746
Epoch 746, Loss: 0.000050803, Improvement: 0.000011764, Best Loss: 0.000015151 in Epoch 735
Epoch 747
Epoch 747, Loss: 0.000055723, Improvement: 0.000004920, Best Loss: 0.000015151 in Epoch 735
Epoch 748
Epoch 748, Loss: 0.000047710, Improvement: -0.000008013, Best Loss: 0.000015151 in Epoch 735
Epoch 749
Epoch 749, Loss: 0.000062453, Improvement: 0.000014743, Best Loss: 0.000015151 in Epoch 735
Epoch 750
Model saving checkpoint: the model trained after epoch 750 has been saved with the training errors.
Epoch 750, Loss: 0.000061463, Improvement: -0.000000990, Best Loss: 0.000015151 in Epoch 735
Epoch 751
Epoch 751, Loss: 0.000075140, Improvement: 0.000013677, Best Loss: 0.000015151 in Epoch 735
Epoch 752
Epoch 752, Loss: 0.000064043, Improvement: -0.000011096, Best Loss: 0.000015151 in Epoch 735
Epoch 753
Epoch 753, Loss: 0.000052747, Improvement: -0.000011297, Best Loss: 0.000015151 in Epoch 735
Epoch 754
Epoch 754, Loss: 0.000044450, Improvement: -0.000008296, Best Loss: 0.000015151 in Epoch 735
Epoch 755
Epoch 755, Loss: 0.000028508, Improvement: -0.000015942, Best Loss: 0.000015151 in Epoch 735
Epoch 756
Epoch 756, Loss: 0.000022675, Improvement: -0.000005833, Best Loss: 0.000015151 in Epoch 735
Epoch 757
Epoch 757, Loss: 0.000031693, Improvement: 0.000009018, Best Loss: 0.000015151 in Epoch 735
Epoch 758
Epoch 758, Loss: 0.000025357, Improvement: -0.000006336, Best Loss: 0.000015151 in Epoch 735
Epoch 759
Epoch 759, Loss: 0.000027778, Improvement: 0.000002420, Best Loss: 0.000015151 in Epoch 735
Epoch 760
Epoch 760, Loss: 0.000031306, Improvement: 0.000003528, Best Loss: 0.000015151 in Epoch 735
Epoch 761
Epoch 761, Loss: 0.000026328, Improvement: -0.000004978, Best Loss: 0.000015151 in Epoch 735
Epoch 762
Epoch 762, Loss: 0.000030055, Improvement: 0.000003728, Best Loss: 0.000015151 in Epoch 735
Epoch 763
Epoch 763, Loss: 0.000023979, Improvement: -0.000006076, Best Loss: 0.000015151 in Epoch 735
Epoch 764
A best model at epoch 764 has been saved with training error 0.000014737.
Epoch 764, Loss: 0.000020816, Improvement: -0.000003164, Best Loss: 0.000014737 in Epoch 764
Epoch 765
A best model at epoch 765 has been saved with training error 0.000013536.
Epoch 765, Loss: 0.000020188, Improvement: -0.000000628, Best Loss: 0.000013536 in Epoch 765
Epoch 766
Epoch 766, Loss: 0.000019882, Improvement: -0.000000306, Best Loss: 0.000013536 in Epoch 765
Epoch 767
Epoch 767, Loss: 0.000020101, Improvement: 0.000000219, Best Loss: 0.000013536 in Epoch 765
Epoch 768
Epoch 768, Loss: 0.000018347, Improvement: -0.000001754, Best Loss: 0.000013536 in Epoch 765
Epoch 769
Epoch 769, Loss: 0.000027876, Improvement: 0.000009529, Best Loss: 0.000013536 in Epoch 765
Epoch 770
Epoch 770, Loss: 0.000045259, Improvement: 0.000017383, Best Loss: 0.000013536 in Epoch 765
Epoch 771
Epoch 771, Loss: 0.000070270, Improvement: 0.000025012, Best Loss: 0.000013536 in Epoch 765
Epoch 772
Epoch 772, Loss: 0.000036753, Improvement: -0.000033517, Best Loss: 0.000013536 in Epoch 765
Epoch 773
Epoch 773, Loss: 0.000025953, Improvement: -0.000010801, Best Loss: 0.000013536 in Epoch 765
Epoch 774
Epoch 774, Loss: 0.000027227, Improvement: 0.000001274, Best Loss: 0.000013536 in Epoch 765
Epoch 775
Epoch 775, Loss: 0.000023545, Improvement: -0.000003682, Best Loss: 0.000013536 in Epoch 765
Epoch 776
Epoch 776, Loss: 0.000021607, Improvement: -0.000001938, Best Loss: 0.000013536 in Epoch 765
Epoch 777
A best model at epoch 777 has been saved with training error 0.000010267.
Epoch 777, Loss: 0.000022178, Improvement: 0.000000571, Best Loss: 0.000010267 in Epoch 777
Epoch 778
Epoch 778, Loss: 0.000028305, Improvement: 0.000006127, Best Loss: 0.000010267 in Epoch 777
Epoch 779
Epoch 779, Loss: 0.000028353, Improvement: 0.000000048, Best Loss: 0.000010267 in Epoch 777
Epoch 780
Epoch 780, Loss: 0.000031415, Improvement: 0.000003062, Best Loss: 0.000010267 in Epoch 777
Epoch 781
Epoch 781, Loss: 0.000019213, Improvement: -0.000012201, Best Loss: 0.000010267 in Epoch 777
Epoch 782
Epoch 782, Loss: 0.000017055, Improvement: -0.000002158, Best Loss: 0.000010267 in Epoch 777
Epoch 783
Epoch 783, Loss: 0.000015153, Improvement: -0.000001902, Best Loss: 0.000010267 in Epoch 777
Epoch 784
Epoch 784, Loss: 0.000018595, Improvement: 0.000003442, Best Loss: 0.000010267 in Epoch 777
Epoch 785
Epoch 785, Loss: 0.000022535, Improvement: 0.000003940, Best Loss: 0.000010267 in Epoch 777
Epoch 786
Epoch 786, Loss: 0.000026641, Improvement: 0.000004106, Best Loss: 0.000010267 in Epoch 777
Epoch 787
Epoch 787, Loss: 0.000019909, Improvement: -0.000006732, Best Loss: 0.000010267 in Epoch 777
Epoch 788
Epoch 788, Loss: 0.000031085, Improvement: 0.000011176, Best Loss: 0.000010267 in Epoch 777
Epoch 789
Epoch 789, Loss: 0.000042159, Improvement: 0.000011074, Best Loss: 0.000010267 in Epoch 777
Epoch 790
Epoch 790, Loss: 0.000048388, Improvement: 0.000006229, Best Loss: 0.000010267 in Epoch 777
Epoch 791
Epoch 791, Loss: 0.000051857, Improvement: 0.000003469, Best Loss: 0.000010267 in Epoch 777
Epoch 792
Epoch 792, Loss: 0.000070922, Improvement: 0.000019065, Best Loss: 0.000010267 in Epoch 777
Epoch 793
Epoch 793, Loss: 0.000098145, Improvement: 0.000027223, Best Loss: 0.000010267 in Epoch 777
Epoch 794
Epoch 794, Loss: 0.000070643, Improvement: -0.000027502, Best Loss: 0.000010267 in Epoch 777
Epoch 795
Epoch 795, Loss: 0.000085446, Improvement: 0.000014803, Best Loss: 0.000010267 in Epoch 777
Epoch 796
Epoch 796, Loss: 0.000059092, Improvement: -0.000026353, Best Loss: 0.000010267 in Epoch 777
Epoch 797
Epoch 797, Loss: 0.000038024, Improvement: -0.000021068, Best Loss: 0.000010267 in Epoch 777
Epoch 798
Epoch 798, Loss: 0.000023870, Improvement: -0.000014154, Best Loss: 0.000010267 in Epoch 777
Epoch 799
Epoch 799, Loss: 0.000022526, Improvement: -0.000001345, Best Loss: 0.000010267 in Epoch 777
Epoch 800
A best model at epoch 800 has been saved with training error 0.000009832.
Model saving checkpoint: the model trained after epoch 800 has been saved with the training errors.
Epoch 800, Loss: 0.000015955, Improvement: -0.000006571, Best Loss: 0.000009832 in Epoch 800
Epoch 801
Epoch 801, Loss: 0.000013289, Improvement: -0.000002666, Best Loss: 0.000009832 in Epoch 800
Epoch 802
A best model at epoch 802 has been saved with training error 0.000008564.
Epoch 802, Loss: 0.000012695, Improvement: -0.000000594, Best Loss: 0.000008564 in Epoch 802
Epoch 803
Epoch 803, Loss: 0.000012639, Improvement: -0.000000057, Best Loss: 0.000008564 in Epoch 802
Epoch 804
Epoch 804, Loss: 0.000012910, Improvement: 0.000000271, Best Loss: 0.000008564 in Epoch 802
Epoch 805
Epoch 805, Loss: 0.000012425, Improvement: -0.000000485, Best Loss: 0.000008564 in Epoch 802
Epoch 806
A best model at epoch 806 has been saved with training error 0.000008480.
A best model at epoch 806 has been saved with training error 0.000008055.
Epoch 806, Loss: 0.000012202, Improvement: -0.000000222, Best Loss: 0.000008055 in Epoch 806
Epoch 807
Epoch 807, Loss: 0.000011465, Improvement: -0.000000738, Best Loss: 0.000008055 in Epoch 806
Epoch 808
Epoch 808, Loss: 0.000011402, Improvement: -0.000000063, Best Loss: 0.000008055 in Epoch 806
Epoch 809
Epoch 809, Loss: 0.000011448, Improvement: 0.000000046, Best Loss: 0.000008055 in Epoch 806
Epoch 810
Epoch 810, Loss: 0.000012146, Improvement: 0.000000698, Best Loss: 0.000008055 in Epoch 806
Epoch 811
A best model at epoch 811 has been saved with training error 0.000007740.
Epoch 811, Loss: 0.000011536, Improvement: -0.000000610, Best Loss: 0.000007740 in Epoch 811
Epoch 812
Epoch 812, Loss: 0.000011203, Improvement: -0.000000333, Best Loss: 0.000007740 in Epoch 811
Epoch 813
Epoch 813, Loss: 0.000011414, Improvement: 0.000000210, Best Loss: 0.000007740 in Epoch 811
Epoch 814
Epoch 814, Loss: 0.000011585, Improvement: 0.000000171, Best Loss: 0.000007740 in Epoch 811
Epoch 815
Epoch 815, Loss: 0.000012224, Improvement: 0.000000639, Best Loss: 0.000007740 in Epoch 811
Epoch 816
Epoch 816, Loss: 0.000014330, Improvement: 0.000002106, Best Loss: 0.000007740 in Epoch 811
Epoch 817
Epoch 817, Loss: 0.000013339, Improvement: -0.000000991, Best Loss: 0.000007740 in Epoch 811
Epoch 818
Epoch 818, Loss: 0.000013368, Improvement: 0.000000029, Best Loss: 0.000007740 in Epoch 811
Epoch 819
Epoch 819, Loss: 0.000013198, Improvement: -0.000000170, Best Loss: 0.000007740 in Epoch 811
Epoch 820
Epoch 820, Loss: 0.000017719, Improvement: 0.000004521, Best Loss: 0.000007740 in Epoch 811
Epoch 821
Epoch 821, Loss: 0.000019221, Improvement: 0.000001502, Best Loss: 0.000007740 in Epoch 811
Epoch 822
Epoch 822, Loss: 0.000023963, Improvement: 0.000004742, Best Loss: 0.000007740 in Epoch 811
Epoch 823
Epoch 823, Loss: 0.000028171, Improvement: 0.000004208, Best Loss: 0.000007740 in Epoch 811
Epoch 824
Epoch 824, Loss: 0.000047084, Improvement: 0.000018912, Best Loss: 0.000007740 in Epoch 811
Epoch 825
Epoch 825, Loss: 0.000068218, Improvement: 0.000021134, Best Loss: 0.000007740 in Epoch 811
Epoch 826
Epoch 826, Loss: 0.000053083, Improvement: -0.000015135, Best Loss: 0.000007740 in Epoch 811
Epoch 827
Epoch 827, Loss: 0.000037950, Improvement: -0.000015133, Best Loss: 0.000007740 in Epoch 811
Epoch 828
Epoch 828, Loss: 0.000027494, Improvement: -0.000010456, Best Loss: 0.000007740 in Epoch 811
Epoch 829
Epoch 829, Loss: 0.000032007, Improvement: 0.000004513, Best Loss: 0.000007740 in Epoch 811
Epoch 830
Epoch 830, Loss: 0.000043096, Improvement: 0.000011089, Best Loss: 0.000007740 in Epoch 811
Epoch 831
Epoch 831, Loss: 0.000030394, Improvement: -0.000012702, Best Loss: 0.000007740 in Epoch 811
Epoch 832
Epoch 832, Loss: 0.000031016, Improvement: 0.000000623, Best Loss: 0.000007740 in Epoch 811
Epoch 833
Epoch 833, Loss: 0.000033703, Improvement: 0.000002687, Best Loss: 0.000007740 in Epoch 811
Epoch 834
Epoch 834, Loss: 0.000039002, Improvement: 0.000005299, Best Loss: 0.000007740 in Epoch 811
Epoch 835
Epoch 835, Loss: 0.000025800, Improvement: -0.000013202, Best Loss: 0.000007740 in Epoch 811
Epoch 836
Epoch 836, Loss: 0.000018236, Improvement: -0.000007563, Best Loss: 0.000007740 in Epoch 811
Epoch 837
Epoch 837, Loss: 0.000019729, Improvement: 0.000001493, Best Loss: 0.000007740 in Epoch 811
Epoch 838
Epoch 838, Loss: 0.000023851, Improvement: 0.000004121, Best Loss: 0.000007740 in Epoch 811
Epoch 839
Epoch 839, Loss: 0.000028197, Improvement: 0.000004346, Best Loss: 0.000007740 in Epoch 811
Epoch 840
