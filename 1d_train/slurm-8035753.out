The dimension of y_tensor is torch.Size([5000, 2]).
The dimension of y_expanded is torch.Size([500, 5000, 2]) after expanding.
The dimensions of the initial conditions are: (500, 50)
The dimensions of the solutions are: (500, 100, 50)
The dimension of u_tensor is torch.Size([500, 50]).
The dimension of u_expanded is torch.Size([500, 5000, 50]) after expanding.
The loaded solution dataset has dimension (500, 100, 50),
	 while the arranged linearized dataset has dimension (500, 5000).
The dimension of s_tensor is torch.Size([500, 5000]).
The dimension of s_expanded is torch.Size([500, 5000, 1]) after expanding.
Epoch 1
A best model at epoch 1 has been saved with training error 0.060961723.
A best model at epoch 1 has been saved with training error 0.036594443.
Epoch 1, Loss: 0.260718262, Improvement: 0.260718262, Best Loss: 0.036594443 in Epoch 1
Epoch 2
A best model at epoch 2 has been saved with training error 0.029512985.
A best model at epoch 2 has been saved with training error 0.022966027.
Epoch 2, Loss: 0.084224300, Improvement: -0.176493962, Best Loss: 0.022966027 in Epoch 2
Epoch 3
A best model at epoch 3 has been saved with training error 0.017262381.
A best model at epoch 3 has been saved with training error 0.015132034.
A best model at epoch 3 has been saved with training error 0.013202629.
A best model at epoch 3 has been saved with training error 0.011924230.
Epoch 3, Loss: 0.026022903, Improvement: -0.058201397, Best Loss: 0.011924230 in Epoch 3
Epoch 4
A best model at epoch 4 has been saved with training error 0.011799620.
A best model at epoch 4 has been saved with training error 0.010139774.
A best model at epoch 4 has been saved with training error 0.008244103.
Epoch 4, Loss: 0.016040648, Improvement: -0.009982255, Best Loss: 0.008244103 in Epoch 4
Epoch 5
Epoch 5, Loss: 0.013672038, Improvement: -0.002368610, Best Loss: 0.008244103 in Epoch 4
Epoch 6
A best model at epoch 6 has been saved with training error 0.007593758.
A best model at epoch 6 has been saved with training error 0.007045695.
Epoch 6, Loss: 0.012703300, Improvement: -0.000968738, Best Loss: 0.007045695 in Epoch 6
Epoch 7
Epoch 7, Loss: 0.012240664, Improvement: -0.000462636, Best Loss: 0.007045695 in Epoch 6
Epoch 8
Epoch 8, Loss: 0.011890399, Improvement: -0.000350265, Best Loss: 0.007045695 in Epoch 6
Epoch 9
Epoch 9, Loss: 0.011662555, Improvement: -0.000227844, Best Loss: 0.007045695 in Epoch 6
Epoch 10
Epoch 10, Loss: 0.011507070, Improvement: -0.000155485, Best Loss: 0.007045695 in Epoch 6
Epoch 11
Epoch 11, Loss: 0.011367056, Improvement: -0.000140014, Best Loss: 0.007045695 in Epoch 6
Epoch 12
A best model at epoch 12 has been saved with training error 0.006712854.
A best model at epoch 12 has been saved with training error 0.005474281.
Epoch 12, Loss: 0.011239976, Improvement: -0.000127080, Best Loss: 0.005474281 in Epoch 12
Epoch 13
Epoch 13, Loss: 0.011145636, Improvement: -0.000094340, Best Loss: 0.005474281 in Epoch 12
Epoch 14
Epoch 14, Loss: 0.011057252, Improvement: -0.000088384, Best Loss: 0.005474281 in Epoch 12
Epoch 15
Epoch 15, Loss: 0.010973509, Improvement: -0.000083743, Best Loss: 0.005474281 in Epoch 12
Epoch 16
Epoch 16, Loss: 0.010903425, Improvement: -0.000070084, Best Loss: 0.005474281 in Epoch 12
Epoch 17
Epoch 17, Loss: 0.010812795, Improvement: -0.000090630, Best Loss: 0.005474281 in Epoch 12
Epoch 18
Epoch 18, Loss: 0.010745658, Improvement: -0.000067137, Best Loss: 0.005474281 in Epoch 12
Epoch 19
Epoch 19, Loss: 0.010674289, Improvement: -0.000071369, Best Loss: 0.005474281 in Epoch 12
Epoch 20
Epoch 20, Loss: 0.010602534, Improvement: -0.000071755, Best Loss: 0.005474281 in Epoch 12
Epoch 21
A best model at epoch 21 has been saved with training error 0.005309480.
Epoch 21, Loss: 0.010540853, Improvement: -0.000061681, Best Loss: 0.005309480 in Epoch 21
Epoch 22
Epoch 22, Loss: 0.010466330, Improvement: -0.000074524, Best Loss: 0.005309480 in Epoch 21
Epoch 23
A best model at epoch 23 has been saved with training error 0.004094624.
Epoch 23, Loss: 0.010400518, Improvement: -0.000065811, Best Loss: 0.004094624 in Epoch 23
Epoch 24
Epoch 24, Loss: 0.010335338, Improvement: -0.000065180, Best Loss: 0.004094624 in Epoch 23
Epoch 25
Epoch 25, Loss: 0.010261686, Improvement: -0.000073653, Best Loss: 0.004094624 in Epoch 23
Epoch 26
Epoch 26, Loss: 0.010194860, Improvement: -0.000066826, Best Loss: 0.004094624 in Epoch 23
Epoch 27
Epoch 27, Loss: 0.010128985, Improvement: -0.000065875, Best Loss: 0.004094624 in Epoch 23
Epoch 28
Epoch 28, Loss: 0.010060013, Improvement: -0.000068972, Best Loss: 0.004094624 in Epoch 23
Epoch 29
Epoch 29, Loss: 0.009986726, Improvement: -0.000073286, Best Loss: 0.004094624 in Epoch 23
Epoch 30
Epoch 30, Loss: 0.009906498, Improvement: -0.000080229, Best Loss: 0.004094624 in Epoch 23
Epoch 31
Epoch 31, Loss: 0.009838061, Improvement: -0.000068436, Best Loss: 0.004094624 in Epoch 23
Epoch 32
Epoch 32, Loss: 0.009777438, Improvement: -0.000060624, Best Loss: 0.004094624 in Epoch 23
Epoch 33
A best model at epoch 33 has been saved with training error 0.003980352.
Epoch 33, Loss: 0.009684797, Improvement: -0.000092641, Best Loss: 0.003980352 in Epoch 33
Epoch 34
Epoch 34, Loss: 0.009606398, Improvement: -0.000078399, Best Loss: 0.003980352 in Epoch 33
Epoch 35
Epoch 35, Loss: 0.009530431, Improvement: -0.000075967, Best Loss: 0.003980352 in Epoch 33
Epoch 36
Epoch 36, Loss: 0.009455301, Improvement: -0.000075130, Best Loss: 0.003980352 in Epoch 33
Epoch 37
Epoch 37, Loss: 0.009372712, Improvement: -0.000082589, Best Loss: 0.003980352 in Epoch 33
Epoch 38
Epoch 38, Loss: 0.009313173, Improvement: -0.000059539, Best Loss: 0.003980352 in Epoch 33
Epoch 39
Epoch 39, Loss: 0.009218239, Improvement: -0.000094935, Best Loss: 0.003980352 in Epoch 33
Epoch 40
Epoch 40, Loss: 0.009127679, Improvement: -0.000090560, Best Loss: 0.003980352 in Epoch 33
Epoch 41
Epoch 41, Loss: 0.009033520, Improvement: -0.000094159, Best Loss: 0.003980352 in Epoch 33
Epoch 42
Epoch 42, Loss: 0.008946161, Improvement: -0.000087359, Best Loss: 0.003980352 in Epoch 33
Epoch 43
Epoch 43, Loss: 0.008856821, Improvement: -0.000089340, Best Loss: 0.003980352 in Epoch 33
Epoch 44
Epoch 44, Loss: 0.008764650, Improvement: -0.000092172, Best Loss: 0.003980352 in Epoch 33
Epoch 45
Epoch 45, Loss: 0.008667262, Improvement: -0.000097388, Best Loss: 0.003980352 in Epoch 33
Epoch 46
Epoch 46, Loss: 0.008603538, Improvement: -0.000063724, Best Loss: 0.003980352 in Epoch 33
Epoch 47
Epoch 47, Loss: 0.008486072, Improvement: -0.000117466, Best Loss: 0.003980352 in Epoch 33
Epoch 48
Epoch 48, Loss: 0.008388671, Improvement: -0.000097400, Best Loss: 0.003980352 in Epoch 33
Epoch 49
Epoch 49, Loss: 0.008292082, Improvement: -0.000096589, Best Loss: 0.003980352 in Epoch 33
Epoch 50
Model saving checkpoint: the model trained after epoch 50 has been saved with the training errors.
Epoch 50, Loss: 0.008183539, Improvement: -0.000108543, Best Loss: 0.003980352 in Epoch 33
Epoch 51
Epoch 51, Loss: 0.008083113, Improvement: -0.000100426, Best Loss: 0.003980352 in Epoch 33
Epoch 52
Epoch 52, Loss: 0.007987167, Improvement: -0.000095946, Best Loss: 0.003980352 in Epoch 33
Epoch 53
Epoch 53, Loss: 0.007887310, Improvement: -0.000099857, Best Loss: 0.003980352 in Epoch 33
Epoch 54
Epoch 54, Loss: 0.007791540, Improvement: -0.000095770, Best Loss: 0.003980352 in Epoch 33
Epoch 55
Epoch 55, Loss: 0.007708517, Improvement: -0.000083023, Best Loss: 0.003980352 in Epoch 33
Epoch 56
Epoch 56, Loss: 0.007617309, Improvement: -0.000091208, Best Loss: 0.003980352 in Epoch 33
Epoch 57
Epoch 57, Loss: 0.007540724, Improvement: -0.000076585, Best Loss: 0.003980352 in Epoch 33
Epoch 58
A best model at epoch 58 has been saved with training error 0.003830474.
Epoch 58, Loss: 0.007492501, Improvement: -0.000048223, Best Loss: 0.003830474 in Epoch 58
Epoch 59
Epoch 59, Loss: 0.007507080, Improvement: 0.000014579, Best Loss: 0.003830474 in Epoch 58
Epoch 60
Epoch 60, Loss: 0.007379914, Improvement: -0.000127166, Best Loss: 0.003830474 in Epoch 58
Epoch 61
Epoch 61, Loss: 0.007336964, Improvement: -0.000042950, Best Loss: 0.003830474 in Epoch 58
Epoch 62
Epoch 62, Loss: 0.007421004, Improvement: 0.000084040, Best Loss: 0.003830474 in Epoch 58
Epoch 63
Epoch 63, Loss: 0.007414748, Improvement: -0.000006256, Best Loss: 0.003830474 in Epoch 58
Epoch 64
Epoch 64, Loss: 0.007487583, Improvement: 0.000072835, Best Loss: 0.003830474 in Epoch 58
Epoch 65
Epoch 65, Loss: 0.007829734, Improvement: 0.000342152, Best Loss: 0.003830474 in Epoch 58
Epoch 66
Epoch 66, Loss: 0.009122784, Improvement: 0.001293050, Best Loss: 0.003830474 in Epoch 58
Epoch 67
Epoch 67, Loss: 0.009869920, Improvement: 0.000747135, Best Loss: 0.003830474 in Epoch 58
Epoch 68
Epoch 68, Loss: 0.011592901, Improvement: 0.001722981, Best Loss: 0.003830474 in Epoch 58
Epoch 69
A best model at epoch 69 has been saved with training error 0.003642547.
Epoch 69, Loss: 0.008839987, Improvement: -0.002752914, Best Loss: 0.003642547 in Epoch 69
Epoch 70
Epoch 70, Loss: 0.007580919, Improvement: -0.001259068, Best Loss: 0.003642547 in Epoch 69
Epoch 71
Epoch 71, Loss: 0.007077029, Improvement: -0.000503890, Best Loss: 0.003642547 in Epoch 69
Epoch 72
Epoch 72, Loss: 0.006892363, Improvement: -0.000184666, Best Loss: 0.003642547 in Epoch 69
Epoch 73
Epoch 73, Loss: 0.006773679, Improvement: -0.000118684, Best Loss: 0.003642547 in Epoch 69
Epoch 74
Epoch 74, Loss: 0.006639685, Improvement: -0.000133995, Best Loss: 0.003642547 in Epoch 69
Epoch 75
Epoch 75, Loss: 0.006535929, Improvement: -0.000103755, Best Loss: 0.003642547 in Epoch 69
Epoch 76
A best model at epoch 76 has been saved with training error 0.003129643.
Epoch 76, Loss: 0.006477546, Improvement: -0.000058383, Best Loss: 0.003129643 in Epoch 76
Epoch 77
Epoch 77, Loss: 0.006421983, Improvement: -0.000055563, Best Loss: 0.003129643 in Epoch 76
Epoch 78
Epoch 78, Loss: 0.006355771, Improvement: -0.000066213, Best Loss: 0.003129643 in Epoch 76
Epoch 79
Epoch 79, Loss: 0.006314940, Improvement: -0.000040831, Best Loss: 0.003129643 in Epoch 76
Epoch 80
Epoch 80, Loss: 0.006259291, Improvement: -0.000055649, Best Loss: 0.003129643 in Epoch 76
Epoch 81
Epoch 81, Loss: 0.006218584, Improvement: -0.000040707, Best Loss: 0.003129643 in Epoch 76
Epoch 82
Epoch 82, Loss: 0.006159360, Improvement: -0.000059223, Best Loss: 0.003129643 in Epoch 76
Epoch 83
Epoch 83, Loss: 0.006115271, Improvement: -0.000044090, Best Loss: 0.003129643 in Epoch 76
Epoch 84
Epoch 84, Loss: 0.006089106, Improvement: -0.000026165, Best Loss: 0.003129643 in Epoch 76
Epoch 85
Epoch 85, Loss: 0.006067020, Improvement: -0.000022087, Best Loss: 0.003129643 in Epoch 76
Epoch 86
Epoch 86, Loss: 0.006058490, Improvement: -0.000008529, Best Loss: 0.003129643 in Epoch 76
Epoch 87
Epoch 87, Loss: 0.006063198, Improvement: 0.000004708, Best Loss: 0.003129643 in Epoch 76
Epoch 88
Epoch 88, Loss: 0.006147691, Improvement: 0.000084493, Best Loss: 0.003129643 in Epoch 76
Epoch 89
Epoch 89, Loss: 0.006233904, Improvement: 0.000086213, Best Loss: 0.003129643 in Epoch 76
Epoch 90
Epoch 90, Loss: 0.006427362, Improvement: 0.000193457, Best Loss: 0.003129643 in Epoch 76
Epoch 91
Epoch 91, Loss: 0.006753857, Improvement: 0.000326495, Best Loss: 0.003129643 in Epoch 76
Epoch 92
Epoch 92, Loss: 0.006607775, Improvement: -0.000146082, Best Loss: 0.003129643 in Epoch 76
Epoch 93
Epoch 93, Loss: 0.006821263, Improvement: 0.000213488, Best Loss: 0.003129643 in Epoch 76
Epoch 94
Epoch 94, Loss: 0.006795686, Improvement: -0.000025577, Best Loss: 0.003129643 in Epoch 76
Epoch 95
Epoch 95, Loss: 0.006983204, Improvement: 0.000187519, Best Loss: 0.003129643 in Epoch 76
Epoch 96
Epoch 96, Loss: 0.007761946, Improvement: 0.000778742, Best Loss: 0.003129643 in Epoch 76
Epoch 97
Epoch 97, Loss: 0.006610902, Improvement: -0.001151044, Best Loss: 0.003129643 in Epoch 76
Epoch 98
Epoch 98, Loss: 0.006068370, Improvement: -0.000542532, Best Loss: 0.003129643 in Epoch 76
Epoch 99
A best model at epoch 99 has been saved with training error 0.003086734.
Epoch 99, Loss: 0.005614891, Improvement: -0.000453479, Best Loss: 0.003086734 in Epoch 99
Epoch 100
Model saving checkpoint: the model trained after epoch 100 has been saved with the training errors.
Epoch 100, Loss: 0.005389541, Improvement: -0.000225350, Best Loss: 0.003086734 in Epoch 99
Epoch 101
Epoch 101, Loss: 0.005247420, Improvement: -0.000142121, Best Loss: 0.003086734 in Epoch 99
Epoch 102
Epoch 102, Loss: 0.005178321, Improvement: -0.000069099, Best Loss: 0.003086734 in Epoch 99
Epoch 103
Epoch 103, Loss: 0.005102995, Improvement: -0.000075326, Best Loss: 0.003086734 in Epoch 99
Epoch 104
Epoch 104, Loss: 0.005024813, Improvement: -0.000078182, Best Loss: 0.003086734 in Epoch 99
Epoch 105
Epoch 105, Loss: 0.005000950, Improvement: -0.000023864, Best Loss: 0.003086734 in Epoch 99
Epoch 106
Epoch 106, Loss: 0.004982289, Improvement: -0.000018661, Best Loss: 0.003086734 in Epoch 99
Epoch 107
Epoch 107, Loss: 0.005067494, Improvement: 0.000085205, Best Loss: 0.003086734 in Epoch 99
Epoch 108
Epoch 108, Loss: 0.005388616, Improvement: 0.000321121, Best Loss: 0.003086734 in Epoch 99
Epoch 109
Epoch 109, Loss: 0.005341806, Improvement: -0.000046810, Best Loss: 0.003086734 in Epoch 99
Epoch 110
Epoch 110, Loss: 0.005250795, Improvement: -0.000091010, Best Loss: 0.003086734 in Epoch 99
Epoch 111
Epoch 111, Loss: 0.005028772, Improvement: -0.000222023, Best Loss: 0.003086734 in Epoch 99
Epoch 112
Epoch 112, Loss: 0.004823454, Improvement: -0.000205317, Best Loss: 0.003086734 in Epoch 99
Epoch 113
A best model at epoch 113 has been saved with training error 0.003021556.
A best model at epoch 113 has been saved with training error 0.002857047.
Epoch 113, Loss: 0.004670107, Improvement: -0.000153348, Best Loss: 0.002857047 in Epoch 113
Epoch 114
Epoch 114, Loss: 0.004611421, Improvement: -0.000058686, Best Loss: 0.002857047 in Epoch 113
Epoch 115
Epoch 115, Loss: 0.004295858, Improvement: -0.000315563, Best Loss: 0.002857047 in Epoch 113
Epoch 116
Epoch 116, Loss: 0.004139930, Improvement: -0.000155928, Best Loss: 0.002857047 in Epoch 113
Epoch 117
A best model at epoch 117 has been saved with training error 0.002710388.
Epoch 117, Loss: 0.004025455, Improvement: -0.000114476, Best Loss: 0.002710388 in Epoch 117
Epoch 118
Epoch 118, Loss: 0.004005652, Improvement: -0.000019803, Best Loss: 0.002710388 in Epoch 117
Epoch 119
A best model at epoch 119 has been saved with training error 0.002530172.
Epoch 119, Loss: 0.003961360, Improvement: -0.000044292, Best Loss: 0.002530172 in Epoch 119
Epoch 120
A best model at epoch 120 has been saved with training error 0.002410148.
A best model at epoch 120 has been saved with training error 0.002285537.
A best model at epoch 120 has been saved with training error 0.002235325.
Epoch 120, Loss: 0.003877987, Improvement: -0.000083373, Best Loss: 0.002235325 in Epoch 120
Epoch 121
Epoch 121, Loss: 0.003940134, Improvement: 0.000062147, Best Loss: 0.002235325 in Epoch 120
Epoch 122
Epoch 122, Loss: 0.003930438, Improvement: -0.000009696, Best Loss: 0.002235325 in Epoch 120
Epoch 123
Epoch 123, Loss: 0.003762716, Improvement: -0.000167722, Best Loss: 0.002235325 in Epoch 120
Epoch 124
Epoch 124, Loss: 0.003892895, Improvement: 0.000130179, Best Loss: 0.002235325 in Epoch 120
Epoch 125
Epoch 125, Loss: 0.004200426, Improvement: 0.000307530, Best Loss: 0.002235325 in Epoch 120
Epoch 126
Epoch 126, Loss: 0.004304959, Improvement: 0.000104534, Best Loss: 0.002235325 in Epoch 120
Epoch 127
Epoch 127, Loss: 0.004118333, Improvement: -0.000186626, Best Loss: 0.002235325 in Epoch 120
Epoch 128
Epoch 128, Loss: 0.004144020, Improvement: 0.000025687, Best Loss: 0.002235325 in Epoch 120
Epoch 129
A best model at epoch 129 has been saved with training error 0.002143860.
Epoch 129, Loss: 0.003841164, Improvement: -0.000302856, Best Loss: 0.002143860 in Epoch 129
Epoch 130
Epoch 130, Loss: 0.003679519, Improvement: -0.000161645, Best Loss: 0.002143860 in Epoch 129
Epoch 131
Epoch 131, Loss: 0.003502331, Improvement: -0.000177188, Best Loss: 0.002143860 in Epoch 129
Epoch 132
Epoch 132, Loss: 0.003418329, Improvement: -0.000084001, Best Loss: 0.002143860 in Epoch 129
Epoch 133
Epoch 133, Loss: 0.003488829, Improvement: 0.000070499, Best Loss: 0.002143860 in Epoch 129
Epoch 134
A best model at epoch 134 has been saved with training error 0.001857177.
Epoch 134, Loss: 0.003332889, Improvement: -0.000155940, Best Loss: 0.001857177 in Epoch 134
Epoch 135
Epoch 135, Loss: 0.003236040, Improvement: -0.000096849, Best Loss: 0.001857177 in Epoch 134
Epoch 136
Epoch 136, Loss: 0.003056345, Improvement: -0.000179694, Best Loss: 0.001857177 in Epoch 134
Epoch 137
Epoch 137, Loss: 0.003023881, Improvement: -0.000032465, Best Loss: 0.001857177 in Epoch 134
Epoch 138
Epoch 138, Loss: 0.002970310, Improvement: -0.000053571, Best Loss: 0.001857177 in Epoch 134
Epoch 139
Epoch 139, Loss: 0.002912969, Improvement: -0.000057341, Best Loss: 0.001857177 in Epoch 134
Epoch 140
Epoch 140, Loss: 0.002866379, Improvement: -0.000046590, Best Loss: 0.001857177 in Epoch 134
Epoch 141
Epoch 141, Loss: 0.002835297, Improvement: -0.000031081, Best Loss: 0.001857177 in Epoch 134
Epoch 142
A best model at epoch 142 has been saved with training error 0.001769878.
Epoch 142, Loss: 0.002772892, Improvement: -0.000062405, Best Loss: 0.001769878 in Epoch 142
Epoch 143
Epoch 143, Loss: 0.002845666, Improvement: 0.000072774, Best Loss: 0.001769878 in Epoch 142
Epoch 144
A best model at epoch 144 has been saved with training error 0.001707603.
Epoch 144, Loss: 0.002934744, Improvement: 0.000089078, Best Loss: 0.001707603 in Epoch 144
Epoch 145
A best model at epoch 145 has been saved with training error 0.001525390.
Epoch 145, Loss: 0.002828275, Improvement: -0.000106469, Best Loss: 0.001525390 in Epoch 145
Epoch 146
Epoch 146, Loss: 0.002672068, Improvement: -0.000156207, Best Loss: 0.001525390 in Epoch 145
Epoch 147
Epoch 147, Loss: 0.002826863, Improvement: 0.000154796, Best Loss: 0.001525390 in Epoch 145
Epoch 148
Epoch 148, Loss: 0.003405343, Improvement: 0.000578480, Best Loss: 0.001525390 in Epoch 145
Epoch 149
Epoch 149, Loss: 0.003424225, Improvement: 0.000018881, Best Loss: 0.001525390 in Epoch 145
Epoch 150
Model saving checkpoint: the model trained after epoch 150 has been saved with the training errors.
Epoch 150, Loss: 0.003104718, Improvement: -0.000319506, Best Loss: 0.001525390 in Epoch 145
Epoch 151
Epoch 151, Loss: 0.003553774, Improvement: 0.000449056, Best Loss: 0.001525390 in Epoch 145
Epoch 152
Epoch 152, Loss: 0.003883214, Improvement: 0.000329439, Best Loss: 0.001525390 in Epoch 145
Epoch 153
Epoch 153, Loss: 0.003811358, Improvement: -0.000071856, Best Loss: 0.001525390 in Epoch 145
Epoch 154
Epoch 154, Loss: 0.003298192, Improvement: -0.000513166, Best Loss: 0.001525390 in Epoch 145
Epoch 155
A best model at epoch 155 has been saved with training error 0.001411897.
Epoch 155, Loss: 0.002957699, Improvement: -0.000340493, Best Loss: 0.001411897 in Epoch 155
Epoch 156
Epoch 156, Loss: 0.002746177, Improvement: -0.000211522, Best Loss: 0.001411897 in Epoch 155
Epoch 157
A best model at epoch 157 has been saved with training error 0.001261423.
Epoch 157, Loss: 0.002569094, Improvement: -0.000177083, Best Loss: 0.001261423 in Epoch 157
Epoch 158
Epoch 158, Loss: 0.002393402, Improvement: -0.000175692, Best Loss: 0.001261423 in Epoch 157
Epoch 159
Epoch 159, Loss: 0.002282270, Improvement: -0.000111132, Best Loss: 0.001261423 in Epoch 157
Epoch 160
Epoch 160, Loss: 0.002196048, Improvement: -0.000086222, Best Loss: 0.001261423 in Epoch 157
Epoch 161
Epoch 161, Loss: 0.002142182, Improvement: -0.000053866, Best Loss: 0.001261423 in Epoch 157
Epoch 162
Epoch 162, Loss: 0.002063043, Improvement: -0.000079139, Best Loss: 0.001261423 in Epoch 157
Epoch 163
Epoch 163, Loss: 0.002086132, Improvement: 0.000023090, Best Loss: 0.001261423 in Epoch 157
Epoch 164
A best model at epoch 164 has been saved with training error 0.001141576.
Epoch 164, Loss: 0.001999967, Improvement: -0.000086166, Best Loss: 0.001141576 in Epoch 164
Epoch 165
A best model at epoch 165 has been saved with training error 0.001059416.
Epoch 165, Loss: 0.001969384, Improvement: -0.000030582, Best Loss: 0.001059416 in Epoch 165
Epoch 166
Epoch 166, Loss: 0.001961010, Improvement: -0.000008374, Best Loss: 0.001059416 in Epoch 165
Epoch 167
Epoch 167, Loss: 0.001955022, Improvement: -0.000005989, Best Loss: 0.001059416 in Epoch 165
Epoch 168
Epoch 168, Loss: 0.001934998, Improvement: -0.000020024, Best Loss: 0.001059416 in Epoch 165
Epoch 169
Epoch 169, Loss: 0.001915046, Improvement: -0.000019952, Best Loss: 0.001059416 in Epoch 165
Epoch 170
A best model at epoch 170 has been saved with training error 0.001047314.
A best model at epoch 170 has been saved with training error 0.001036219.
Epoch 170, Loss: 0.001893039, Improvement: -0.000022007, Best Loss: 0.001036219 in Epoch 170
Epoch 171
Epoch 171, Loss: 0.001839508, Improvement: -0.000053531, Best Loss: 0.001036219 in Epoch 170
Epoch 172
Epoch 172, Loss: 0.001836925, Improvement: -0.000002582, Best Loss: 0.001036219 in Epoch 170
Epoch 173
Epoch 173, Loss: 0.001800957, Improvement: -0.000035968, Best Loss: 0.001036219 in Epoch 170
Epoch 174
Epoch 174, Loss: 0.001861630, Improvement: 0.000060673, Best Loss: 0.001036219 in Epoch 170
Epoch 175
Epoch 175, Loss: 0.001860157, Improvement: -0.000001473, Best Loss: 0.001036219 in Epoch 170
Epoch 176
Epoch 176, Loss: 0.001852335, Improvement: -0.000007823, Best Loss: 0.001036219 in Epoch 170
Epoch 177
Epoch 177, Loss: 0.001995209, Improvement: 0.000142874, Best Loss: 0.001036219 in Epoch 170
Epoch 178
Epoch 178, Loss: 0.001939729, Improvement: -0.000055479, Best Loss: 0.001036219 in Epoch 170
Epoch 179
Epoch 179, Loss: 0.002057624, Improvement: 0.000117895, Best Loss: 0.001036219 in Epoch 170
Epoch 180
Epoch 180, Loss: 0.002069868, Improvement: 0.000012244, Best Loss: 0.001036219 in Epoch 170
Epoch 181
Epoch 181, Loss: 0.002252789, Improvement: 0.000182920, Best Loss: 0.001036219 in Epoch 170
Epoch 182
Epoch 182, Loss: 0.002296789, Improvement: 0.000044000, Best Loss: 0.001036219 in Epoch 170
Epoch 183
Epoch 183, Loss: 0.002349460, Improvement: 0.000052671, Best Loss: 0.001036219 in Epoch 170
Epoch 184
Epoch 184, Loss: 0.002210353, Improvement: -0.000139106, Best Loss: 0.001036219 in Epoch 170
Epoch 185
Epoch 185, Loss: 0.001897607, Improvement: -0.000312746, Best Loss: 0.001036219 in Epoch 170
Epoch 186
Epoch 186, Loss: 0.002415290, Improvement: 0.000517682, Best Loss: 0.001036219 in Epoch 170
Epoch 187
Epoch 187, Loss: 0.003095176, Improvement: 0.000679887, Best Loss: 0.001036219 in Epoch 170
Epoch 188
Epoch 188, Loss: 0.002219592, Improvement: -0.000875584, Best Loss: 0.001036219 in Epoch 170
Epoch 189
A best model at epoch 189 has been saved with training error 0.001004324.
Epoch 189, Loss: 0.002032296, Improvement: -0.000187296, Best Loss: 0.001004324 in Epoch 189
Epoch 190
Epoch 190, Loss: 0.001928826, Improvement: -0.000103470, Best Loss: 0.001004324 in Epoch 189
Epoch 191
Epoch 191, Loss: 0.001760966, Improvement: -0.000167860, Best Loss: 0.001004324 in Epoch 189
Epoch 192
Epoch 192, Loss: 0.001859714, Improvement: 0.000098748, Best Loss: 0.001004324 in Epoch 189
Epoch 193
A best model at epoch 193 has been saved with training error 0.001002977.
A best model at epoch 193 has been saved with training error 0.000896794.
Epoch 193, Loss: 0.001753211, Improvement: -0.000106503, Best Loss: 0.000896794 in Epoch 193
Epoch 194
A best model at epoch 194 has been saved with training error 0.000869249.
Epoch 194, Loss: 0.001631418, Improvement: -0.000121793, Best Loss: 0.000869249 in Epoch 194
Epoch 195
Epoch 195, Loss: 0.001549498, Improvement: -0.000081920, Best Loss: 0.000869249 in Epoch 194
Epoch 196
Epoch 196, Loss: 0.001498212, Improvement: -0.000051286, Best Loss: 0.000869249 in Epoch 194
Epoch 197
Epoch 197, Loss: 0.001470486, Improvement: -0.000027726, Best Loss: 0.000869249 in Epoch 194
Epoch 198
Epoch 198, Loss: 0.001445837, Improvement: -0.000024648, Best Loss: 0.000869249 in Epoch 194
Epoch 199
Epoch 199, Loss: 0.001440099, Improvement: -0.000005738, Best Loss: 0.000869249 in Epoch 194
Epoch 200
Model saving checkpoint: the model trained after epoch 200 has been saved with the training errors.
Epoch 200, Loss: 0.001425706, Improvement: -0.000014394, Best Loss: 0.000869249 in Epoch 194
Epoch 201
A best model at epoch 201 has been saved with training error 0.000666218.
Epoch 201, Loss: 0.001410713, Improvement: -0.000014993, Best Loss: 0.000666218 in Epoch 201
Epoch 202
Epoch 202, Loss: 0.001397658, Improvement: -0.000013054, Best Loss: 0.000666218 in Epoch 201
Epoch 203
Epoch 203, Loss: 0.001380152, Improvement: -0.000017506, Best Loss: 0.000666218 in Epoch 201
Epoch 204
Epoch 204, Loss: 0.001393730, Improvement: 0.000013578, Best Loss: 0.000666218 in Epoch 201
Epoch 205
Epoch 205, Loss: 0.001384098, Improvement: -0.000009633, Best Loss: 0.000666218 in Epoch 201
Epoch 206
Epoch 206, Loss: 0.001366573, Improvement: -0.000017525, Best Loss: 0.000666218 in Epoch 201
Epoch 207
Epoch 207, Loss: 0.001355812, Improvement: -0.000010761, Best Loss: 0.000666218 in Epoch 201
Epoch 208
Epoch 208, Loss: 0.001406873, Improvement: 0.000051060, Best Loss: 0.000666218 in Epoch 201
Epoch 209
Epoch 209, Loss: 0.001418765, Improvement: 0.000011892, Best Loss: 0.000666218 in Epoch 201
Epoch 210
Epoch 210, Loss: 0.001385097, Improvement: -0.000033668, Best Loss: 0.000666218 in Epoch 201
Epoch 211
Epoch 211, Loss: 0.001343492, Improvement: -0.000041605, Best Loss: 0.000666218 in Epoch 201
Epoch 212
Epoch 212, Loss: 0.001341532, Improvement: -0.000001960, Best Loss: 0.000666218 in Epoch 201
Epoch 213
Epoch 213, Loss: 0.001340736, Improvement: -0.000000796, Best Loss: 0.000666218 in Epoch 201
Epoch 214
Epoch 214, Loss: 0.001360925, Improvement: 0.000020188, Best Loss: 0.000666218 in Epoch 201
Epoch 215
Epoch 215, Loss: 0.001375842, Improvement: 0.000014917, Best Loss: 0.000666218 in Epoch 201
Epoch 216
Epoch 216, Loss: 0.001569768, Improvement: 0.000193927, Best Loss: 0.000666218 in Epoch 201
Epoch 217
Epoch 217, Loss: 0.001452127, Improvement: -0.000117642, Best Loss: 0.000666218 in Epoch 201
Epoch 218
Epoch 218, Loss: 0.001470059, Improvement: 0.000017933, Best Loss: 0.000666218 in Epoch 201
Epoch 219
Epoch 219, Loss: 0.001425909, Improvement: -0.000044151, Best Loss: 0.000666218 in Epoch 201
Epoch 220
Epoch 220, Loss: 0.001448409, Improvement: 0.000022501, Best Loss: 0.000666218 in Epoch 201
Epoch 221
Epoch 221, Loss: 0.001503107, Improvement: 0.000054698, Best Loss: 0.000666218 in Epoch 201
Epoch 222
Epoch 222, Loss: 0.001372229, Improvement: -0.000130878, Best Loss: 0.000666218 in Epoch 201
Epoch 223
Epoch 223, Loss: 0.001301523, Improvement: -0.000070706, Best Loss: 0.000666218 in Epoch 201
Epoch 224
Epoch 224, Loss: 0.001359637, Improvement: 0.000058113, Best Loss: 0.000666218 in Epoch 201
Epoch 225
Epoch 225, Loss: 0.001364706, Improvement: 0.000005070, Best Loss: 0.000666218 in Epoch 201
Epoch 226
Epoch 226, Loss: 0.001340329, Improvement: -0.000024377, Best Loss: 0.000666218 in Epoch 201
Epoch 227
Epoch 227, Loss: 0.001266281, Improvement: -0.000074048, Best Loss: 0.000666218 in Epoch 201
Epoch 228
Epoch 228, Loss: 0.001219600, Improvement: -0.000046681, Best Loss: 0.000666218 in Epoch 201
Epoch 229
Epoch 229, Loss: 0.001195293, Improvement: -0.000024308, Best Loss: 0.000666218 in Epoch 201
Epoch 230
A best model at epoch 230 has been saved with training error 0.000579072.
Epoch 230, Loss: 0.001203074, Improvement: 0.000007782, Best Loss: 0.000579072 in Epoch 230
Epoch 231
Epoch 231, Loss: 0.001160421, Improvement: -0.000042653, Best Loss: 0.000579072 in Epoch 230
Epoch 232
Epoch 232, Loss: 0.001114579, Improvement: -0.000045842, Best Loss: 0.000579072 in Epoch 230
Epoch 233
Epoch 233, Loss: 0.001096315, Improvement: -0.000018264, Best Loss: 0.000579072 in Epoch 230
Epoch 234
A best model at epoch 234 has been saved with training error 0.000557648.
Epoch 234, Loss: 0.001105248, Improvement: 0.000008933, Best Loss: 0.000557648 in Epoch 234
Epoch 235
Epoch 235, Loss: 0.001200077, Improvement: 0.000094829, Best Loss: 0.000557648 in Epoch 234
Epoch 236
Epoch 236, Loss: 0.001300658, Improvement: 0.000100582, Best Loss: 0.000557648 in Epoch 234
Epoch 237
Epoch 237, Loss: 0.001403246, Improvement: 0.000102587, Best Loss: 0.000557648 in Epoch 234
Epoch 238
Epoch 238, Loss: 0.001398644, Improvement: -0.000004602, Best Loss: 0.000557648 in Epoch 234
Epoch 239
Epoch 239, Loss: 0.001228889, Improvement: -0.000169754, Best Loss: 0.000557648 in Epoch 234
Epoch 240
Epoch 240, Loss: 0.001135514, Improvement: -0.000093375, Best Loss: 0.000557648 in Epoch 234
Epoch 241
Epoch 241, Loss: 0.001108555, Improvement: -0.000026959, Best Loss: 0.000557648 in Epoch 234
Epoch 242
A best model at epoch 242 has been saved with training error 0.000475587.
Epoch 242, Loss: 0.001344015, Improvement: 0.000235460, Best Loss: 0.000475587 in Epoch 242
Epoch 243
Epoch 243, Loss: 0.001856992, Improvement: 0.000512977, Best Loss: 0.000475587 in Epoch 242
Epoch 244
Epoch 244, Loss: 0.001663709, Improvement: -0.000193284, Best Loss: 0.000475587 in Epoch 242
Epoch 245
Epoch 245, Loss: 0.001274215, Improvement: -0.000389494, Best Loss: 0.000475587 in Epoch 242
Epoch 246
Epoch 246, Loss: 0.001327537, Improvement: 0.000053322, Best Loss: 0.000475587 in Epoch 242
Epoch 247
Epoch 247, Loss: 0.001443811, Improvement: 0.000116274, Best Loss: 0.000475587 in Epoch 242
Epoch 248
Epoch 248, Loss: 0.001130803, Improvement: -0.000313007, Best Loss: 0.000475587 in Epoch 242
Epoch 249
Epoch 249, Loss: 0.001043948, Improvement: -0.000086855, Best Loss: 0.000475587 in Epoch 242
Epoch 250
Model saving checkpoint: the model trained after epoch 250 has been saved with the training errors.
Epoch 250, Loss: 0.000982270, Improvement: -0.000061678, Best Loss: 0.000475587 in Epoch 242
Epoch 251
Epoch 251, Loss: 0.000964292, Improvement: -0.000017978, Best Loss: 0.000475587 in Epoch 242
Epoch 252
Epoch 252, Loss: 0.000927724, Improvement: -0.000036568, Best Loss: 0.000475587 in Epoch 242
Epoch 253
Epoch 253, Loss: 0.000905974, Improvement: -0.000021749, Best Loss: 0.000475587 in Epoch 242
Epoch 254
Epoch 254, Loss: 0.000898493, Improvement: -0.000007481, Best Loss: 0.000475587 in Epoch 242
Epoch 255
Epoch 255, Loss: 0.000892943, Improvement: -0.000005550, Best Loss: 0.000475587 in Epoch 242
Epoch 256
Epoch 256, Loss: 0.000887558, Improvement: -0.000005385, Best Loss: 0.000475587 in Epoch 242
Epoch 257
A best model at epoch 257 has been saved with training error 0.000428872.
Epoch 257, Loss: 0.000871323, Improvement: -0.000016235, Best Loss: 0.000428872 in Epoch 257
Epoch 258
Epoch 258, Loss: 0.000877066, Improvement: 0.000005742, Best Loss: 0.000428872 in Epoch 257
Epoch 259
Epoch 259, Loss: 0.000860117, Improvement: -0.000016949, Best Loss: 0.000428872 in Epoch 257
Epoch 260
Epoch 260, Loss: 0.000848820, Improvement: -0.000011297, Best Loss: 0.000428872 in Epoch 257
Epoch 261
Epoch 261, Loss: 0.000832767, Improvement: -0.000016053, Best Loss: 0.000428872 in Epoch 257
Epoch 262
Epoch 262, Loss: 0.000844489, Improvement: 0.000011722, Best Loss: 0.000428872 in Epoch 257
Epoch 263
Epoch 263, Loss: 0.000837824, Improvement: -0.000006665, Best Loss: 0.000428872 in Epoch 257
Epoch 264
Epoch 264, Loss: 0.000895441, Improvement: 0.000057617, Best Loss: 0.000428872 in Epoch 257
Epoch 265
Epoch 265, Loss: 0.001034490, Improvement: 0.000139049, Best Loss: 0.000428872 in Epoch 257
Epoch 266
Epoch 266, Loss: 0.001118699, Improvement: 0.000084209, Best Loss: 0.000428872 in Epoch 257
Epoch 267
Epoch 267, Loss: 0.001381322, Improvement: 0.000262624, Best Loss: 0.000428872 in Epoch 257
Epoch 268
Epoch 268, Loss: 0.001589719, Improvement: 0.000208397, Best Loss: 0.000428872 in Epoch 257
Epoch 269
Epoch 269, Loss: 0.001355451, Improvement: -0.000234269, Best Loss: 0.000428872 in Epoch 257
Epoch 270
Epoch 270, Loss: 0.001091712, Improvement: -0.000263739, Best Loss: 0.000428872 in Epoch 257
Epoch 271
Epoch 271, Loss: 0.000915986, Improvement: -0.000175726, Best Loss: 0.000428872 in Epoch 257
Epoch 272
Epoch 272, Loss: 0.000867798, Improvement: -0.000048189, Best Loss: 0.000428872 in Epoch 257
Epoch 273
Epoch 273, Loss: 0.001011364, Improvement: 0.000143567, Best Loss: 0.000428872 in Epoch 257
Epoch 274
Epoch 274, Loss: 0.000979917, Improvement: -0.000031447, Best Loss: 0.000428872 in Epoch 257
Epoch 275
Epoch 275, Loss: 0.000925770, Improvement: -0.000054147, Best Loss: 0.000428872 in Epoch 257
Epoch 276
Epoch 276, Loss: 0.001097025, Improvement: 0.000171256, Best Loss: 0.000428872 in Epoch 257
Epoch 277
Epoch 277, Loss: 0.001012133, Improvement: -0.000084893, Best Loss: 0.000428872 in Epoch 257
Epoch 278
A best model at epoch 278 has been saved with training error 0.000372869.
Epoch 278, Loss: 0.000966299, Improvement: -0.000045834, Best Loss: 0.000372869 in Epoch 278
Epoch 279
Epoch 279, Loss: 0.000865457, Improvement: -0.000100841, Best Loss: 0.000372869 in Epoch 278
Epoch 280
Epoch 280, Loss: 0.000777333, Improvement: -0.000088124, Best Loss: 0.000372869 in Epoch 278
Epoch 281
Epoch 281, Loss: 0.000761817, Improvement: -0.000015517, Best Loss: 0.000372869 in Epoch 278
Epoch 282
Epoch 282, Loss: 0.000783161, Improvement: 0.000021344, Best Loss: 0.000372869 in Epoch 278
Epoch 283
Epoch 283, Loss: 0.000769076, Improvement: -0.000014085, Best Loss: 0.000372869 in Epoch 278
Epoch 284
Epoch 284, Loss: 0.000725402, Improvement: -0.000043674, Best Loss: 0.000372869 in Epoch 278
Epoch 285
Epoch 285, Loss: 0.000705351, Improvement: -0.000020051, Best Loss: 0.000372869 in Epoch 278
Epoch 286
A best model at epoch 286 has been saved with training error 0.000370878.
Epoch 286, Loss: 0.000688272, Improvement: -0.000017079, Best Loss: 0.000370878 in Epoch 286
Epoch 287
Epoch 287, Loss: 0.000684440, Improvement: -0.000003831, Best Loss: 0.000370878 in Epoch 286
Epoch 288
Epoch 288, Loss: 0.000679005, Improvement: -0.000005436, Best Loss: 0.000370878 in Epoch 286
Epoch 289
Epoch 289, Loss: 0.000713657, Improvement: 0.000034653, Best Loss: 0.000370878 in Epoch 286
Epoch 290
Epoch 290, Loss: 0.000728512, Improvement: 0.000014855, Best Loss: 0.000370878 in Epoch 286
Epoch 291
Epoch 291, Loss: 0.000855142, Improvement: 0.000126630, Best Loss: 0.000370878 in Epoch 286
Epoch 292
Epoch 292, Loss: 0.000801056, Improvement: -0.000054086, Best Loss: 0.000370878 in Epoch 286
Epoch 293
Epoch 293, Loss: 0.000789279, Improvement: -0.000011777, Best Loss: 0.000370878 in Epoch 286
Epoch 294
Epoch 294, Loss: 0.000820716, Improvement: 0.000031437, Best Loss: 0.000370878 in Epoch 286
Epoch 295
Epoch 295, Loss: 0.000839619, Improvement: 0.000018903, Best Loss: 0.000370878 in Epoch 286
Epoch 296
Epoch 296, Loss: 0.000784435, Improvement: -0.000055184, Best Loss: 0.000370878 in Epoch 286
Epoch 297
Epoch 297, Loss: 0.000682088, Improvement: -0.000102347, Best Loss: 0.000370878 in Epoch 286
Epoch 298
Epoch 298, Loss: 0.000658476, Improvement: -0.000023612, Best Loss: 0.000370878 in Epoch 286
Epoch 299
Epoch 299, Loss: 0.000621648, Improvement: -0.000036828, Best Loss: 0.000370878 in Epoch 286
Epoch 300
Model saving checkpoint: the model trained after epoch 300 has been saved with the training errors.
Epoch 300, Loss: 0.000609350, Improvement: -0.000012297, Best Loss: 0.000370878 in Epoch 286
Epoch 301
Epoch 301, Loss: 0.000755904, Improvement: 0.000146554, Best Loss: 0.000370878 in Epoch 286
Epoch 302
Epoch 302, Loss: 0.000696166, Improvement: -0.000059738, Best Loss: 0.000370878 in Epoch 286
Epoch 303
Epoch 303, Loss: 0.000689037, Improvement: -0.000007129, Best Loss: 0.000370878 in Epoch 286
Epoch 304
Epoch 304, Loss: 0.000650585, Improvement: -0.000038452, Best Loss: 0.000370878 in Epoch 286
Epoch 305
Epoch 305, Loss: 0.000622347, Improvement: -0.000028238, Best Loss: 0.000370878 in Epoch 286
Epoch 306
Epoch 306, Loss: 0.000623048, Improvement: 0.000000701, Best Loss: 0.000370878 in Epoch 286
Epoch 307
Epoch 307, Loss: 0.000607241, Improvement: -0.000015807, Best Loss: 0.000370878 in Epoch 286
Epoch 308
Epoch 308, Loss: 0.000574133, Improvement: -0.000033109, Best Loss: 0.000370878 in Epoch 286
Epoch 309
Epoch 309, Loss: 0.000613362, Improvement: 0.000039229, Best Loss: 0.000370878 in Epoch 286
Epoch 310
Epoch 310, Loss: 0.000841446, Improvement: 0.000228084, Best Loss: 0.000370878 in Epoch 286
Epoch 311
Epoch 311, Loss: 0.000847592, Improvement: 0.000006146, Best Loss: 0.000370878 in Epoch 286
Epoch 312
Epoch 312, Loss: 0.000751691, Improvement: -0.000095901, Best Loss: 0.000370878 in Epoch 286
Epoch 313
Epoch 313, Loss: 0.000720345, Improvement: -0.000031345, Best Loss: 0.000370878 in Epoch 286
Epoch 314
Epoch 314, Loss: 0.000799844, Improvement: 0.000079499, Best Loss: 0.000370878 in Epoch 286
Epoch 315
Epoch 315, Loss: 0.000697918, Improvement: -0.000101926, Best Loss: 0.000370878 in Epoch 286
Epoch 316
Epoch 316, Loss: 0.000732984, Improvement: 0.000035066, Best Loss: 0.000370878 in Epoch 286
Epoch 317
Epoch 317, Loss: 0.000769259, Improvement: 0.000036276, Best Loss: 0.000370878 in Epoch 286
Epoch 318
Epoch 318, Loss: 0.000743066, Improvement: -0.000026193, Best Loss: 0.000370878 in Epoch 286
Epoch 319
Epoch 319, Loss: 0.000649842, Improvement: -0.000093225, Best Loss: 0.000370878 in Epoch 286
Epoch 320
Epoch 320, Loss: 0.000677008, Improvement: 0.000027166, Best Loss: 0.000370878 in Epoch 286
Epoch 321
A best model at epoch 321 has been saved with training error 0.000320737.
Epoch 321, Loss: 0.000683438, Improvement: 0.000006430, Best Loss: 0.000320737 in Epoch 321
Epoch 322
Epoch 322, Loss: 0.000536004, Improvement: -0.000147434, Best Loss: 0.000320737 in Epoch 321
Epoch 323
Epoch 323, Loss: 0.000493520, Improvement: -0.000042484, Best Loss: 0.000320737 in Epoch 321
Epoch 324
A best model at epoch 324 has been saved with training error 0.000307680.
Epoch 324, Loss: 0.000481366, Improvement: -0.000012154, Best Loss: 0.000307680 in Epoch 324
Epoch 325
Epoch 325, Loss: 0.000481163, Improvement: -0.000000204, Best Loss: 0.000307680 in Epoch 324
Epoch 326
Epoch 326, Loss: 0.000478577, Improvement: -0.000002586, Best Loss: 0.000307680 in Epoch 324
Epoch 327
Epoch 327, Loss: 0.000487419, Improvement: 0.000008842, Best Loss: 0.000307680 in Epoch 324
Epoch 328
A best model at epoch 328 has been saved with training error 0.000273217.
Epoch 328, Loss: 0.000467493, Improvement: -0.000019926, Best Loss: 0.000273217 in Epoch 328
Epoch 329
Epoch 329, Loss: 0.000458178, Improvement: -0.000009315, Best Loss: 0.000273217 in Epoch 328
Epoch 330
Epoch 330, Loss: 0.000504079, Improvement: 0.000045901, Best Loss: 0.000273217 in Epoch 328
Epoch 331
Epoch 331, Loss: 0.000476446, Improvement: -0.000027633, Best Loss: 0.000273217 in Epoch 328
Epoch 332
Epoch 332, Loss: 0.000613857, Improvement: 0.000137411, Best Loss: 0.000273217 in Epoch 328
Epoch 333
Epoch 333, Loss: 0.000631417, Improvement: 0.000017560, Best Loss: 0.000273217 in Epoch 328
Epoch 334
Epoch 334, Loss: 0.000500930, Improvement: -0.000130487, Best Loss: 0.000273217 in Epoch 328
Epoch 335
Epoch 335, Loss: 0.000480760, Improvement: -0.000020170, Best Loss: 0.000273217 in Epoch 328
Epoch 336
A best model at epoch 336 has been saved with training error 0.000266599.
Epoch 336, Loss: 0.000477403, Improvement: -0.000003358, Best Loss: 0.000266599 in Epoch 336
Epoch 337
A best model at epoch 337 has been saved with training error 0.000253683.
Epoch 337, Loss: 0.000564606, Improvement: 0.000087203, Best Loss: 0.000253683 in Epoch 337
Epoch 338
Epoch 338, Loss: 0.000508062, Improvement: -0.000056544, Best Loss: 0.000253683 in Epoch 337
Epoch 339
Epoch 339, Loss: 0.000636838, Improvement: 0.000128776, Best Loss: 0.000253683 in Epoch 337
Epoch 340
Epoch 340, Loss: 0.000537155, Improvement: -0.000099682, Best Loss: 0.000253683 in Epoch 337
Epoch 341
Epoch 341, Loss: 0.000462152, Improvement: -0.000075004, Best Loss: 0.000253683 in Epoch 337
Epoch 342
Epoch 342, Loss: 0.000454068, Improvement: -0.000008084, Best Loss: 0.000253683 in Epoch 337
Epoch 343
Epoch 343, Loss: 0.000435887, Improvement: -0.000018181, Best Loss: 0.000253683 in Epoch 337
Epoch 344
Epoch 344, Loss: 0.000406877, Improvement: -0.000029009, Best Loss: 0.000253683 in Epoch 337
Epoch 345
Epoch 345, Loss: 0.000397959, Improvement: -0.000008918, Best Loss: 0.000253683 in Epoch 337
Epoch 346
A best model at epoch 346 has been saved with training error 0.000225291.
Epoch 346, Loss: 0.000389449, Improvement: -0.000008511, Best Loss: 0.000225291 in Epoch 346
Epoch 347
Epoch 347, Loss: 0.000368979, Improvement: -0.000020469, Best Loss: 0.000225291 in Epoch 346
Epoch 348
Epoch 348, Loss: 0.000409198, Improvement: 0.000040218, Best Loss: 0.000225291 in Epoch 346
Epoch 349
Epoch 349, Loss: 0.000414350, Improvement: 0.000005152, Best Loss: 0.000225291 in Epoch 346
Epoch 350
Model saving checkpoint: the model trained after epoch 350 has been saved with the training errors.
Epoch 350, Loss: 0.000451090, Improvement: 0.000036741, Best Loss: 0.000225291 in Epoch 346
Epoch 351
Epoch 351, Loss: 0.000568313, Improvement: 0.000117222, Best Loss: 0.000225291 in Epoch 346
Epoch 352
Epoch 352, Loss: 0.000646306, Improvement: 0.000077994, Best Loss: 0.000225291 in Epoch 346
Epoch 353
Epoch 353, Loss: 0.000654519, Improvement: 0.000008212, Best Loss: 0.000225291 in Epoch 346
Epoch 354
Epoch 354, Loss: 0.000728923, Improvement: 0.000074404, Best Loss: 0.000225291 in Epoch 346
Epoch 355
Epoch 355, Loss: 0.000612987, Improvement: -0.000115936, Best Loss: 0.000225291 in Epoch 346
Epoch 356
Epoch 356, Loss: 0.000477000, Improvement: -0.000135987, Best Loss: 0.000225291 in Epoch 346
Epoch 357
Epoch 357, Loss: 0.000395309, Improvement: -0.000081691, Best Loss: 0.000225291 in Epoch 346
Epoch 358
Epoch 358, Loss: 0.000475410, Improvement: 0.000080100, Best Loss: 0.000225291 in Epoch 346
Epoch 359
Epoch 359, Loss: 0.000419241, Improvement: -0.000056169, Best Loss: 0.000225291 in Epoch 346
Epoch 360
Epoch 360, Loss: 0.000364954, Improvement: -0.000054287, Best Loss: 0.000225291 in Epoch 346
Epoch 361
A best model at epoch 361 has been saved with training error 0.000219962.
A best model at epoch 361 has been saved with training error 0.000215599.
A best model at epoch 361 has been saved with training error 0.000209059.
Epoch 361, Loss: 0.000324492, Improvement: -0.000040462, Best Loss: 0.000209059 in Epoch 361
Epoch 362
Epoch 362, Loss: 0.000315022, Improvement: -0.000009470, Best Loss: 0.000209059 in Epoch 361
Epoch 363
Epoch 363, Loss: 0.000303893, Improvement: -0.000011129, Best Loss: 0.000209059 in Epoch 361
Epoch 364
Epoch 364, Loss: 0.000295852, Improvement: -0.000008042, Best Loss: 0.000209059 in Epoch 361
Epoch 365
A best model at epoch 365 has been saved with training error 0.000202899.
A best model at epoch 365 has been saved with training error 0.000188456.
Epoch 365, Loss: 0.000289597, Improvement: -0.000006255, Best Loss: 0.000188456 in Epoch 365
Epoch 366
Epoch 366, Loss: 0.000288732, Improvement: -0.000000865, Best Loss: 0.000188456 in Epoch 365
Epoch 367
Epoch 367, Loss: 0.000286697, Improvement: -0.000002034, Best Loss: 0.000188456 in Epoch 365
Epoch 368
Epoch 368, Loss: 0.000292643, Improvement: 0.000005945, Best Loss: 0.000188456 in Epoch 365
Epoch 369
Epoch 369, Loss: 0.000329125, Improvement: 0.000036482, Best Loss: 0.000188456 in Epoch 365
Epoch 370
Epoch 370, Loss: 0.000420354, Improvement: 0.000091229, Best Loss: 0.000188456 in Epoch 365
Epoch 371
Epoch 371, Loss: 0.000396557, Improvement: -0.000023797, Best Loss: 0.000188456 in Epoch 365
Epoch 372
Epoch 372, Loss: 0.000404110, Improvement: 0.000007553, Best Loss: 0.000188456 in Epoch 365
Epoch 373
Epoch 373, Loss: 0.000397787, Improvement: -0.000006323, Best Loss: 0.000188456 in Epoch 365
Epoch 374
Epoch 374, Loss: 0.000359366, Improvement: -0.000038421, Best Loss: 0.000188456 in Epoch 365
Epoch 375
Epoch 375, Loss: 0.000368184, Improvement: 0.000008818, Best Loss: 0.000188456 in Epoch 365
Epoch 376
Epoch 376, Loss: 0.000377473, Improvement: 0.000009289, Best Loss: 0.000188456 in Epoch 365
Epoch 377
Epoch 377, Loss: 0.000401997, Improvement: 0.000024524, Best Loss: 0.000188456 in Epoch 365
Epoch 378
Epoch 378, Loss: 0.000713723, Improvement: 0.000311725, Best Loss: 0.000188456 in Epoch 365
Epoch 379
Epoch 379, Loss: 0.000870241, Improvement: 0.000156518, Best Loss: 0.000188456 in Epoch 365
Epoch 380
Epoch 380, Loss: 0.000683482, Improvement: -0.000186758, Best Loss: 0.000188456 in Epoch 365
Epoch 381
Epoch 381, Loss: 0.000452166, Improvement: -0.000231317, Best Loss: 0.000188456 in Epoch 365
Epoch 382
Epoch 382, Loss: 0.000340406, Improvement: -0.000111760, Best Loss: 0.000188456 in Epoch 365
Epoch 383
Epoch 383, Loss: 0.000299838, Improvement: -0.000040568, Best Loss: 0.000188456 in Epoch 365
Epoch 384
A best model at epoch 384 has been saved with training error 0.000186567.
Epoch 384, Loss: 0.000271829, Improvement: -0.000028009, Best Loss: 0.000186567 in Epoch 384
Epoch 385
A best model at epoch 385 has been saved with training error 0.000159850.
Epoch 385, Loss: 0.000263176, Improvement: -0.000008653, Best Loss: 0.000159850 in Epoch 385
Epoch 386
Epoch 386, Loss: 0.000241528, Improvement: -0.000021647, Best Loss: 0.000159850 in Epoch 385
Epoch 387
Epoch 387, Loss: 0.000234242, Improvement: -0.000007286, Best Loss: 0.000159850 in Epoch 385
Epoch 388
Epoch 388, Loss: 0.000229458, Improvement: -0.000004784, Best Loss: 0.000159850 in Epoch 385
Epoch 389
Epoch 389, Loss: 0.000226241, Improvement: -0.000003217, Best Loss: 0.000159850 in Epoch 385
Epoch 390
A best model at epoch 390 has been saved with training error 0.000135884.
Epoch 390, Loss: 0.000222718, Improvement: -0.000003523, Best Loss: 0.000135884 in Epoch 390
Epoch 391
Epoch 391, Loss: 0.000220545, Improvement: -0.000002173, Best Loss: 0.000135884 in Epoch 390
Epoch 392
Epoch 392, Loss: 0.000218467, Improvement: -0.000002078, Best Loss: 0.000135884 in Epoch 390
Epoch 393
A best model at epoch 393 has been saved with training error 0.000134025.
Epoch 393, Loss: 0.000214761, Improvement: -0.000003706, Best Loss: 0.000134025 in Epoch 393
Epoch 394
A best model at epoch 394 has been saved with training error 0.000129335.
Epoch 394, Loss: 0.000213000, Improvement: -0.000001761, Best Loss: 0.000129335 in Epoch 394
Epoch 395
Epoch 395, Loss: 0.000209240, Improvement: -0.000003760, Best Loss: 0.000129335 in Epoch 394
Epoch 396
A best model at epoch 396 has been saved with training error 0.000116106.
Epoch 396, Loss: 0.000207961, Improvement: -0.000001279, Best Loss: 0.000116106 in Epoch 396
Epoch 397
Epoch 397, Loss: 0.000210225, Improvement: 0.000002265, Best Loss: 0.000116106 in Epoch 396
Epoch 398
Epoch 398, Loss: 0.000205227, Improvement: -0.000004998, Best Loss: 0.000116106 in Epoch 396
Epoch 399
Epoch 399, Loss: 0.000207702, Improvement: 0.000002475, Best Loss: 0.000116106 in Epoch 396
Epoch 400
Model saving checkpoint: the model trained after epoch 400 has been saved with the training errors.
Epoch 400, Loss: 0.000207553, Improvement: -0.000000150, Best Loss: 0.000116106 in Epoch 396
Epoch 401
Epoch 401, Loss: 0.000222041, Improvement: 0.000014488, Best Loss: 0.000116106 in Epoch 396
Epoch 402
Epoch 402, Loss: 0.000212261, Improvement: -0.000009780, Best Loss: 0.000116106 in Epoch 396
Epoch 403
Epoch 403, Loss: 0.000223442, Improvement: 0.000011181, Best Loss: 0.000116106 in Epoch 396
Epoch 404
Epoch 404, Loss: 0.000272911, Improvement: 0.000049470, Best Loss: 0.000116106 in Epoch 396
Epoch 405
Epoch 405, Loss: 0.000263602, Improvement: -0.000009309, Best Loss: 0.000116106 in Epoch 396
Epoch 406
Epoch 406, Loss: 0.000249722, Improvement: -0.000013880, Best Loss: 0.000116106 in Epoch 396
Epoch 407
Epoch 407, Loss: 0.000211883, Improvement: -0.000037839, Best Loss: 0.000116106 in Epoch 396
Epoch 408
Epoch 408, Loss: 0.000227420, Improvement: 0.000015537, Best Loss: 0.000116106 in Epoch 396
Epoch 409
Epoch 409, Loss: 0.000226773, Improvement: -0.000000648, Best Loss: 0.000116106 in Epoch 396
Epoch 410
Epoch 410, Loss: 0.000210094, Improvement: -0.000016679, Best Loss: 0.000116106 in Epoch 396
Epoch 411
Epoch 411, Loss: 0.000203257, Improvement: -0.000006837, Best Loss: 0.000116106 in Epoch 396
Epoch 412
A best model at epoch 412 has been saved with training error 0.000114996.
Epoch 412, Loss: 0.000213975, Improvement: 0.000010718, Best Loss: 0.000114996 in Epoch 412
Epoch 413
Epoch 413, Loss: 0.000333526, Improvement: 0.000119551, Best Loss: 0.000114996 in Epoch 412
Epoch 414
Epoch 414, Loss: 0.000260933, Improvement: -0.000072593, Best Loss: 0.000114996 in Epoch 412
Epoch 415
Epoch 415, Loss: 0.000296446, Improvement: 0.000035513, Best Loss: 0.000114996 in Epoch 412
Epoch 416
Epoch 416, Loss: 0.000244604, Improvement: -0.000051842, Best Loss: 0.000114996 in Epoch 412
Epoch 417
Epoch 417, Loss: 0.000236602, Improvement: -0.000008002, Best Loss: 0.000114996 in Epoch 412
Epoch 418
Epoch 418, Loss: 0.000202077, Improvement: -0.000034525, Best Loss: 0.000114996 in Epoch 412
Epoch 419
Epoch 419, Loss: 0.000202024, Improvement: -0.000000053, Best Loss: 0.000114996 in Epoch 412
Epoch 420
Epoch 420, Loss: 0.000217243, Improvement: 0.000015220, Best Loss: 0.000114996 in Epoch 412
Epoch 421
Epoch 421, Loss: 0.000236881, Improvement: 0.000019637, Best Loss: 0.000114996 in Epoch 412
Epoch 422
Epoch 422, Loss: 0.000251872, Improvement: 0.000014992, Best Loss: 0.000114996 in Epoch 412
Epoch 423
Epoch 423, Loss: 0.000265114, Improvement: 0.000013242, Best Loss: 0.000114996 in Epoch 412
Epoch 424
Epoch 424, Loss: 0.000218835, Improvement: -0.000046280, Best Loss: 0.000114996 in Epoch 412
Epoch 425
Epoch 425, Loss: 0.000219377, Improvement: 0.000000542, Best Loss: 0.000114996 in Epoch 412
Epoch 426
Epoch 426, Loss: 0.000249674, Improvement: 0.000030297, Best Loss: 0.000114996 in Epoch 412
Epoch 427
Epoch 427, Loss: 0.000234733, Improvement: -0.000014941, Best Loss: 0.000114996 in Epoch 412
Epoch 428
Epoch 428, Loss: 0.000230905, Improvement: -0.000003828, Best Loss: 0.000114996 in Epoch 412
Epoch 429
Epoch 429, Loss: 0.000302716, Improvement: 0.000071810, Best Loss: 0.000114996 in Epoch 412
Epoch 430
Epoch 430, Loss: 0.000389068, Improvement: 0.000086352, Best Loss: 0.000114996 in Epoch 412
Epoch 431
Epoch 431, Loss: 0.000420032, Improvement: 0.000030963, Best Loss: 0.000114996 in Epoch 412
Epoch 432
Epoch 432, Loss: 0.000284455, Improvement: -0.000135576, Best Loss: 0.000114996 in Epoch 412
Epoch 433
Epoch 433, Loss: 0.000205730, Improvement: -0.000078726, Best Loss: 0.000114996 in Epoch 412
Epoch 434
Epoch 434, Loss: 0.000177992, Improvement: -0.000027738, Best Loss: 0.000114996 in Epoch 412
Epoch 435
Epoch 435, Loss: 0.000168032, Improvement: -0.000009960, Best Loss: 0.000114996 in Epoch 412
Epoch 436
Epoch 436, Loss: 0.000155927, Improvement: -0.000012104, Best Loss: 0.000114996 in Epoch 412
Epoch 437
A best model at epoch 437 has been saved with training error 0.000101803.
Epoch 437, Loss: 0.000154530, Improvement: -0.000001397, Best Loss: 0.000101803 in Epoch 437
Epoch 438
Epoch 438, Loss: 0.000148091, Improvement: -0.000006439, Best Loss: 0.000101803 in Epoch 437
Epoch 439
Epoch 439, Loss: 0.000145517, Improvement: -0.000002573, Best Loss: 0.000101803 in Epoch 437
Epoch 440
Epoch 440, Loss: 0.000143336, Improvement: -0.000002182, Best Loss: 0.000101803 in Epoch 437
Epoch 441
Epoch 441, Loss: 0.000150059, Improvement: 0.000006724, Best Loss: 0.000101803 in Epoch 437
Epoch 442
A best model at epoch 442 has been saved with training error 0.000083157.
Epoch 442, Loss: 0.000146652, Improvement: -0.000003408, Best Loss: 0.000083157 in Epoch 442
Epoch 443
Epoch 443, Loss: 0.000143600, Improvement: -0.000003052, Best Loss: 0.000083157 in Epoch 442
Epoch 444
Epoch 444, Loss: 0.000134483, Improvement: -0.000009117, Best Loss: 0.000083157 in Epoch 442
Epoch 445
Epoch 445, Loss: 0.000132484, Improvement: -0.000001999, Best Loss: 0.000083157 in Epoch 442
Epoch 446
Epoch 446, Loss: 0.000129354, Improvement: -0.000003130, Best Loss: 0.000083157 in Epoch 442
Epoch 447
Epoch 447, Loss: 0.000126773, Improvement: -0.000002581, Best Loss: 0.000083157 in Epoch 442
Epoch 448
Epoch 448, Loss: 0.000126419, Improvement: -0.000000354, Best Loss: 0.000083157 in Epoch 442
Epoch 449
Epoch 449, Loss: 0.000126627, Improvement: 0.000000208, Best Loss: 0.000083157 in Epoch 442
Epoch 450
Model saving checkpoint: the model trained after epoch 450 has been saved with the training errors.
Epoch 450, Loss: 0.000124863, Improvement: -0.000001764, Best Loss: 0.000083157 in Epoch 442
Epoch 451
A best model at epoch 451 has been saved with training error 0.000079755.
Epoch 451, Loss: 0.000121639, Improvement: -0.000003223, Best Loss: 0.000079755 in Epoch 451
Epoch 452
Epoch 452, Loss: 0.000121624, Improvement: -0.000000016, Best Loss: 0.000079755 in Epoch 451
Epoch 453
Epoch 453, Loss: 0.000119779, Improvement: -0.000001845, Best Loss: 0.000079755 in Epoch 451
Epoch 454
Epoch 454, Loss: 0.000119492, Improvement: -0.000000287, Best Loss: 0.000079755 in Epoch 451
Epoch 455
Epoch 455, Loss: 0.000123141, Improvement: 0.000003649, Best Loss: 0.000079755 in Epoch 451
Epoch 456
Epoch 456, Loss: 0.000129678, Improvement: 0.000006537, Best Loss: 0.000079755 in Epoch 451
Epoch 457
Epoch 457, Loss: 0.000174024, Improvement: 0.000044347, Best Loss: 0.000079755 in Epoch 451
Epoch 458
Epoch 458, Loss: 0.000216857, Improvement: 0.000042833, Best Loss: 0.000079755 in Epoch 451
Epoch 459
Epoch 459, Loss: 0.000252467, Improvement: 0.000035610, Best Loss: 0.000079755 in Epoch 451
Epoch 460
Epoch 460, Loss: 0.000215829, Improvement: -0.000036638, Best Loss: 0.000079755 in Epoch 451
Epoch 461
Epoch 461, Loss: 0.000283921, Improvement: 0.000068092, Best Loss: 0.000079755 in Epoch 451
Epoch 462
Epoch 462, Loss: 0.000319521, Improvement: 0.000035599, Best Loss: 0.000079755 in Epoch 451
Epoch 463
Epoch 463, Loss: 0.000220276, Improvement: -0.000099244, Best Loss: 0.000079755 in Epoch 451
Epoch 464
Epoch 464, Loss: 0.000253067, Improvement: 0.000032790, Best Loss: 0.000079755 in Epoch 451
Epoch 465
Epoch 465, Loss: 0.000230994, Improvement: -0.000022073, Best Loss: 0.000079755 in Epoch 451
Epoch 466
Epoch 466, Loss: 0.000186740, Improvement: -0.000044254, Best Loss: 0.000079755 in Epoch 451
Epoch 467
Epoch 467, Loss: 0.000166174, Improvement: -0.000020565, Best Loss: 0.000079755 in Epoch 451
Epoch 468
Epoch 468, Loss: 0.000133290, Improvement: -0.000032885, Best Loss: 0.000079755 in Epoch 451
Epoch 469
Epoch 469, Loss: 0.000139982, Improvement: 0.000006692, Best Loss: 0.000079755 in Epoch 451
Epoch 470
A best model at epoch 470 has been saved with training error 0.000075261.
Epoch 470, Loss: 0.000125252, Improvement: -0.000014730, Best Loss: 0.000075261 in Epoch 470
Epoch 471
A best model at epoch 471 has been saved with training error 0.000073723.
Epoch 471, Loss: 0.000110911, Improvement: -0.000014341, Best Loss: 0.000073723 in Epoch 471
Epoch 472
Epoch 472, Loss: 0.000111020, Improvement: 0.000000109, Best Loss: 0.000073723 in Epoch 471
Epoch 473
Epoch 473, Loss: 0.000113885, Improvement: 0.000002866, Best Loss: 0.000073723 in Epoch 471
Epoch 474
Epoch 474, Loss: 0.000111724, Improvement: -0.000002161, Best Loss: 0.000073723 in Epoch 471
Epoch 475
Epoch 475, Loss: 0.000108977, Improvement: -0.000002747, Best Loss: 0.000073723 in Epoch 471
Epoch 476
Epoch 476, Loss: 0.000121776, Improvement: 0.000012798, Best Loss: 0.000073723 in Epoch 471
Epoch 477
Epoch 477, Loss: 0.000122733, Improvement: 0.000000958, Best Loss: 0.000073723 in Epoch 471
Epoch 478
Epoch 478, Loss: 0.000135004, Improvement: 0.000012270, Best Loss: 0.000073723 in Epoch 471
Epoch 479
Epoch 479, Loss: 0.000119258, Improvement: -0.000015745, Best Loss: 0.000073723 in Epoch 471
Epoch 480
Epoch 480, Loss: 0.000122745, Improvement: 0.000003487, Best Loss: 0.000073723 in Epoch 471
Epoch 481
Epoch 481, Loss: 0.000150077, Improvement: 0.000027332, Best Loss: 0.000073723 in Epoch 471
Epoch 482
Epoch 482, Loss: 0.000151794, Improvement: 0.000001716, Best Loss: 0.000073723 in Epoch 471
Epoch 483
Epoch 483, Loss: 0.000189675, Improvement: 0.000037882, Best Loss: 0.000073723 in Epoch 471
Epoch 484
Epoch 484, Loss: 0.000263651, Improvement: 0.000073976, Best Loss: 0.000073723 in Epoch 471
Epoch 485
Epoch 485, Loss: 0.000191692, Improvement: -0.000071959, Best Loss: 0.000073723 in Epoch 471
Epoch 486
Epoch 486, Loss: 0.000154138, Improvement: -0.000037554, Best Loss: 0.000073723 in Epoch 471
Epoch 487
Epoch 487, Loss: 0.000149126, Improvement: -0.000005011, Best Loss: 0.000073723 in Epoch 471
Epoch 488
Epoch 488, Loss: 0.000149734, Improvement: 0.000000608, Best Loss: 0.000073723 in Epoch 471
Epoch 489
Epoch 489, Loss: 0.000135017, Improvement: -0.000014717, Best Loss: 0.000073723 in Epoch 471
Epoch 490
Epoch 490, Loss: 0.000137275, Improvement: 0.000002258, Best Loss: 0.000073723 in Epoch 471
Epoch 491
Epoch 491, Loss: 0.000150685, Improvement: 0.000013411, Best Loss: 0.000073723 in Epoch 471
Epoch 492
Epoch 492, Loss: 0.000309236, Improvement: 0.000158551, Best Loss: 0.000073723 in Epoch 471
Epoch 493
Epoch 493, Loss: 0.000233912, Improvement: -0.000075324, Best Loss: 0.000073723 in Epoch 471
Epoch 494
Epoch 494, Loss: 0.000176180, Improvement: -0.000057732, Best Loss: 0.000073723 in Epoch 471
Epoch 495
Epoch 495, Loss: 0.000125529, Improvement: -0.000050651, Best Loss: 0.000073723 in Epoch 471
Epoch 496
A best model at epoch 496 has been saved with training error 0.000069795.
Epoch 496, Loss: 0.000107863, Improvement: -0.000017666, Best Loss: 0.000069795 in Epoch 496
Epoch 497
A best model at epoch 497 has been saved with training error 0.000065633.
Epoch 497, Loss: 0.000120777, Improvement: 0.000012915, Best Loss: 0.000065633 in Epoch 497
Epoch 498
Epoch 498, Loss: 0.000139933, Improvement: 0.000019156, Best Loss: 0.000065633 in Epoch 497
Epoch 499
Epoch 499, Loss: 0.000144296, Improvement: 0.000004362, Best Loss: 0.000065633 in Epoch 497
Epoch 500
Model saving checkpoint: the model trained after epoch 500 has been saved with the training errors.
Epoch 500, Loss: 0.000115355, Improvement: -0.000028941, Best Loss: 0.000065633 in Epoch 497
Epoch 501
Epoch 501, Loss: 0.000103005, Improvement: -0.000012350, Best Loss: 0.000065633 in Epoch 497
Epoch 502
Epoch 502, Loss: 0.000100403, Improvement: -0.000002602, Best Loss: 0.000065633 in Epoch 497
Epoch 503
Epoch 503, Loss: 0.000110400, Improvement: 0.000009997, Best Loss: 0.000065633 in Epoch 497
Epoch 504
Epoch 504, Loss: 0.000107760, Improvement: -0.000002641, Best Loss: 0.000065633 in Epoch 497
Epoch 505
Epoch 505, Loss: 0.000113148, Improvement: 0.000005389, Best Loss: 0.000065633 in Epoch 497
Epoch 506
A best model at epoch 506 has been saved with training error 0.000057147.
Epoch 506, Loss: 0.000102198, Improvement: -0.000010950, Best Loss: 0.000057147 in Epoch 506
Epoch 507
Epoch 507, Loss: 0.000097159, Improvement: -0.000005039, Best Loss: 0.000057147 in Epoch 506
Epoch 508
Epoch 508, Loss: 0.000103059, Improvement: 0.000005900, Best Loss: 0.000057147 in Epoch 506
Epoch 509
Epoch 509, Loss: 0.000091817, Improvement: -0.000011242, Best Loss: 0.000057147 in Epoch 506
Epoch 510
