{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:48:32.051240Z",
     "start_time": "2024-11-17T04:48:32.046840Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import fipy as fp\n",
    "\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "\n",
    "'''\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description=\"DeepONet with configurable parameters.\")\n",
    "parser.add_argument('--var', type=int, default=0, help='Variant of DeepONet')\n",
    "parser.add_argument('--struct', type=int, default=2, help='Structure of DeepONet')\n",
    "parser.add_argument('--sensor', type=int, default=50, help='Number of sensors')\n",
    "parser.add_argument('--boundary_parameter', type=float, default=0, help='Weight parameter for boundary conditions')\n",
    "# 解析命令行参数\n",
    "args = parser.parse_args()\n",
    "var = args.var\n",
    "struct = args.struct\n",
    "n_points = args.sensor\n",
    "boundary_parameter = args.boundary_parameter\n",
    "'''\n",
    "var = 0\n",
    "struct = 2\n",
    "n_points = 50\n",
    "boundary_parameter = 0\n",
    "\n",
    "\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c301c190545560",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_limit = 1\n",
    "time_step = 0.01\n",
    "total_time_steps = int(time_limit/time_step)\n",
    "total_sample = 500\n",
    "boundary = int(total_sample*4/5) # 设置训练集和测试集的边界\n",
    "batch_size = 20\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "branch_input_dim = n_points  # Number of points to represent the original function\n",
    "trunk_input_dim = 2     # Coordinate where we evaluate the transformed function\n",
    "\n",
    "# Define the dictionary mapping struct values to neural network structures\n",
    "if var!=6:\n",
    "    structures = {\n",
    "        1: {'hidden_dims': [100, 100, 100, 100], 'output_dim': 50},\n",
    "        2: {'hidden_dims': [200, 200, 200, 200], 'output_dim': 50}\n",
    "    }\n",
    "\n",
    "    # Get the configuration based on the struct value\n",
    "    config = structures.get(struct, {'hidden_dims': [], 'output_dim': 0})\n",
    "\n",
    "    hidden_dims = config['hidden_dims']\n",
    "    output_dim = config['output_dim']\n",
    "elif var==6:\n",
    "    structure_params = {\n",
    "        1: (3, 3, 100, 50),\n",
    "        2: (3, 3, 200, 50),\n",
    "    }\n",
    "    if struct in structure_params:\n",
    "        branch_depth, trunk_depth, hidden_dim, output_dim = structure_params[struct]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid structure type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "494baac2c1b96444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:48:32.096029Z",
     "start_time": "2024-11-17T04:48:32.089093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of y_tensor is torch.Size([5000, 2]).\n",
      "The dimension of y_expanded is torch.Size([500, 5000, 2]) after expanding.\n"
     ]
    }
   ],
   "source": [
    "# In this cell, we define the function to get the cell centers of a 1D mesh. \n",
    "# Also, we set up the spatial and temporal grid points for the training and testing datasets.\n",
    "# This is the so-called y_expanded tensor. \n",
    "def get_cell_centers(time_limit = 1, n_points = 50):\n",
    "    \"\"\"\n",
    "    Get the cell center positions for a 1D mesh with the specified number of grid points.\n",
    "\n",
    "    Parameters:\n",
    "    - n_points: Number of grid points in the spatial domain.\n",
    "\n",
    "    Returns:\n",
    "    - cell_centers: The x-positions of the cell centers.\n",
    "    \"\"\"\n",
    "    L = time_limit  # Length of the domain\n",
    "    dx = L / n_points\n",
    "\n",
    "    # Create a 1D mesh\n",
    "    mesh = fp.Grid1D(nx=n_points, dx=dx)\n",
    "\n",
    "    # Get the cell center positions\n",
    "    cell_centers = mesh.cellCenters[0]  # These are the x-positions of the cell centers\n",
    "    cell_centers = np.array(cell_centers)\n",
    "\n",
    "    return cell_centers\n",
    "\n",
    "# Example usage:\n",
    "cell_centers = get_cell_centers(n_points=n_points)\n",
    "cell_centers = np.around(cell_centers, decimals=2)\n",
    "\n",
    "time_steps = np.arange(time_step, time_limit+time_step, time_step)\n",
    "time_steps = np.around(time_steps, decimals=2)\n",
    "\n",
    "Y1, Y2 = np.meshgrid(cell_centers, time_steps)  # 第一个变量进行行展开，第二个变量进行列展开\n",
    "\n",
    "y = np.column_stack([Y2.ravel(),Y1.ravel()]) \n",
    "# 先将 Y2 和 Y1 进行展开，然后将展开后的两个向量进行列合并\n",
    "\n",
    "y_tensor = torch.tensor(y, dtype=torch.float)\n",
    "print(f\"The dimension of y_tensor is {y_tensor.shape}.\")\n",
    "y_expanded = y_tensor.unsqueeze(0).expand(total_sample, -1, -1)\n",
    "print(f\"The dimension of y_expanded is {y_expanded.shape} after expanding.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "97c2618d2af6012",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:48:32.216718Z",
     "start_time": "2024-11-17T04:48:32.202323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the initial conditions are: (500, 50)\n",
      "The dimensions of the solutions are: (500, 100, 50)\n"
     ]
    }
   ],
   "source": [
    "# In this cell, we load the initial conditions and solutions from the saved files.\n",
    "\n",
    "# Define the directory where you want to save the file\n",
    "from pathlib import Path\n",
    "# Get the current directory\n",
    "current_dir = Path.cwd()\n",
    "#data_directory = os.path.join(current_dir.parent, 'data')\n",
    "data_directory = os.path.join(current_dir, 'data')\n",
    "initials_name = f'heat_initials_{len(cell_centers)}.npy'\n",
    "solutions_name = f'heat_solutions_{len(cell_centers)}.npy'\n",
    "\n",
    "# Define the file paths\n",
    "initials_path = os.path.join(data_directory, initials_name)\n",
    "solutions_path = os.path.join(data_directory, solutions_name)\n",
    "\n",
    "# Load the data\n",
    "initials = np.load(initials_path)\n",
    "solutions = np.load(solutions_path)\n",
    "\n",
    "print(f\"The dimensions of the initial conditions are: {initials.shape}\")\n",
    "print(f\"The dimensions of the solutions are: {solutions.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4bd2ad7a59d3c19d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:48:32.294618Z",
     "start_time": "2024-11-17T04:48:32.291688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of u_tensor is torch.Size([500, 50]).\n",
      "The dimension of u_expanded is torch.Size([500, 5000, 50]) after expanding.\n"
     ]
    }
   ],
   "source": [
    "# In this cell, we arrange the initial conditions into the desired format for training the DeepONet.\n",
    "# This is the so-called u_expanded tensor.\n",
    "u_tensor = torch.tensor(initials, dtype=torch.float)\n",
    "print(f\"The dimension of u_tensor is {u_tensor.shape}.\")\n",
    "\n",
    "u_expanded = u_tensor.unsqueeze(1) # u_expanded: tensor[total_sample, 1, n_points]\n",
    "u_expanded = u_expanded.expand(-1, total_time_steps*n_points, -1) # u_expanded: tensor[total_sample, total_time_steps*n_points, n_points]\n",
    "print(f\"The dimension of u_expanded is {u_expanded.shape} after expanding.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6b86789219fee30b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:48:32.385490Z",
     "start_time": "2024-11-17T04:48:32.378575Z"
    }
   },
   "outputs": [],
   "source": [
    "# I have a tensor of shape (total_sample, n_points) representing the initial conditions. In this cell, I wanted to expand it to (total_sample, total_time_steps*n_points) by repeating the initial conditions for each time step.\n",
    "\n",
    "# Assuming u_tensor is the tensor of shape (total_sample, n_points)\n",
    "# Expand the tensor to (total_sample, total_time_steps*n_points)\n",
    "u_corresponding = u_tensor.repeat(1, total_time_steps)\n",
    "u_corresponding = u_corresponding.unsqueeze(2)\n",
    "# print(u_corresponding.shape)\n",
    "\n",
    "if var==2 or var==3:\n",
    "    y_expanded = torch.cat((y_expanded, u_corresponding), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bc20320d16f0200d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:48:32.439275Z",
     "start_time": "2024-11-17T04:48:32.423462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loaded solution dataset has dimension (500, 100, 50),\n",
      "\t while the arranged linearized dataset has dimension (500, 5000).\n",
      "The dimension of s_tensor is torch.Size([500, 5000]).\n",
      "The dimension of s_expanded is torch.Size([500, 5000, 1]) after expanding.\n"
     ]
    }
   ],
   "source": [
    "# In this cell, we arrange the solutions into the desired format for training the DeepONet.\n",
    "# This is the so-called s_expanded tensor.\n",
    "\n",
    "solutions_linear = np.zeros((total_sample, total_time_steps*n_points))\n",
    "\n",
    "for i in range(total_sample):\n",
    "    solutions_linear[i] = solutions[i].flatten()\n",
    "\n",
    "# solutions is a 3D array of shape (total_sample, total_time_steps, n_points)\n",
    "print(f\"The loaded solution dataset has dimension {solutions.shape},\\n\\t while the arranged linearized dataset has dimension {solutions_linear.shape}.\")\n",
    "\n",
    "s_tensor  = torch.tensor(solutions_linear, dtype=torch.float) # s_tensor: tensor[total_sample, total_time_steps*n_points]\n",
    "s_expanded  = s_tensor.unsqueeze(2) # s_expanded: tensor[total_sample, total_time_steps*n_points, 1]\n",
    "\n",
    "print(f\"The dimension of s_tensor is {s_tensor.shape}.\")\n",
    "print(f\"The dimension of s_expanded is {s_expanded.shape} after expanding.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c7fb3d4c0f958ce9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:48:32.508896Z",
     "start_time": "2024-11-17T04:48:32.506143Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the function to well organize the dataset\n",
    "\"\"\"\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, input1_data, input2_data, targets):\n",
    "        self.input1_data = input1_data\n",
    "        self.input2_data = input2_data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input1_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input1 = self.input1_data[idx]\n",
    "        input2 = self.input2_data[idx]\n",
    "        target = self.targets[idx]\n",
    "        return input1, input2, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dcdc8073c92892a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:48:32.583779Z",
     "start_time": "2024-11-17T04:48:32.580749Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = CustomDataset(u_expanded[:boundary], y_expanded[:boundary], s_expanded[:boundary])\n",
    "test_set = CustomDataset(u_expanded[boundary:], y_expanded[boundary:], s_expanded[boundary:])\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1) \n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d06e8e2f96a73942",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:48:32.669717Z",
     "start_time": "2024-11-17T04:48:32.665783Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Design DeepONet Components.\n",
    "\"\"\"\n",
    "# Branch Network\n",
    "class BranchNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "        super(BranchNet, self).__init__()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        \n",
    "        # 添加多个隐藏层\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, h_dim))\n",
    "            layers.append(nn.ELU())\n",
    "            in_dim = h_dim\n",
    "        \n",
    "        layers.append(nn.Linear(in_dim, output_dim))\n",
    "        self.fc = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Trunk Network\n",
    "class TrunkNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "        super(TrunkNet, self).__init__()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        \n",
    "        # 添加多个隐藏层\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, h_dim))\n",
    "            layers.append(nn.ELU())\n",
    "            in_dim = h_dim\n",
    "        \n",
    "        layers.append(nn.Linear(in_dim, output_dim))\n",
    "        self.fc = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, y):\n",
    "        return self.fc(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ce89a9ad4e97103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:48:32.713058Z",
     "start_time": "2024-11-17T04:48:32.705377Z"
    }
   },
   "outputs": [],
   "source": [
    "# In this cell, we define the DeepONet Variants\n",
    "class DeepONet_0(nn.Module):\n",
    "    def __init__(self, branch_input_dim, trunk_input_dim, hidden_dims, output_dim):\n",
    "        super(DeepONet_0, self).__init__()\n",
    "        self.branch_net = BranchNet(branch_input_dim, hidden_dims, output_dim)\n",
    "        self.trunk_net = TrunkNet(trunk_input_dim, hidden_dims, output_dim)\n",
    "        \n",
    "    def forward(self, x, yy):\n",
    "        branch_output = self.branch_net(x)\n",
    "        trunk_output = self.trunk_net(yy)\n",
    "        # Combine the outputs (typically element-wise product)\n",
    "        output = torch.sum(branch_output * trunk_output, dim=-1, keepdim=True) # 按照最后一个坐标做内积\n",
    "        return output\n",
    "    \n",
    "class DeepONet_1(nn.Module):\n",
    "    def __init__(self, branch_input_dim, trunk_input_dim, hidden_dims, output_dim):\n",
    "        super(DeepONet_1, self).__init__()\n",
    "        self.branch_net = BranchNet(branch_input_dim+1, hidden_dims, output_dim)\n",
    "        self.trunk_net = TrunkNet(trunk_input_dim, hidden_dims, output_dim)\n",
    "        \n",
    "    def forward(self, x, yy):\n",
    "        y_part = yy[:, :, -1].unsqueeze(-1)\n",
    "        x_extend = torch.cat((x, y_part), dim=-1)\n",
    "        branch_output = self.branch_net(x_extend)\n",
    "        \n",
    "        trunk_output = self.trunk_net(yy)\n",
    "        \n",
    "        # Combine the outputs (typically element-wise product)\n",
    "        output = torch.sum(branch_output * trunk_output, dim=-1, keepdim=True) # 按照最后一个坐标做内积\n",
    "        return output\n",
    "\n",
    "class DeepONet_2(nn.Module):\n",
    "    def __init__(self, branch_input_dim, trunk_input_dim, hidden_dims, output_dim):\n",
    "        super(DeepONet_2, self).__init__()\n",
    "        self.branch_net = BranchNet(branch_input_dim, hidden_dims, output_dim)\n",
    "        self.trunk_net = TrunkNet(trunk_input_dim+1, hidden_dims, output_dim)\n",
    "        \n",
    "    def forward(self, x, yy):\n",
    "        branch_output = self.branch_net(x)\n",
    "        trunk_output = self.trunk_net(yy)\n",
    "        \n",
    "        # Combine the outputs (typically element-wise product)\n",
    "        output = torch.sum(branch_output * trunk_output, dim=-1, keepdim=True) # 按照最后一个坐标做内积\n",
    "        return output\n",
    "    \n",
    "class DeepONet_3(nn.Module):\n",
    "    def __init__(self, branch_input_dim, trunk_input_dim, hidden_dims, output_dim):\n",
    "        super(DeepONet_3, self).__init__()\n",
    "        self.branch_net = BranchNet(branch_input_dim+1, hidden_dims, output_dim)\n",
    "        self.trunk_net = TrunkNet(trunk_input_dim+1, hidden_dims, output_dim)\n",
    "        \n",
    "    def forward(self, x, yy):\n",
    "        y_part = yy[:, :, -1].unsqueeze(-1)\n",
    "        x_extend = torch.cat((x, y_part), dim=-1)\n",
    "        branch_output = self.branch_net(x_extend)\n",
    "        \n",
    "        trunk_output = self.trunk_net(yy)\n",
    "        \n",
    "        # Combine the outputs (typically element-wise product)\n",
    "        output = torch.sum(branch_output * trunk_output, dim=-1, keepdim=True) # 按照最后一个坐标做内积\n",
    "        return output\n",
    "    \n",
    "class DeepONet_4(nn.Module):\n",
    "    def __init__(self, branch_input_dim, trunk_input_dim, hidden_dims, output_dim):\n",
    "        super(DeepONet_4, self).__init__()\n",
    "        self.branch_net = BranchNet(branch_input_dim+1, hidden_dims, output_dim)\n",
    "        self.trunk_net = TrunkNet(trunk_input_dim+branch_input_dim, hidden_dims, output_dim)\n",
    "        \n",
    "    def forward(self, x, yy):      \n",
    "        y_part = yy[:, :, -1].unsqueeze(-1)\n",
    "        x_extend = torch.cat((x, y_part), dim=-1)\n",
    "        branch_output = self.branch_net(x_extend)\n",
    "        \n",
    "        yy_extend = torch.cat((yy,x), dim=-1)\n",
    "        trunk_output = self.trunk_net(yy_extend)\n",
    "        \n",
    "        # Combine the outputs (typically element-wise product)\n",
    "        output = torch.sum(branch_output * trunk_output, dim=-1, keepdim=True) # 按照最后一个坐标做内积\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7a17b2b6b023c8c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:48:32.782237Z",
     "start_time": "2024-11-17T04:48:32.776028Z"
    }
   },
   "outputs": [],
   "source": [
    "# In this cell, we define the DeepONet_6, the modified DeepONet\n",
    "# Branch Network\n",
    "class MBranchNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, depth):\n",
    "        super(MBranchNet, self).__init__()\n",
    "        self.elu = nn.ELU()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        # 动态生成多层隐藏层\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for _ in range(depth)])\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # Apply weight initialization if needed\n",
    "        # self.apply(initialize_weights)\n",
    "\n",
    "    def forward(self, x, U, V):\n",
    "        xx = self.elu(self.fc1(x))\n",
    "        xx = torch.mul(1 - xx, U) + torch.mul(xx, V)\n",
    "\n",
    "        # 动态遍历隐藏层\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            xx = self.elu(hidden_layer(xx))\n",
    "            xx = torch.mul(1 - xx, U) + torch.mul(xx, V)\n",
    "\n",
    "        return self.fc_out(xx)\n",
    "\n",
    "\n",
    "# Trunk Network\n",
    "class MTrunkNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, depth):\n",
    "        super(MTrunkNet, self).__init__()\n",
    "        self.elu = nn.ELU()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "        # 动态生成多层隐藏层\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for _ in range(depth)])\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # Apply weight initialization if needed\n",
    "        # self.apply(initialize_weights)\n",
    "\n",
    "    def forward(self, y, U, V):\n",
    "        yy = self.elu(self.fc1(y))\n",
    "        yy = torch.mul(1 - yy, U) + torch.mul(yy, V)\n",
    "\n",
    "        # 动态遍历隐藏层\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            yy = self.elu(hidden_layer(yy))\n",
    "            yy = torch.mul(1 - yy, U) + torch.mul(yy, V)\n",
    "\n",
    "        return self.fc_out(yy)\n",
    "\n",
    "\n",
    "# DeepONet_6\n",
    "class DeepONet_6(nn.Module):\n",
    "    def __init__(self, branch_input_dim, branch_depth, trunk_input_dim, trunk_depth, hidden_dim, output_dim):\n",
    "        super(DeepONet_6, self).__init__()\n",
    "        self.elu = nn.ELU()\n",
    "        self.branch_net = MBranchNet(branch_input_dim, hidden_dim, output_dim, branch_depth)\n",
    "        self.trunk_net = MTrunkNet(trunk_input_dim, hidden_dim, output_dim, trunk_depth)\n",
    "        self.fcB = nn.Linear(branch_input_dim, hidden_dim)\n",
    "        self.fcT = nn.Linear(trunk_input_dim, hidden_dim)\n",
    "        # Apply weight initialization\n",
    "        # self.apply(initialize_weights)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        U = self.elu(self.fcB(x))\n",
    "        V = self.elu(self.fcT(y))\n",
    "\n",
    "        branch_output = self.branch_net(x, U, V)\n",
    "        trunk_output = self.trunk_net(y, U, V)\n",
    "        # Combine the outputs (typically element-wise product)\n",
    "\n",
    "        output = torch.sum(branch_output * trunk_output, dim=-1, keepdim=True)  # 按照最后一个坐标做内积\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f7382da74478d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:48:32.851889Z",
     "start_time": "2024-11-17T04:48:32.849854Z"
    }
   },
   "outputs": [],
   "source": [
    "# In this cell, we define the dictionary mapping the variant number to the corresponding DeepONet model\n",
    "\n",
    "DeepONets = {\n",
    "    0: DeepONet_0,\n",
    "    1: DeepONet_1,\n",
    "    2: DeepONet_2,\n",
    "    3: DeepONet_3,\n",
    "    4: DeepONet_4,\n",
    "    6: DeepONet_6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4852a2385d3faa33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:48:32.925388Z",
     "start_time": "2024-11-17T04:48:32.922404Z"
    }
   },
   "outputs": [],
   "source": [
    "# In this cell, we define the loss function\n",
    "\n",
    "# mean squared error function\n",
    "def mse(prediction, target):\n",
    "    ms_loss = torch.mean((prediction - target) ** 2)\n",
    "    return ms_loss\n",
    "# boundary condition\n",
    "def boundary_error(prediction):\n",
    "    prediction.reshape(-1, total_time_steps, n_points)\n",
    "    left_boundary = prediction[:, :, 0]\n",
    "    right_boundary = prediction[:, :, -1]\n",
    "    both_boundary = torch.cat([left_boundary, right_boundary], dim=1)\n",
    "    both_boundary_squared = both_boundary ** 2\n",
    "    return both_boundary_squared.mean()\n",
    "# loss function\n",
    "def loss_fn(prediction, target, boundary_parameter=0):\n",
    "    ms_loss = mse(prediction, target)\n",
    "    bc_loss = boundary_error(prediction)\n",
    "    return ms_loss + boundary_parameter * bc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b6bf19a07bbf4385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:48:33.000926Z",
     "start_time": "2024-11-17T04:48:32.995388Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if var!=6:\n",
    "    model = DeepONets[var](branch_input_dim, trunk_input_dim, hidden_dims, output_dim).to(device)\n",
    "elif var==6:\n",
    "    model = DeepONets[var](branch_input_dim, branch_depth, trunk_input_dim, trunk_depth, hidden_dim, output_dim).to(device)\n",
    "\n",
    "optimizer = optim.Adamax(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "685c9105c4470cfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:49:24.102745Z",
     "start_time": "2024-11-17T04:48:33.126921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A best model at epoch 1 has been saved with training error 0.017074037.\n",
      "A best model at epoch 1 has been saved with training error 0.011438650.\n",
      "A best model at epoch 1 has been saved with training error 0.010200941.\n",
      "A best model at epoch 1 has been saved with training error 0.010198979.\n",
      "A best model at epoch 1 has been saved with training error 0.009904126.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.018270605, Improvement: 0.018270605, Best Loss: 0.009904126 in Epoch 1\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A best model at epoch 2 has been saved with training error 0.009767191.\n",
      "A best model at epoch 2 has been saved with training error 0.006019806.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.010901987, Improvement: -0.007368617, Best Loss: 0.006019806 in Epoch 2\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "error_list = []\n",
    "err_best = float('inf')\n",
    "err_prev = 0\n",
    "best_epoch = 0\n",
    "model_best = model.state_dict().copy()\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\") \n",
    "    err = []\n",
    "    for input1_batch, input2_batch, target_batch in train_loader:\n",
    "        input1_batch = input1_batch.to(device)\n",
    "        input2_batch = input2_batch.to(device)\n",
    "        target_batch = target_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input1_batch, input2_batch)\n",
    "        loss = loss_fn(outputs, target_batch, boundary_parameter)\n",
    "        err.append(loss.item())\n",
    "        if loss.item()<err_best:\n",
    "            err_best = loss.item()\n",
    "            best_epoch = epoch\n",
    "            model_best = model.state_dict().copy()\n",
    "            model_filename_best = f\"Var{var}_Struct{struct}_Sensor{n_points}_Batch{batch_size}-best.pth\"\n",
    "            torch.save(model_best, model_filename_best)\n",
    "            print(f\"A best model at epoch {epoch+1} has been saved with training error {err_best:.9f}.\", file=sys.stderr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        del input1_batch, input2_batch, outputs, loss\n",
    "        torch.cuda.empty_cache()  # 释放当前批次的缓存\n",
    "    error_list.append(err)\n",
    "    err_curr = np.mean(err)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {err_curr:.9f}, Improvement: {err_curr - err_prev:.9f}, Best Loss: {err_best:.9f} in Epoch {best_epoch+1}\")\n",
    "    err_prev = err_curr\n",
    "    if epoch%50==49:\n",
    "        # 保存损失值和模型，修改文件名以包含参数信息  \n",
    "        output_filename = f\"Var{var}_Struct{struct}_Sensor{n_points}_Batch{batch_size}-final.npy\"\n",
    "        model_filename = f\"Var{var}_Struct{struct}_Sensor{n_points}_Batch{batch_size}-final.pth\"\n",
    "        np.save(output_filename, np.array(error_list))\n",
    "        torch.save(model.state_dict(), model_filename)\n",
    "        print(f\"Model saving checkpoint: the model trained after epoch {epoch+1} has been saved with the training errors.\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9f10a0718ea561fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:49:24.147728Z",
     "start_time": "2024-11-17T04:49:24.145168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0182706  0.01090199]\n"
     ]
    }
   ],
   "source": [
    "errs = np.array(error_list)\n",
    "\n",
    "print(np.mean(errs,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "81b8cd7c1dc06fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T04:49:24.242253Z",
     "start_time": "2024-11-17T04:49:24.215951Z"
    }
   },
   "outputs": [],
   "source": [
    "# 保存损失值和模型，修改文件名以包含参数信息\n",
    "output_filename = f\"Var{var}_Struct{struct}_Sensor{n_points}_Batch{batch_size}-final.npy\"\n",
    "model_filename = f\"Var{var}_Struct{struct}_Sensor{n_points}_Batch{batch_size}-final.pth\"\n",
    "\n",
    "np.save(output_filename, np.array(error_list))\n",
    "torch.save(model.state_dict(), model_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
