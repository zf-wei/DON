{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:34:46.574076Z",
     "start_time": "2024-11-12T07:34:46.569982Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import fipy as fp\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "'''\n",
    "parser = argparse.ArgumentParser(description=\"DeepONet with configurable parameters.\")\n",
    "parser.add_argument('--var', type=int, default=0, help='Variant of DeepONet')\n",
    "# 解析命令行参数\n",
    "args = parser.parse_args()\n",
    "var = args.var\n",
    "'''\n",
    "var = 3\n",
    "epochs = 2\n",
    "\n",
    "time_limit = 1\n",
    "time_step = 0.01\n",
    "n_points = 50\n",
    "total_time_steps = int(time_limit/time_step)\n",
    "total_sample = 500\n",
    "boundary = int(total_sample*4/5) # 设置训练集和测试集的边界\n",
    "batch_size = 20\n",
    "struct = 1\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "branch_input_dim = n_points  # Number of points to represent the original function\n",
    "trunk_input_dim = 2     # Coordinate where we evaluate the transformed function\n",
    "\n",
    "# Define the dictionary mapping struct values to hidden_dims and output_dim\n",
    "configurations = {\n",
    "    1: {'hidden_dims': [100, 100, 100, 100], 'output_dim': 50},\n",
    "    2: {'hidden_dims': [200, 200, 200, 200], 'output_dim': 50}\n",
    "}\n",
    "\n",
    "# Get the configuration based on the struct value\n",
    "config = configurations.get(struct, {'hidden_dims': [], 'output_dim': 0})\n",
    "\n",
    "hidden_dims = config['hidden_dims']\n",
    "output_dim = config['output_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "494baac2c1b96444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:34:46.612839Z",
     "start_time": "2024-11-12T07:34:46.605430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of y_tensor is torch.Size([5000, 2]).\n",
      "The dimension of y_expanded is torch.Size([500, 5000, 2]) after expanding.\n"
     ]
    }
   ],
   "source": [
    "# In this cell, we define the function to get the cell centers of a 1D mesh. \n",
    "# Also, we set up the spatial and temporal grid points for the training and testing datasets.\n",
    "# This is the so-called y_expanded tensor. \n",
    "def get_cell_centers(time_limit = 1, n_points = 50):\n",
    "    \"\"\"\n",
    "    Get the cell center positions for a 1D mesh with the specified number of grid points.\n",
    "\n",
    "    Parameters:\n",
    "    - n_points: Number of grid points in the spatial domain.\n",
    "\n",
    "    Returns:\n",
    "    - cell_centers: The x-positions of the cell centers.\n",
    "    \"\"\"\n",
    "    L = time_limit  # Length of the domain\n",
    "    dx = L / n_points\n",
    "\n",
    "    # Create a 1D mesh\n",
    "    mesh = fp.Grid1D(nx=n_points, dx=dx)\n",
    "\n",
    "    # Get the cell center positions\n",
    "    cell_centers = mesh.cellCenters[0]  # These are the x-positions of the cell centers\n",
    "    cell_centers = np.array(cell_centers)\n",
    "\n",
    "    return cell_centers\n",
    "\n",
    "# Example usage:\n",
    "cell_centers = get_cell_centers(n_points=n_points)\n",
    "cell_centers = np.around(cell_centers, decimals=2)\n",
    "\n",
    "time_steps = np.arange(time_step, time_limit+time_step, time_step)\n",
    "time_steps = np.around(time_steps, decimals=2)\n",
    "\n",
    "Y1, Y2 = np.meshgrid(cell_centers, time_steps)  # 第一个变量进行行展开，第二个变量进行列展开\n",
    "\n",
    "y = np.column_stack([Y2.ravel(),Y1.ravel()]) \n",
    "# 先将 Y2 和 Y1 进行展开，然后将展开后的两个向量进行列合并\n",
    "\n",
    "y_tensor = torch.tensor(y, dtype=torch.float)\n",
    "print(f\"The dimension of y_tensor is {y_tensor.shape}.\")\n",
    "y_expanded = y_tensor.unsqueeze(0).expand(total_sample, -1, -1)\n",
    "print(f\"The dimension of y_expanded is {y_expanded.shape} after expanding.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97c2618d2af6012",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:34:46.698918Z",
     "start_time": "2024-11-12T07:34:46.683093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the initial conditions are: (500, 50)\n",
      "The dimensions of the solutions are: (500, 100, 50)\n"
     ]
    }
   ],
   "source": [
    "# In this cell, we load the initial conditions and solutions from the saved files.\n",
    "\n",
    "# Define the directory where you want to save the file\n",
    "from pathlib import Path\n",
    "# Get the current directory\n",
    "current_dir = Path.cwd()\n",
    "#data_directory = os.path.join(current_dir.parent, 'data')\n",
    "data_directory = os.path.join(current_dir, 'data')\n",
    "initials_name = f'heat_initials_{len(cell_centers)}.npy'\n",
    "solutions_name = f'heat_solutions_{len(cell_centers)}.npy'\n",
    "\n",
    "# Define the file paths\n",
    "initials_path = os.path.join(data_directory, initials_name)\n",
    "solutions_path = os.path.join(data_directory, solutions_name)\n",
    "\n",
    "# Load the data\n",
    "initials = np.load(initials_path)\n",
    "solutions = np.load(solutions_path)\n",
    "\n",
    "print(f\"The dimensions of the initial conditions are: {initials.shape}\")\n",
    "print(f\"The dimensions of the solutions are: {solutions.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4bd2ad7a59d3c19d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:34:46.767802Z",
     "start_time": "2024-11-12T07:34:46.764836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of u_tensor is torch.Size([500, 50]).\n",
      "The dimension of u_expanded is torch.Size([500, 5000, 50]) after expanding.\n"
     ]
    }
   ],
   "source": [
    "# In this cell, we arrange the initial conditions into the desired format for training the DeepONet.\n",
    "# This is the so-called u_expanded tensor.\n",
    "u_tensor = torch.tensor(initials, dtype=torch.float)\n",
    "print(f\"The dimension of u_tensor is {u_tensor.shape}.\")\n",
    "\n",
    "u_expanded = u_tensor.unsqueeze(1) # u_expanded: tensor[total_sample, 1, n_points]\n",
    "u_expanded = u_expanded.expand(-1, total_time_steps*n_points, -1) # u_expanded: tensor[total_sample, total_time_steps*n_points, n_points]\n",
    "print(f\"The dimension of u_expanded is {u_expanded.shape} after expanding.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b86789219fee30b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:34:46.806948Z",
     "start_time": "2024-11-12T07:34:46.800287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 5000, 1])\n"
     ]
    }
   ],
   "source": [
    "# I have a tensor of shape (total_sample, n_points) representing the initial conditions. In this cell, I wanted to expand it to (total_sample, total_time_steps*n_points) by repeating the initial conditions for each time step.\n",
    "\n",
    "# Assuming u_tensor is the tensor of shape (total_sample, n_points)\n",
    "# Expand the tensor to (total_sample, total_time_steps*n_points)\n",
    "u_corresponding = u_tensor.repeat(1, total_time_steps)\n",
    "u_corresponding = u_corresponding.unsqueeze(2)\n",
    "# print(u_corresponding.shape)\n",
    "\n",
    "if var==2 or var==3:\n",
    "    y_expanded = torch.cat((y_expanded, u_corresponding), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc20320d16f0200d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:34:46.865337Z",
     "start_time": "2024-11-12T07:34:46.846229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loaded solution dataset has dimension (500, 100, 50),\n",
      "\t while the arranged linearized dataset has dimension (500, 5000).\n",
      "The dimension of s_tensor is torch.Size([500, 5000]).\n",
      "The dimension of s_expanded is torch.Size([500, 5000, 1]) after expanding.\n"
     ]
    }
   ],
   "source": [
    "# In this cell, we arrange the solutions into the desired format for training the DeepONet.\n",
    "# This is the so-called s_expanded tensor.\n",
    "\n",
    "solutions_linear = np.zeros((total_sample, total_time_steps*n_points))\n",
    "\n",
    "for i in range(total_sample):\n",
    "    solutions_linear[i] = solutions[i].flatten()\n",
    "\n",
    "# solutions is a 3D array of shape (total_sample, total_time_steps, n_points)\n",
    "print(f\"The loaded solution dataset has dimension {solutions.shape},\\n\\t while the arranged linearized dataset has dimension {solutions_linear.shape}.\")\n",
    "\n",
    "s_tensor  = torch.tensor(solutions_linear, dtype=torch.float) # s_tensor: tensor[total_sample, total_time_steps*n_points]\n",
    "s_expanded  = s_tensor.unsqueeze(2) # s_expanded: tensor[total_sample, total_time_steps*n_points, 1]\n",
    "\n",
    "print(f\"The dimension of s_tensor is {s_tensor.shape}.\")\n",
    "print(f\"The dimension of s_expanded is {s_expanded.shape} after expanding.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7fb3d4c0f958ce9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:34:46.927578Z",
     "start_time": "2024-11-12T07:34:46.924139Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the function to well organize the dataset\n",
    "\"\"\"\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, input1_data, input2_data, targets):\n",
    "        self.input1_data = input1_data\n",
    "        self.input2_data = input2_data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input1_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input1 = self.input1_data[idx]\n",
    "        input2 = self.input2_data[idx]\n",
    "        target = self.targets[idx]\n",
    "        return input1, input2, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dcdc8073c92892a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:34:47.002394Z",
     "start_time": "2024-11-12T07:34:46.995398Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = CustomDataset(u_expanded[:boundary], y_expanded[:boundary], s_expanded[:boundary])\n",
    "test_set = CustomDataset(u_expanded[boundary:], y_expanded[boundary:], s_expanded[boundary:])\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=1) \n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d06e8e2f96a73942",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:34:47.083530Z",
     "start_time": "2024-11-12T07:34:47.079422Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Design DeepONet Components.\n",
    "\"\"\"\n",
    "# Branch Network\n",
    "class BranchNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "        super(BranchNet, self).__init__()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        \n",
    "        # 添加多个隐藏层\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, h_dim))\n",
    "            layers.append(nn.ELU())\n",
    "            in_dim = h_dim\n",
    "        \n",
    "        layers.append(nn.Linear(in_dim, output_dim))\n",
    "        self.fc = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Trunk Network\n",
    "class TrunkNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "        super(TrunkNet, self).__init__()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        \n",
    "        # 添加多个隐藏层\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, h_dim))\n",
    "            layers.append(nn.ELU())\n",
    "            in_dim = h_dim\n",
    "        \n",
    "        layers.append(nn.Linear(in_dim, output_dim))\n",
    "        self.fc = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, y):\n",
    "        return self.fc(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce89a9ad4e97103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:34:47.170065Z",
     "start_time": "2024-11-12T07:34:47.162765Z"
    }
   },
   "outputs": [],
   "source": [
    "# In this cell, we define the DeepONet Variants\n",
    "class DeepONet_0(nn.Module):\n",
    "    def __init__(self, branch_input_dim, trunk_input_dim, hidden_dims, output_dim):\n",
    "        super(DeepONet_0, self).__init__()\n",
    "        self.branch_net = BranchNet(branch_input_dim, hidden_dims, output_dim)\n",
    "        self.trunk_net = TrunkNet(trunk_input_dim, hidden_dims, output_dim)\n",
    "        \n",
    "    def forward(self, x, yy):\n",
    "        branch_output = self.branch_net(x)\n",
    "        trunk_output = self.trunk_net(yy)\n",
    "        # Combine the outputs (typically element-wise product)\n",
    "        output = torch.sum(branch_output * trunk_output, dim=-1, keepdim=True) # 按照最后一个坐标做内积\n",
    "        return output\n",
    "    \n",
    "class DeepONet_1(nn.Module):\n",
    "    def __init__(self, branch_input_dim, trunk_input_dim, hidden_dims, output_dim):\n",
    "        super(DeepONet_1, self).__init__()\n",
    "        self.branch_net = BranchNet(branch_input_dim+1, hidden_dims, output_dim)\n",
    "        self.trunk_net = TrunkNet(trunk_input_dim, hidden_dims, output_dim)\n",
    "        \n",
    "    def forward(self, x, yy):\n",
    "        y_part = yy[:, :, -1].unsqueeze(-1)\n",
    "        x_extend = torch.cat((x, y_part), dim=-1)\n",
    "        branch_output = self.branch_net(x_extend)\n",
    "        \n",
    "        trunk_output = self.trunk_net(yy)\n",
    "        \n",
    "        # Combine the outputs (typically element-wise product)\n",
    "        output = torch.sum(branch_output * trunk_output, dim=-1, keepdim=True) # 按照最后一个坐标做内积\n",
    "        return output\n",
    "\n",
    "class DeepONet_2(nn.Module):\n",
    "    def __init__(self, branch_input_dim, trunk_input_dim, hidden_dims, output_dim):\n",
    "        super(DeepONet_2, self).__init__()\n",
    "        self.branch_net = BranchNet(branch_input_dim, hidden_dims, output_dim)\n",
    "        self.trunk_net = TrunkNet(trunk_input_dim+1, hidden_dims, output_dim)\n",
    "        \n",
    "    def forward(self, x, yy):\n",
    "        branch_output = self.branch_net(x)\n",
    "        trunk_output = self.trunk_net(yy)\n",
    "        \n",
    "        # Combine the outputs (typically element-wise product)\n",
    "        output = torch.sum(branch_output * trunk_output, dim=-1, keepdim=True) # 按照最后一个坐标做内积\n",
    "        return output\n",
    "    \n",
    "class DeepONet_3(nn.Module):\n",
    "    def __init__(self, branch_input_dim, trunk_input_dim, hidden_dims, output_dim):\n",
    "        super(DeepONet_3, self).__init__()\n",
    "        self.branch_net = BranchNet(branch_input_dim+1, hidden_dims, output_dim)\n",
    "        self.trunk_net = TrunkNet(trunk_input_dim+1, hidden_dims, output_dim)\n",
    "        \n",
    "    def forward(self, x, yy):\n",
    "        y_part = yy[:, :, -1].unsqueeze(-1)\n",
    "        x_extend = torch.cat((x, y_part), dim=-1)\n",
    "        branch_output = self.branch_net(x_extend)\n",
    "        \n",
    "        trunk_output = self.trunk_net(yy)\n",
    "        \n",
    "        # Combine the outputs (typically element-wise product)\n",
    "        output = torch.sum(branch_output * trunk_output, dim=-1, keepdim=True) # 按照最后一个坐标做内积\n",
    "        return output\n",
    "    \n",
    "class DeepONet_4(nn.Module):\n",
    "    def __init__(self, branch_input_dim, trunk_input_dim, hidden_dims, output_dim):\n",
    "        super(DeepONet_4, self).__init__()\n",
    "        self.branch_net = BranchNet(branch_input_dim+1, hidden_dims, output_dim)\n",
    "        self.trunk_net = TrunkNet(trunk_input_dim+branch_input_dim, hidden_dims, output_dim)\n",
    "        \n",
    "    def forward(self, x, yy):      \n",
    "        y_part = yy[:, :, -1].unsqueeze(-1)\n",
    "        x_extend = torch.cat((x, y_part), dim=-1)\n",
    "        branch_output = self.branch_net(x_extend)\n",
    "        \n",
    "        yy_extend = torch.cat((yy,x), dim=-1)\n",
    "        trunk_output = self.trunk_net(yy_extend)\n",
    "        \n",
    "        # Combine the outputs (typically element-wise product)\n",
    "        output = torch.sum(branch_output * trunk_output, dim=-1, keepdim=True) # 按照最后一个坐标做内积\n",
    "        return output\n",
    "    \n",
    "DeepONets = [DeepONet_0, DeepONet_1, DeepONet_2, DeepONet_3, DeepONet_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4852a2385d3faa33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:34:47.271655Z",
     "start_time": "2024-11-12T07:34:47.269605Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "def mse(prediction, target):\n",
    "    ms_loss = torch.mean((prediction - target) ** 2)\n",
    "    return ms_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6bf19a07bbf4385",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:34:47.354577Z",
     "start_time": "2024-11-12T07:34:47.349362Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DeepONets[var](branch_input_dim, trunk_input_dim, hidden_dims, output_dim).to(device)\n",
    "optimizer = optim.Adamax(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "685c9105c4470cfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:36:41.655169Z",
     "start_time": "2024-11-12T07:34:47.436657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A best model at epoch 1 has been saved with training error 0.018577220.\n",
      "A best model at epoch 1 has been saved with training error 0.012943567.\n",
      "A best model at epoch 1 has been saved with training error 0.011722613.\n",
      "A best model at epoch 1 has been saved with training error 0.010068863.\n",
      "A best model at epoch 1 has been saved with training error 0.009052048.\n",
      "A best model at epoch 1 has been saved with training error 0.008677189.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.014487458, Improvement: 0.014487458, Best Loss: 0.008677189 in Epoch 1\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A best model at epoch 2 has been saved with training error 0.007070955.\n",
      "A best model at epoch 2 has been saved with training error 0.006305048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.009928822, Improvement: -0.004558636, Best Loss: 0.006305048 in Epoch 2\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "error_list = []\n",
    "err_best = float('inf')\n",
    "err_prev = 0\n",
    "best_epoch = 0\n",
    "model_best = model.state_dict().copy()\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\") \n",
    "    err = []\n",
    "    for input1_batch, input2_batch, target_batch in train_loader:\n",
    "        input1_batch = input1_batch.to(device)\n",
    "        input2_batch = input2_batch.to(device)\n",
    "        target_batch = target_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input1_batch, input2_batch)\n",
    "        loss = mse(outputs, target_batch)\n",
    "        err.append(loss.item())\n",
    "        if loss.item()<err_best:\n",
    "            err_best = loss.item()\n",
    "            best_epoch = epoch\n",
    "            model_best = model.state_dict().copy()\n",
    "            model_filename_best = f\"Var{var}_Sensor{n_points}_Batch{batch_size}-best.pth\"\n",
    "            torch.save(model_best, model_filename_best)\n",
    "            print(f\"A best model at epoch {epoch+1} has been saved with training error {err_best:.9f}.\", file=sys.stderr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        del input1_batch, input2_batch, outputs, loss\n",
    "        torch.cuda.empty_cache()  # 释放当前批次的缓存\n",
    "    error_list.append(err)\n",
    "    err_curr = np.mean(err)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {err_curr:.9f}, Improvement: {err_curr - err_prev:.9f}, Best Loss: {err_best:.9f} in Epoch {best_epoch+1}\")\n",
    "    err_prev = err_curr\n",
    "    if epoch%50==49:\n",
    "        # 保存损失值和模型，修改文件名以包含参数信息  \n",
    "        output_filename = f\"Var{var}_Sensor{n_points}_Batch{batch_size}-final.npy\"\n",
    "        model_filename = f\"Var{var}_Sensor{n_points}_Batch{batch_size}-final.pth\"\n",
    "        np.save(output_filename, np.array(error_list))\n",
    "        torch.save(model.state_dict(), model_filename)\n",
    "        print(f\"Model saving checkpoint: the model trained after epoch {epoch+1} has been saved with the training errors.\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f10a0718ea561fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:36:41.696782Z",
     "start_time": "2024-11-12T07:36:41.693965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01448746 0.00992882]\n"
     ]
    }
   ],
   "source": [
    "errs = np.array(error_list)\n",
    "\n",
    "print(np.mean(errs,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81b8cd7c1dc06fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T07:36:41.772597Z",
     "start_time": "2024-11-12T07:36:41.747638Z"
    }
   },
   "outputs": [],
   "source": [
    "# 保存损失值和模型，修改文件名以包含参数信息\n",
    "output_filename = f\"Var{var}_Sensor{n_points}_Batch{batch_size}-final.npy\"\n",
    "model_filename = f\"Var{var}_Sensor{n_points}_Batch{batch_size}-final.pth\"\n",
    "\n",
    "np.save(output_filename, np.array(error_list))\n",
    "torch.save(model.state_dict(), model_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
